{
 "metadata": {
  "name": "",
  "signature": "sha256:561207c55b56be592b6a96959852bb62355fe98ad953a5f282b973986671983b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this part imports libs and load data from csv file\n",
      "import sys\n",
      "sys.path.append('../../../libs/')\n",
      "import csv\n",
      "from dateutil import parser\n",
      "from datetime import timedelta\n",
      "from sklearn import svm\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import pickle\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn import preprocessing\n",
      "import sklearn\n",
      "import scipy.stats as ss\n",
      "import cPickle\n",
      "import gzip\n",
      "import os\n",
      "import time\n",
      "import numpy\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "from theano.tensor.shared_randomstreams import RandomStreams\n",
      "import os.path\n",
      "import IO_class\n",
      "from IO_class import FileOperator\n",
      "from sklearn import cross_validation\n",
      "import sklearn\n",
      "import numpy as np\n",
      "import csv\n",
      "from dateutil import parser\n",
      "from datetime import timedelta\n",
      "from sklearn import svm\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import pdb\n",
      "import pickle\n",
      "import numpy as np\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.cross_validation import KFold\n",
      "from sklearn import preprocessing\n",
      "import sklearn\n",
      "import scipy.stats as ss\n",
      "from sklearn.svm import LinearSVC\n",
      "import random\n",
      "from DL_libs import *\n",
      "from itertools import izip #new\n",
      "import math\n",
      "from sklearn.svm import SVC"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set settings for this script\n",
      "settings = {}\n",
      "settings['fisher_mode'] = 'FisherM1'\n",
      "settings['with_auc_score'] = False\n",
      "settings['reduce_ratio'] = 1\n",
      "settings['SVM'] = 1\n",
      "settings['SVM_RBF'] = 1\n",
      "settings['SVM_POLY'] = 1\n",
      "settings['DL'] = 1\n",
      "settings['Log'] = 1\n",
      "settings['SAE_SVM'] = 1\n",
      "settings['SAE_SVM_RBF'] = 1\n",
      "settings['SAE_SVM_POLY'] = 1\n",
      "\n",
      "settings['DL_S'] = 1\n",
      "settings['SAE_S_SVM'] = 1\n",
      "settings['SAE_S_SVM_RBF'] = 1\n",
      "settings['SAE_S_SVM_POLY'] = 1\n",
      "settings['number_iterations'] =10\n",
      "\n",
      "\n",
      "settings['finetune_lr'] = 0.1\n",
      "settings['batch_size'] = 30\n",
      "settings['pretraining_interations'] = 10000\n",
      "settings['pretrain_lr'] = 0.001\n",
      "settings['training_epochs'] = 300\n",
      "settings['hidden_layers_sizes'] = [200, 200]\n",
      "settings['corruption_levels'] = [0,0]\n",
      "\n",
      "\n",
      "import logging\n",
      "import time\n",
      "current_date = time.strftime(\"%m_%d_%Y\")\n",
      "\n",
      "logger = logging.getLogger(__name__)\n",
      "logger.setLevel(logging.DEBUG)\n",
      "\n",
      "logname = 'log_DL_handwritten_digits' + current_date + '.log'\n",
      "handler = logging.FileHandler(logname)\n",
      "handler.setLevel(logging.DEBUG)\n",
      "\n",
      "# create a logging format\n",
      "\n",
      "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
      "handler.setFormatter(formatter)\n",
      "\n",
      "# add the handlers to the logger\n",
      "\n",
      "logger.addHandler(handler)\n",
      "\n",
      "#logger.debug('This message should go to the log file')\n",
      "for key, value in settings.items():\n",
      "    logger.info(key +': '+ str(value))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:DL: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:Log: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:DL_S: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:SVM_POLY: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:reduce_ratio: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:hidden_layers_sizes: [200, 200]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:corruption_levels: [0, 0]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:pretrain_lr: 0.001\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:SAE_S_SVM: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:SAE_SVM_POLY: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:SVM: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:SAE_S_SVM_RBF: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:SVM_RBF: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:batch_size: 30\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:SAE_S_SVM_POLY: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:SAE_SVM_RBF: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:SAE_SVM: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:pretraining_interations: 10000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:fisher_mode: FisherM1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:number_iterations: 10\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:finetune_lr: 0.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:with_auc_score: False\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:training_epochs: 300\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = gzip.open('mnist.pkl.gz', 'rb')\n",
      "train_set, valid_set, test_set = cPickle.load(f)\n",
      "X_train,y_train = train_set\n",
      "\n",
      "X_valid,y_valid = valid_set\n",
      "X_total=np.vstack((X_train, X_valid))\n",
      "X_total = np.array(X_total, dtype= theano.config.floatX)\n",
      "print'sample size', X_total.shape\n",
      "y_total = np.concatenate([y_train, y_valid])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sample size (60000, 784)\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "################## generate data ###################\n",
      "array_A =[]\n",
      "array_B =[]\n",
      "for i in range(100000):\n",
      "    array_A.append(np.random.random_integers(0, 59999))\n",
      "    array_B.append(np.random.random_integers(0, 59999))\n",
      "pos_index = []\n",
      "neg_index = []\n",
      "for index in xrange(100000):\n",
      "    if y_total[array_A[index]] - y_total[array_B[index]] == 1:\n",
      "        pos_index.append(index)\n",
      "    else:\n",
      "        neg_index.append(index)\n",
      "print 'number of positive examples', len(pos_index)\n",
      "selected_neg_index= neg_index[ : len(pos_index)]    \n",
      "\n",
      "array_A = np.array(array_A)\n",
      "array_B = np.array(array_B)\n",
      "index_for_positive_image_A = array_A[pos_index]\n",
      "index_for_positive_image_B = array_B[pos_index]\n",
      "index_for_neg_image_A = array_A[selected_neg_index]\n",
      "index_for_neg_image_B = array_B[selected_neg_index]\n",
      "\n",
      "X_pos_A = X_total[index_for_positive_image_A]\n",
      "X_pos_B = X_total[index_for_positive_image_B]\n",
      "X_pos_whole = np.hstack((X_pos_A,X_pos_B))\n",
      "X_neg_A = X_total[index_for_neg_image_A]\n",
      "X_neg_B = X_total[index_for_neg_image_B]\n",
      "X_neg_whole = np.hstack((X_neg_A, X_neg_B))\n",
      "print X_pos_A.shape,  X_pos_B.shape, X_pos_whole.shape\n",
      "print X_neg_A.shape,  X_neg_B.shape, X_neg_whole.shape\n",
      "\n",
      "X_whole = np.vstack((X_pos_whole, X_neg_whole))\n",
      "print X_whole.shape\n",
      "y_pos = np.ones(X_pos_whole.shape[0])\n",
      "y_neg = np.zeros(X_neg_whole.shape[0])\n",
      "y_whole = np.concatenate([y_pos,y_neg])\n",
      "print y_whole"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of positive examples 9097\n",
        "(9097, 784)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (9097, 784) (9097, 1568)\n",
        "(9097, 784) (9097, 784) (9097, 1568)\n",
        "(18194, 1568)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 1.  1.  1. ...,  0.  0.  0.]\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "joint = X_whole[-3]\n",
      "print 'label', y_whole[-3]\n",
      "imageA = joint[0: 784]\n",
      "imageB = joint[784: ]\n",
      "pylab.imshow(imageA.reshape(28, 28), cmap=\"Greys\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n",
        "label 0.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "<matplotlib.image.AxesImage at 0xa20a290>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD5CAYAAAADZljUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neEFwECJ4QXAQInhBcBAieEFwEP8fQYEzZYQsJQgAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x9c82450>"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pylab.imshow(imageB.reshape(28, 28), cmap=\"Greys\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "<matplotlib.image.AxesImage at 0x6fe5610>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD5CAYAAAADZljUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEFzE/wfJAgRc1QT2HAAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0xa427f50>"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def performance_score(target_label, predicted_label, with_auc_score = False, print_report = True): \n",
      "    \"\"\" get performance matrix for prediction\n",
      "        Attributes:\n",
      "            target_label: int 0, 1\n",
      "            predicted_label: 0, 1 or ranking\n",
      "            with_auc_score: bool if False, predicted_label is from 0, 1. If Ture, predicted_label is ranked, need to get AUC score.\n",
      "            print_report: if True, print the perfromannce on screen\n",
      "    \"\"\"\n",
      "    import sklearn\n",
      "    from sklearn.metrics import roc_auc_score\n",
      "    score = {}\n",
      "    if with_auc_score == False:\n",
      "        score['accuracy'] = sklearn.metrics.accuracy_score(target_label, predicted_label)\n",
      "        score['precision'] = sklearn.metrics.precision_score(target_label, predicted_label, pos_label=1)\n",
      "        score['recall'] = sklearn.metrics.recall_score(target_label, predicted_label, pos_label=1)\n",
      "    if with_auc_score == True:\n",
      "        auc_score  = roc_auc_score(target_label, predicted_label)\n",
      "        score['auc_score'] = auc_score\n",
      "        target_label = [x >= 0.5 for x in target_label]\n",
      "        score['accuracy'] = sklearn.metrics.accuracy_score(target_label, predicted_label)\n",
      "        score['precision'] = sklearn.metrics.precision_score(target_label, predicted_label, pos_label=1)\n",
      "        score['recall'] = sklearn.metrics.recall_score(target_label, predicted_label, pos_label=1)\n",
      "    if print_report == True:\n",
      "        for key, value in score.iteritems():\n",
      "            print key, '{percent:.1%}'.format(percent=value)\n",
      "    return score\n",
      "def saveAsCsv(with_auc_score, fname, score_dict, arguments): #new\n",
      "    newfile = False\n",
      "    if os.path.isfile('report_' + fname + '.csv'):\n",
      "        pass\n",
      "    else:\n",
      "        newfile = True\n",
      "    csvfile = open('report_' + fname + '.csv', 'a+')\n",
      "    writer = csv.writer(csvfile)\n",
      "    if newfile == True:\n",
      "        if with_auc_score == False:\n",
      "            writer.writerow(['no.',  'method', 'isTest']+ score_dict.keys()) #, 'AUC'])\n",
      "        else:\n",
      "            writer.writerow(['no.',  'method', 'isTest'] + score_dict.keys())\n",
      "    for arg in arguments:        \n",
      "        writer.writerow([i for i in arg])\n",
      "    csvfile.close()\n",
      "def run_models(settings = None):\n",
      "    analysis_scr = []\n",
      "    with_auc_score = settings['with_auc_score']\n",
      "\n",
      "    for subset_no in xrange(1,settings['number_iterations']+1):\n",
      "        print(\"Subset:\", subset_no)\n",
      "        \n",
      "        ################## generate data ###################\n",
      "        array_A =[]\n",
      "        array_B =[]\n",
      "        for i in range(100000):\n",
      "            array_A.append(np.random.random_integers(0, 59999))\n",
      "            array_B.append(np.random.random_integers(0, 59999))\n",
      "        pos_index = []\n",
      "        neg_index = []\n",
      "        for index in xrange(100000):\n",
      "            if y_total[array_A[index]] - y_total[array_B[index]] == 1:\n",
      "                pos_index.append(index)\n",
      "            else:\n",
      "                neg_index.append(index)\n",
      "        print 'number of positive examples', len(pos_index)\n",
      "        selected_neg_index= neg_index[ : len(pos_index)]    \n",
      "        \n",
      "        array_A = np.array(array_A)\n",
      "        array_B = np.array(array_B)\n",
      "        index_for_positive_image_A = array_A[pos_index]\n",
      "        index_for_positive_image_B = array_B[pos_index]\n",
      "        index_for_neg_image_A = array_A[selected_neg_index]\n",
      "        index_for_neg_image_B = array_B[selected_neg_index]\n",
      "\n",
      "        X_pos_A = X_total[index_for_positive_image_A]\n",
      "        X_pos_B = X_total[index_for_positive_image_B]\n",
      "        X_pos_whole = np.hstack((X_pos_A,X_pos_B))\n",
      "        X_neg_A = X_total[index_for_neg_image_A]\n",
      "        X_neg_B = X_total[index_for_neg_image_B]\n",
      "        X_neg_whole = np.hstack((X_neg_A, X_neg_B))\n",
      "        print X_pos_A.shape,  X_pos_B.shape, X_pos_whole.shape\n",
      "        print X_neg_A.shape,  X_neg_B.shape, X_neg_whole.shape\n",
      "\n",
      "        X_whole = np.vstack((X_pos_whole, X_neg_whole))\n",
      "        print X_whole.shape\n",
      "        y_pos = np.ones(X_pos_whole.shape[0])\n",
      "        y_neg = np.zeros(X_neg_whole.shape[0])\n",
      "        y_whole = np.concatenate([y_pos,y_neg])\n",
      "        print y_whole\n",
      "        \n",
      "        x_train_pre_validation_minmax, x_test_minmax, y_train_pre_validation_minmax, y_test_minmax = train_test_split(X_whole,y_whole,\\\n",
      "                                                            test_size=0.2, random_state=211)\n",
      "        x_train_minmax, x_validation_minmax, y_train_minmax, y_validation_minmax = train_test_split(x_train_pre_validation_minmax,\n",
      "                                                                                                    y_train_pre_validation_minmax,\\\n",
      "                                                                    test_size=0.2, random_state=21)\n",
      "        print x_train_minmax.shape, y_train_minmax.shape, x_validation_minmax.shape, \\\n",
      "        y_validation_minmax.shape, x_test_minmax.shape, y_test_minmax.shape\n",
      "\n",
      "        train_X_reduced = x_train_minmax\n",
      "        train_y_reduced = y_train_minmax\n",
      "        test_X = x_test_minmax\n",
      "        test_y = y_test_minmax\n",
      "        ###original data###\n",
      "        ################ end of data ####################\n",
      "        if settings['SVM']:\n",
      "            print \"SVM\"                   \n",
      "            standard_scaler = preprocessing.StandardScaler().fit(train_X_reduced)\n",
      "            scaled_train_X = standard_scaler.transform(train_X_reduced)\n",
      "            scaled_test_X = standard_scaler.transform(test_X)\n",
      "            Linear_SVC = LinearSVC(C=1, penalty=\"l2\")\n",
      "            Linear_SVC.fit(scaled_train_X, train_y_reduced)\n",
      "            predicted_test_y = Linear_SVC.predict(scaled_test_X)\n",
      "            isTest = True; #new\n",
      "            analysis_scr.append((subset_no,  'SVM', isTest) + tuple(performance_score(test_y, predicted_test_y).values())) #new\n",
      "\n",
      "            predicted_train_y = Linear_SVC.predict(scaled_train_X)\n",
      "            isTest = False; #new\n",
      "            analysis_scr.append(( subset_no, 'SVM', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y).values()))\n",
      "\n",
      "        if settings['SVM_RBF']:\n",
      "            print \"SVM_RBF\"\n",
      "            standard_scaler = preprocessing.StandardScaler().fit(train_X_reduced)\n",
      "            scaled_train_X = standard_scaler.transform(train_X_reduced)\n",
      "            scaled_test_X = standard_scaler.transform(test_X)\n",
      "            L1_SVC_RBF_Selector = SVC(C=1, gamma=0.01, kernel='rbf').fit(scaled_train_X, train_y_reduced)\n",
      "\n",
      "            predicted_test_y = L1_SVC_RBF_Selector.predict(scaled_test_X)\n",
      "            isTest = True; #new\n",
      "            analysis_scr.append((subset_no,  'SVM_RBF', isTest) + tuple(performance_score(test_y, predicted_test_y).values())) #new\n",
      "\n",
      "            predicted_train_y = L1_SVC_RBF_Selector.predict(scaled_train_X)\n",
      "            isTest = False; #new\n",
      "            analysis_scr.append((subset_no,  'SVM_RBF', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y).values()))\n",
      "        if settings['SVM_POLY']:\n",
      "            print \"SVM_POLY\"\n",
      "            standard_scaler = preprocessing.StandardScaler().fit(train_X_reduced)\n",
      "            scaled_train_X = standard_scaler.transform(train_X_reduced)\n",
      "            scaled_test_X = standard_scaler.transform(test_X)\n",
      "            L1_SVC_POLY_Selector = SVC(C=1, kernel='poly').fit(scaled_train_X, train_y_reduced)\n",
      "\n",
      "            predicted_test_y = L1_SVC_POLY_Selector.predict(scaled_test_X)\n",
      "            isTest = True; #new\n",
      "            analysis_scr.append(( subset_no, 'SVM_POLY', isTest) + tuple(performance_score(test_y, predicted_test_y).values())) #new\n",
      "\n",
      "            predicted_train_y = L1_SVC_POLY_Selector.predict(scaled_train_X)\n",
      "            isTest = False; #new\n",
      "            analysis_scr.append((subset_no, 'SVM_POLY', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y).values()))\n",
      "        \n",
      "        if settings['Log']:\n",
      "            print \"Log\"\n",
      "            standard_scaler = preprocessing.StandardScaler().fit(train_X_reduced)\n",
      "            scaled_train_X = standard_scaler.transform(train_X_reduced)\n",
      "            scaled_test_X = standard_scaler.transform(test_X)\n",
      "            \n",
      "            log_clf_l2 = sklearn.linear_model.LogisticRegression(C=1, penalty='l2' )\n",
      "            log_clf_l2.fit(scaled_train_X, train_y_reduced)\n",
      "\n",
      "            predicted_test_y = log_clf_l2.predict(scaled_test_X)\n",
      "            isTest = True; #new\n",
      "            analysis_scr.append((subset_no, 'Log', isTest) + tuple(performance_score(test_y, predicted_test_y).values())) #new\n",
      "\n",
      "            predicted_train_y = log_clf_l2.predict(scaled_train_X)\n",
      "            isTest = False; #new\n",
      "            analysis_scr.append((subset_no, 'Log', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y).values()))        \n",
      "        \n",
      "        # direct deep learning \n",
      "\n",
      "        finetune_lr = settings['finetune_lr']\n",
      "        batch_size = settings['batch_size']\n",
      "        pretraining_epochs = cal_epochs(settings['pretraining_interations'], x_train_minmax, batch_size = batch_size)\n",
      "        #pretrain_lr=0.001\n",
      "        pretrain_lr = settings['pretrain_lr']\n",
      "        training_epochs = settings['training_epochs']\n",
      "        hidden_layers_sizes = settings['hidden_layers_sizes']\n",
      "        corruption_levels = settings['corruption_levels']\n",
      "\n",
      "\n",
      "        if settings['DL']:\n",
      "            print \"direct deep learning\"\n",
      "            sda = trainSda(x_train_minmax, y_train_minmax,\n",
      "                         x_validation_minmax, y_validation_minmax , \n",
      "                         x_test_minmax, test_y,\n",
      "                         hidden_layers_sizes = hidden_layers_sizes, corruption_levels = corruption_levels, batch_size = batch_size , \\\n",
      "                         training_epochs = training_epochs, pretraining_epochs = pretraining_epochs, \n",
      "                         pretrain_lr = pretrain_lr, finetune_lr=finetune_lr\n",
      "             )\n",
      "            print 'hidden_layers_sizes:', hidden_layers_sizes\n",
      "            print 'corruption_levels:', corruption_levels\n",
      "            \n",
      "            test_predicted = sda.predict(x_test_minmax)\n",
      "            y_test = test_y\n",
      "            isTest = True; #new\n",
      "            analysis_scr.append((subset_no, 'DL', isTest) + tuple(performance_score(y_test, test_predicted).values()))\n",
      "            \n",
      "            training_predicted = sda.predict(x_train_minmax)\n",
      "            y_train = y_train_minmax\n",
      "            isTest = False; #new\n",
      "            analysis_scr.append((subset_no, 'DL', isTest) + tuple(performance_score(y_train, training_predicted).values()))\n",
      "            \n",
      "        ####transformed original data####    \n",
      "        x = train_X_reduced\n",
      "        a_MAE_A = train_a_MultipleAEs(x, pretraining_epochs=pretraining_epochs, pretrain_lr=pretrain_lr, batch_size=batch_size, \n",
      "                                hidden_layers_sizes =hidden_layers_sizes, corruption_levels=corruption_levels)\n",
      "        new_x_train_minmax_A =  a_MAE_A.transform(train_X_reduced)\n",
      "        new_x_test_minmax_A =  a_MAE_A.transform(x_test_minmax)            \n",
      "            \n",
      "        if settings['SAE_SVM']: \n",
      "            # SAE_SVM\n",
      "            print 'SAE followed by SVM'\n",
      "\n",
      "            Linear_SVC = LinearSVC(C=1, penalty=\"l2\")\n",
      "            Linear_SVC.fit(new_x_train_minmax_A, train_y_reduced)\n",
      "            predicted_test_y = Linear_SVC.predict(new_x_test_minmax_A)\n",
      "            isTest = True; #new\n",
      "            analysis_scr.append(( subset_no, 'SAE_SVM', isTest) + tuple(performance_score(test_y, predicted_test_y).values())) #new\n",
      "\n",
      "            predicted_train_y = Linear_SVC.predict(new_x_train_minmax_A)\n",
      "            isTest = False; #new\n",
      "            analysis_scr.append(( subset_no, 'SAE_SVM', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y).values()))\n",
      "        if settings['SAE_SVM_RBF']: \n",
      "            # SAE_SVM\n",
      "            print 'SAE followed by SVM RBF'\n",
      "            L1_SVC_RBF_Selector = SVC(C=1, gamma=0.01, kernel='rbf').fit(new_x_train_minmax_A, train_y_reduced)\n",
      "\n",
      "            predicted_test_y = L1_SVC_RBF_Selector.predict(new_x_test_minmax_A)\n",
      "            isTest = True; #new\n",
      "            analysis_scr.append((subset_no,  'SAE_SVM_RBF', isTest) + tuple(performance_score(test_y, predicted_test_y).values())) #new\n",
      "\n",
      "            predicted_train_y = L1_SVC_RBF_Selector.predict(new_x_train_minmax_A)\n",
      "            isTest = False; #new\n",
      "            analysis_scr.append((subset_no,  'SAE_SVM_RBF', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y).values()))\n",
      "        if settings['SAE_SVM_POLY']: \n",
      "            # SAE_SVM\n",
      "            print 'SAE followed by SVM POLY'\n",
      "            L1_SVC_RBF_Selector = SVC(C=1, kernel='poly').fit(new_x_train_minmax_A, train_y_reduced)\n",
      "\n",
      "            predicted_test_y = L1_SVC_RBF_Selector.predict(new_x_test_minmax_A)\n",
      "            isTest = True; #new\n",
      "            analysis_scr.append((subset_no,  'SAE_SVM_POLY', isTest) + tuple(performance_score(test_y, predicted_test_y).values())) #new\n",
      "\n",
      "            predicted_train_y = L1_SVC_RBF_Selector.predict(new_x_train_minmax_A)\n",
      "            isTest = False; #new\n",
      "            analysis_scr.append((subset_no,  'SAE_SVM_POLY', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y).values()))\n",
      "\n",
      "        #### separated transformed data ####\n",
      "        y_test = test_y\n",
      "        print 'deep learning using split network'\n",
      "        # get the new representation for A set. first 784-D\n",
      "        pretraining_epochs = cal_epochs(settings['pretraining_interations'], x_train_minmax, batch_size = batch_size)\n",
      "\n",
      "        x = x_train_minmax[:, :x_train_minmax.shape[1]/2]\n",
      "        print \"original shape for A\", x.shape\n",
      "        a_MAE_A = train_a_MultipleAEs(x, pretraining_epochs=pretraining_epochs, pretrain_lr=pretrain_lr, batch_size=batch_size, \n",
      "                                hidden_layers_sizes = [x/2 for x in hidden_layers_sizes], corruption_levels=corruption_levels)\n",
      "        new_x_train_minmax_A =  a_MAE_A.transform(x_train_minmax[:, :x_train_minmax.shape[1]/2])\n",
      "        x = x_train_minmax[:, x_train_minmax.shape[1]/2:]\n",
      "\n",
      "        print \"original shape for B\", x.shape\n",
      "        a_MAE_B = train_a_MultipleAEs(x, pretraining_epochs=pretraining_epochs, pretrain_lr=pretrain_lr, batch_size=batch_size, \n",
      "                                hidden_layers_sizes = [x/2 for x in hidden_layers_sizes], corruption_levels=corruption_levels)\n",
      "        new_x_train_minmax_B =  a_MAE_B.transform(x_train_minmax[:, x_train_minmax.shape[1]/2:])\n",
      "\n",
      "        new_x_test_minmax_A = a_MAE_A.transform(x_test_minmax[:, :x_test_minmax.shape[1]/2])\n",
      "        new_x_test_minmax_B = a_MAE_B.transform(x_test_minmax[:, x_test_minmax.shape[1]/2:])\n",
      "        new_x_validation_minmax_A = a_MAE_A.transform(x_validation_minmax[:, :x_validation_minmax.shape[1]/2])\n",
      "        new_x_validation_minmax_B = a_MAE_B.transform(x_validation_minmax[:, x_validation_minmax.shape[1]/2:])\n",
      "        new_x_train_minmax_whole = np.hstack((new_x_train_minmax_A, new_x_train_minmax_B))\n",
      "        new_x_test_minmax_whole = np.hstack((new_x_test_minmax_A, new_x_test_minmax_B))\n",
      "        new_x_validationt_minmax_whole = np.hstack((new_x_validation_minmax_A, new_x_validation_minmax_B))        \n",
      "        if settings['DL_S']:\n",
      "            # deep learning using split network\n",
      "            sda_transformed = trainSda(new_x_train_minmax_whole, y_train_minmax,\n",
      "                 new_x_validationt_minmax_whole, y_validation_minmax , \n",
      "                 new_x_test_minmax_whole, y_test,\n",
      "                 hidden_layers_sizes = hidden_layers_sizes, corruption_levels = corruption_levels, batch_size = batch_size , \\\n",
      "                 training_epochs = training_epochs, pretraining_epochs = pretraining_epochs, \n",
      "                 pretrain_lr = pretrain_lr, finetune_lr=finetune_lr\n",
      "                 )\n",
      "            print 'hidden_layers_sizes:', hidden_layers_sizes\n",
      "            print 'corruption_levels:', corruption_levels\n",
      "            \n",
      "            test_predicted = sda_transformed.predict(new_x_test_minmax_whole)\n",
      "            y_test = test_y\n",
      "            isTest = True; #new\n",
      "            analysis_scr.append((subset_no, 'DL_S', isTest) + tuple(performance_score(y_test, test_predicted, with_auc_score).values()))\n",
      "\n",
      "            training_predicted = sda_transformed.predict(new_x_train_minmax_whole)\n",
      "            y_train = y_train_minmax\n",
      "            isTest = False; #new\n",
      "            analysis_scr.append((subset_no, 'DL_S', isTest) + tuple(performance_score(y_train, training_predicted, with_auc_score).values()))\n",
      "        if settings['SAE_S_SVM']:\n",
      "            print 'SAE_S followed by SVM'\n",
      "\n",
      "            Linear_SVC = LinearSVC(C=1, penalty=\"l2\")\n",
      "            Linear_SVC.fit(new_x_train_minmax_whole, train_y_reduced)\n",
      "            predicted_test_y = Linear_SVC.predict(new_x_test_minmax_whole)\n",
      "            isTest = True; #new\n",
      "            analysis_scr.append(( subset_no, 'SAE_S_SVM', isTest) + tuple(performance_score(test_y, predicted_test_y, with_auc_score).values())) #new\n",
      "\n",
      "            predicted_train_y = Linear_SVC.predict(new_x_train_minmax_whole)\n",
      "            isTest = False; #new\n",
      "            analysis_scr.append(( subset_no, 'SAE_S_SVM', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y, with_auc_score).values()))\n",
      "        if settings['SAE_S_SVM_RBF']: \n",
      "            print 'SAE S followed by SVM RBF'\n",
      "            L1_SVC_RBF_Selector = SVC(C=1, gamma=0.01, kernel='rbf').fit(new_x_train_minmax_whole, train_y_reduced)\n",
      "\n",
      "            predicted_test_y = L1_SVC_RBF_Selector.predict(new_x_test_minmax_whole)\n",
      "            isTest = True; #new\n",
      "            analysis_scr.append((subset_no,  'SAE_S_SVM_RBF', isTest) + tuple(performance_score(test_y, predicted_test_y, with_auc_score).values())) #new\n",
      "\n",
      "            predicted_train_y = L1_SVC_RBF_Selector.predict(new_x_train_minmax_whole)\n",
      "            isTest = False; #new\n",
      "            analysis_scr.append((subset_no,  'SAE_S_SVM_RBF', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y, with_auc_score).values()))\n",
      "        if settings['SAE_S_SVM_POLY']: \n",
      "            # SAE_SVM\n",
      "            print 'SAE S followed by SVM POLY'\n",
      "            L1_SVC_RBF_Selector = SVC(C=1, kernel='poly').fit(new_x_train_minmax_whole, train_y_reduced)\n",
      "\n",
      "            predicted_test_y = L1_SVC_RBF_Selector.predict(new_x_test_minmax_whole)\n",
      "            isTest = True; #new\n",
      "            analysis_scr.append((subset_no,  'SAE_S_SVM_POLY', isTest) + tuple(performance_score(test_y, predicted_test_y, with_auc_score).values())) #new\n",
      "\n",
      "            predicted_train_y = L1_SVC_RBF_Selector.predict(new_x_train_minmax_whole)\n",
      "            isTest = False; #new\n",
      "            analysis_scr.append((subset_no,  'SAE_S_SVM_POLY', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y, with_auc_score).values()))\n",
      "     \n",
      "    report_name = 'DL_handwritten_digits' + '_size_'.join(map(str, hidden_layers_sizes)) + \\\n",
      "                    '_' + str(pretrain_lr) + '_' + str(finetune_lr) + '_' + \\\n",
      "            '_' + str(training_epochs) + '_' + current_date\n",
      "    saveAsCsv(with_auc_score, report_name, performance_score(test_y, predicted_test_y, with_auc_score), analysis_scr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_models(settings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Subset:', 1)\n",
        "number of positive examples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9130\n",
        "(9130L, 784L)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (9130L, 784L) (9130L, 1568L)\n",
        "(9130L, 784L) (9130L, 784L) (9130L, 1568L)\n",
        "(18260L, 1568L)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 1.  1.  1. ...,  0.  0.  0.]\n",
        "(11686L, 1568L)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (11686L,) (2922L, 1568L) (2922L,) (3652L, 1568L) (3652L,)\n",
        "... building the model\n",
        "... getting the pretraining functions\n",
        "... pre-training the model"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "SAE followed by SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "recall"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 64.3%\n",
        "precision 60.4%\n",
        "accuracy 61.6%\n",
        "recall 66.5%\n",
        "precision 63.1%\n",
        "accuracy 63.7%\n",
        "deep learning using split network\n",
        "original shape for A (11686L, 784L)\n",
        "... building the model\n",
        "... getting the pretraining functions\n",
        "... pre-training the model"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "original shape for B"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (11686L, 784L)\n",
        "... building the model\n",
        "... getting the pretraining functions\n",
        "... pre-training the model"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "recall"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 64.3%\n",
        "precision 60.4%\n",
        "accuracy 61.6%\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = logging._handlers.copy()\n",
      "for i in x:\n",
      "    log.removeHandler(i)\n",
      "    i.flush()\n",
      "    i.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}