{
 "metadata": {
  "name": "",
  "signature": "sha256:b46992c78b2d2f844863784bfe0af0065988302f8042451354f017e4696e1a46"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"This tutorial introduces Contractive auto-encoders (cA) using Theano.\n",
      "\n",
      " They are based on auto-encoders as the ones used in Bengio et\n",
      " al. 2007.  An autoencoder takes an input x and first maps it to a\n",
      " hidden representation y = f_{\\theta}(x) = s(Wx+b), parameterized by\n",
      " \\theta={W,b}. The resulting latent representation y is then mapped\n",
      " back to a \"reconstructed\" vector z \\in [0,1]^d in input space z =\n",
      " g_{\\theta'}(y) = s(W'y + b').  The weight matrix W' can optionally be\n",
      " constrained such that W' = W^T, in which case the autoencoder is said\n",
      " to have tied weights. The network is trained such that to minimize\n",
      " the reconstruction error (the error between x and z).  Adding the\n",
      " squared Frobenius norm of the Jacobian of the hidden mapping h with\n",
      " respect to the visible units yields the contractive auto-encoder:\n",
      "\n",
      "      - \\sum_{k=1}^d[ x_k \\log z_k + (1-x_k) \\log( 1-z_k)]  + \\| \\frac{\\partial h(x)}{\\partial x} \\|^2\n",
      "\n",
      " References :\n",
      "   - S. Rifai, P. Vincent, X. Muller, X. Glorot, Y. Bengio: Contractive\n",
      "   Auto-Encoders: Explicit Invariance During Feature Extraction, ICML-11\n",
      "\n",
      "   - S. Rifai, X. Muller, X. Glorot, G. Mesnil, Y. Bengio, and Pascal\n",
      "     Vincent. Learning invariant features through local space\n",
      "     contraction. Technical Report 1360, Universite de Montreal\n",
      "\n",
      "   - Y. Bengio, P. Lamblin, D. Popovici, H. Larochelle: Greedy Layer-Wise\n",
      "   Training of Deep Networks, Advances in Neural Information Processing\n",
      "   Systems 19, 2007\n",
      "\n",
      "\"\"\"\n",
      "import math\n",
      "import cPickle\n",
      "import gzip\n",
      "import os\n",
      "import sys\n",
      "import time\n",
      "sys.path.append('../../../libs/')\n",
      "import csv\n",
      "from dateutil import parser\n",
      "from datetime import timedelta\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import pickle\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn import preprocessing\n",
      "import sklearn\n",
      "import scipy.stats as ss\n",
      "import cPickle\n",
      "import gzip\n",
      "import os\n",
      "import time\n",
      "import numpy\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "from theano.tensor.shared_randomstreams import RandomStreams\n",
      "import os.path\n",
      "import IO_class\n",
      "from IO_class import FileOperator\n",
      "from sklearn import cross_validation\n",
      "import sklearn\n",
      "import numpy as np\n",
      "import csv\n",
      "from dateutil import parser\n",
      "from datetime import timedelta\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import pdb\n",
      "import pickle\n",
      "import numpy as np\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.cross_validation import KFold\n",
      "from sklearn import preprocessing\n",
      "import sklearn\n",
      "import scipy.stats as ss\n",
      "\n",
      "import random\n",
      "from DL_libs import *\n",
      "from itertools import izip #new\n",
      "import math\n",
      "import cPickle\n",
      "import gzip\n",
      "import os\n",
      "import sys\n",
      "import time\n",
      "\n",
      "import numpy\n",
      "\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "\n",
      "\n",
      "from logistic_sgd import load_data\n",
      "from utils import tile_raster_images\n",
      "\n",
      "import PIL.Image\n",
      "\n",
      "\n",
      "class cA(object):\n",
      "    \"\"\" Contractive Auto-Encoder class (cA)\n",
      "\n",
      "    The contractive autoencoder tries to reconstruct the input with an\n",
      "    additional constraint on the latent space. With the objective of\n",
      "    obtaining a robust representation of the input space, we\n",
      "    regularize the L2 norm(Froebenius) of the jacobian of the hidden\n",
      "    representation with respect to the input. Please refer to Rifai et\n",
      "    al.,2011 for more details.\n",
      "\n",
      "    If x is the input then equation (1) computes the projection of the\n",
      "    input into the latent space h. Equation (2) computes the jacobian\n",
      "    of h with respect to x.  Equation (3) computes the reconstruction\n",
      "    of the input, while equation (4) computes the reconstruction\n",
      "    error and the added regularization term from Eq.(2).\n",
      "\n",
      "    .. math::\n",
      "\n",
      "        h_i = s(W_i x + b_i)                                             (1)\n",
      "\n",
      "        J_i = h_i (1 - h_i) * W_i                                        (2)\n",
      "\n",
      "        x' = s(W' h  + b')                                               (3)\n",
      "\n",
      "        L = -sum_{k=1}^d [x_k \\log x'_k + (1-x_k) \\log( 1-x'_k)]\n",
      "             + lambda * sum_{i=1}^d sum_{j=1}^n J_{ij}^2                 (4)\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, numpy_rng, input=None, n_visible=784, n_hidden=100,\n",
      "                 n_batchsize=1, W=None, bhid=None, bvis=None):\n",
      "        \"\"\"Initialize the cA class by specifying the number of visible units (the\n",
      "        dimension d of the input ), the number of hidden units ( the dimension\n",
      "        d' of the latent or hidden space ) and the contraction level. The\n",
      "        constructor also receives symbolic variables for the input, weights and\n",
      "        bias.\n",
      "\n",
      "        :type numpy_rng: numpy.random.RandomState\n",
      "        :param numpy_rng: number random generator used to generate weights\n",
      "\n",
      "        :type theano_rng: theano.tensor.shared_randomstreams.RandomStreams\n",
      "        :param theano_rng: Theano random generator; if None is given\n",
      "                     one is generated based on a seed drawn from `rng`\n",
      "\n",
      "        :type input: theano.tensor.TensorType\n",
      "        :param input: a symbolic description of the input or None for\n",
      "                      standalone cA\n",
      "\n",
      "        :type n_visible: int\n",
      "        :param n_visible: number of visible units\n",
      "\n",
      "        :type n_hidden: int\n",
      "        :param n_hidden:  number of hidden units\n",
      "\n",
      "        :type n_batchsize int\n",
      "        :param n_batchsize: number of examples per batch\n",
      "\n",
      "        :type W: theano.tensor.TensorType\n",
      "        :param W: Theano variable pointing to a set of weights that should be\n",
      "                  shared belong the dA and another architecture; if dA should\n",
      "                  be standalone set this to None\n",
      "\n",
      "        :type bhid: theano.tensor.TensorType\n",
      "        :param bhid: Theano variable pointing to a set of biases values (for\n",
      "                     hidden units) that should be shared belong dA and another\n",
      "                     architecture; if dA should be standalone set this to None\n",
      "\n",
      "        :type bvis: theano.tensor.TensorType\n",
      "        :param bvis: Theano variable pointing to a set of biases values (for\n",
      "                     visible units) that should be shared belong dA and another\n",
      "                     architecture; if dA should be standalone set this to None\n",
      "\n",
      "        \"\"\"\n",
      "        self.n_visible = n_visible\n",
      "        self.n_hidden = n_hidden\n",
      "        self.n_batchsize = n_batchsize\n",
      "        # note : W' was written as `W_prime` and b' as `b_prime`\n",
      "        if not W:\n",
      "            # W is initialized with `initial_W` which is uniformely sampled\n",
      "            # from -4*sqrt(6./(n_visible+n_hidden)) and\n",
      "            # 4*sqrt(6./(n_hidden+n_visible))the output of uniform if\n",
      "            # converted using asarray to dtype\n",
      "            # theano.config.floatX so that the code is runable on GPU\n",
      "            initial_W = numpy.asarray(numpy_rng.uniform(\n",
      "                      low=-4 * numpy.sqrt(6. / (n_hidden + n_visible)),\n",
      "                      high=4 * numpy.sqrt(6. / (n_hidden + n_visible)),\n",
      "                      size=(n_visible, n_hidden)),\n",
      "                                      dtype=theano.config.floatX)\n",
      "            W = theano.shared(value=initial_W, name='W', borrow=True)\n",
      "\n",
      "        if not bvis:\n",
      "            bvis = theano.shared(value=numpy.zeros(n_visible,\n",
      "                                                   dtype=theano.config.floatX),\n",
      "                                 borrow=True)\n",
      "\n",
      "        if not bhid:\n",
      "            bhid = theano.shared(value=numpy.zeros(n_hidden,\n",
      "                                                   dtype=theano.config.floatX),\n",
      "                                 name='b',\n",
      "                                 borrow=True)\n",
      "\n",
      "        self.W = W\n",
      "        # b corresponds to the bias of the hidden\n",
      "        self.b = bhid\n",
      "        # b_prime corresponds to the bias of the visible\n",
      "        self.b_prime = bvis\n",
      "        # tied weights, therefore W_prime is W transpose\n",
      "        self.W_prime = self.W.T\n",
      "\n",
      "        # if no input is given, generate a variable representing the input\n",
      "        if input == None:\n",
      "            # we use a matrix because we expect a minibatch of several\n",
      "            # examples, each example being a row\n",
      "            self.x = T.dmatrix(name='input')\n",
      "        else:\n",
      "            self.x = input\n",
      "\n",
      "        self.params = [self.W, self.b, self.b_prime]\n",
      "\n",
      "    def get_hidden_values(self, input):\n",
      "        \"\"\" Computes the values of the hidden layer \"\"\"\n",
      "        return T.nnet.sigmoid(T.dot(input, self.W) + self.b)\n",
      "\n",
      "    def get_jacobian(self, hidden, W):\n",
      "        \"\"\"Computes the jacobian of the hidden layer with respect to\n",
      "        the input, reshapes are necessary for broadcasting the\n",
      "        element-wise product on the right axis\n",
      "\n",
      "        \"\"\"\n",
      "        return T.reshape(hidden * (1 - hidden),\n",
      "                         (self.n_batchsize, 1, self.n_hidden)) * T.reshape(\n",
      "                             W, (1, self.n_visible, self.n_hidden))\n",
      "\n",
      "    def get_reconstructed_input(self, hidden):\n",
      "        \"\"\"Computes the reconstructed input given the values of the\n",
      "        hidden layer\n",
      "\n",
      "        \"\"\"\n",
      "        return  T.nnet.sigmoid(T.dot(hidden, self.W_prime) + self.b_prime)\n",
      "\n",
      "    def get_cost_updates(self, contraction_level, learning_rate):\n",
      "        \"\"\" This function computes the cost and the updates for one trainng\n",
      "        step of the cA \"\"\"\n",
      "\n",
      "        y = self.get_hidden_values(self.x)\n",
      "        z = self.get_reconstructed_input(y)\n",
      "        J = self.get_jacobian(y, self.W)\n",
      "        # note : we sum over the size of a datapoint; if we are using\n",
      "        #        minibatches, L will be a vector, with one entry per\n",
      "        #        example in minibatch\n",
      "        self.L_rec = - T.sum(self.x * T.log(z) +\n",
      "                             (1 - self.x) * T.log(1 - z),\n",
      "                             axis=1)\n",
      "\n",
      "        # Compute the jacobian and average over the number of samples/minibatch\n",
      "        self.L_jacob = T.sum(J ** 2) / self.n_batchsize\n",
      "\n",
      "        # note : L is now a vector, where each element is the\n",
      "        #        cross-entropy cost of the reconstruction of the\n",
      "        #        corresponding example of the minibatch. We need to\n",
      "        #        compute the average of all these to get the cost of\n",
      "        #        the minibatch\n",
      "        cost = T.mean(self.L_rec) + contraction_level * T.mean(self.L_jacob)\n",
      "\n",
      "        # compute the gradients of the cost of the `cA` with respect\n",
      "        # to its parameters\n",
      "        gparams = T.grad(cost, self.params)\n",
      "        # generate the list of updates\n",
      "        updates = []\n",
      "        for param, gparam in zip(self.params, gparams):\n",
      "            updates.append((param, param - learning_rate * gparam))\n",
      "\n",
      "        return (cost, updates)\n",
      "\n",
      "\n",
      "def test_cA(learning_rate=0.01, training_epochs=20,\n",
      "            dataset='mnist.pkl.gz',\n",
      "            batch_size=10, output_folder='cA_plots', contraction_level=.1):\n",
      "    \"\"\"\n",
      "    This demo is tested on MNIST\n",
      "\n",
      "    :type learning_rate: float\n",
      "    :param learning_rate: learning rate used for training the contracting\n",
      "                          AutoEncoder\n",
      "\n",
      "    :type training_epochs: int\n",
      "    :param training_epochs: number of epochs used for training\n",
      "\n",
      "    :type dataset: string\n",
      "    :param dataset: path to the picked dataset\n",
      "\n",
      "    \"\"\"\n",
      "    f = gzip.open('mnist.pkl.gz', 'rb')\n",
      "    train_set, valid_set, test_set = cPickle.load(f)\n",
      "    \n",
      "    train_set_x, train_set_y = train_set\n",
      "    train_set_x = shared_dataset_X(train_set_x)\n",
      "    train_set_y= shared_dataset_X(train_set_y)\n",
      "    # compute number of minibatches for training, validation and testing\n",
      "    n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
      "\n",
      "    # allocate symbolic variables for the data\n",
      "    index = T.lscalar()    # index to a [mini]batch\n",
      "    x = T.matrix('x')  # the data is presented as rasterized images\n",
      "\n",
      "    if not os.path.isdir(output_folder):\n",
      "        os.makedirs(output_folder)\n",
      "    os.chdir(output_folder)\n",
      "    ####################################\n",
      "    #        BUILDING THE MODEL        #\n",
      "    ####################################\n",
      "\n",
      "    rng = numpy.random.RandomState(123)\n",
      "\n",
      "    ca = cA(numpy_rng=rng, input=x,\n",
      "            n_visible=28 * 28, n_hidden=500, n_batchsize=batch_size)\n",
      "\n",
      "    cost, updates = ca.get_cost_updates(contraction_level=contraction_level,\n",
      "                                        learning_rate=learning_rate)\n",
      "\n",
      "    train_ca = theano.function([index], [T.mean(ca.L_rec), ca.L_jacob],\n",
      "                               updates=updates,\n",
      "                               givens={x: train_set_x[index * batch_size:\n",
      "                                                    (index + 1) * batch_size]})\n",
      "\n",
      "    start_time = time.clock()\n",
      "\n",
      "    ############\n",
      "    # TRAINING #\n",
      "    ############\n",
      "\n",
      "    # go through training epochs\n",
      "    for epoch in xrange(training_epochs):\n",
      "        # go through trainng set\n",
      "        c = []\n",
      "        for batch_index in xrange(n_train_batches):\n",
      "            c.append(train_ca(batch_index))\n",
      "\n",
      "        c_array = numpy.vstack(c)\n",
      "        print 'Training epoch %d, reconstruction cost ' % epoch, numpy.mean(\n",
      "            c_array[0]), ' jacobian norm ', numpy.mean(numpy.sqrt(c_array[1]))\n",
      "\n",
      "    end_time = time.clock()\n",
      "\n",
      "    training_time = (end_time - start_time)\n",
      "\n",
      "    print >> sys.stderr, ('The code for file ' + os.path.split(__file__)[1] +\n",
      "                          ' ran for %.2fm' % ((training_time) / 60.))\n",
      "    image = PIL.Image.fromarray(tile_raster_images(\n",
      "        X=ca.W.get_value(borrow=True).T,\n",
      "        img_shape=(28, 28), tile_shape=(10, 10),\n",
      "        tile_spacing=(1, 1)))\n",
      "\n",
      "    image.save('cae_filters.png')\n",
      "\n",
      "    os.chdir('../')\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    test_cA()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/scipy/spatial/__init__.py:91: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility\n",
        "  from .qhull import *\n",
        "/usr/local/lib/python2.7/dist-packages/scipy/spatial/__init__.py:91: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from .qhull import *\n",
        "/usr/local/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training epoch 0, reconstruction cost  589.571872577  jacobian norm  20.9938791886\n",
        "Training epoch 1, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 115.13390224  jacobian norm  10.673699659\n",
        "Training epoch 2, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.291018001  jacobian norm  10.134422748\n",
        "Training epoch 3, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 94.220284334  jacobian norm  9.84685383242\n",
        "Training epoch 4, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 89.5890225412  jacobian norm  9.64736166807\n",
        "Training epoch 5, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 86.1490384385  jacobian norm  9.49857669084\n",
        "Training epoch 6, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 83.4664242016  jacobian norm  9.38143172793\n",
        "Training epoch 7, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 81.3512907826  jacobian norm  9.28327421556\n",
        "Training epoch 8, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 79.6482831506  jacobian norm  9.19748922967\n",
        "Training epoch 9, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 78.2066659332  jacobian norm  9.12143982155\n",
        "Training epoch 10, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 76.9456192804  jacobian norm  9.05343287129\n",
        "Training epoch 11, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 75.8435863545  jacobian norm  8.99151663486\n",
        "Training epoch 12, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 74.8999458491  jacobian norm  8.9338049163\n",
        "Training epoch 13, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 74.1060022563  jacobian norm  8.87925367541\n",
        "Training epoch 14, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 73.4415396294  jacobian norm  8.8291852146\n",
        "Training epoch 15, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 72.879630175  jacobian norm  8.78442892358\n",
        "Training epoch 16, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 72.3729563995  jacobian norm  8.74324402838\n",
        "Training epoch 17, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 71.8622392555  jacobian norm  8.70262903409\n",
        "Training epoch 18, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 71.3049790204  jacobian norm  8.66103980493\n",
        "Training epoch 19, reconstruction cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 70.6462751293  jacobian norm  8.61777944201\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "global name '__file__' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-7f6f1c6583c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m     \u001b[0mtest_cA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-1-7f6f1c6583c7>\u001b[0m in \u001b[0;36mtest_cA\u001b[1;34m(learning_rate, training_epochs, dataset, batch_size, output_folder, contraction_level)\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[0mtraining_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m     print >> sys.stderr, ('The code for file ' + os.path.split(__file__)[1] +\n\u001b[0m\u001b[0;32m    346\u001b[0m                           ' ran for %.2fm' % ((training_time) / 60.))\n\u001b[0;32m    347\u001b[0m     image = PIL.Image.fromarray(tile_raster_images(\n",
        "\u001b[1;31mNameError\u001b[0m: global name '__file__' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Solution:\n",
      "    # @param s, a string\n",
      "    # @return a list of strings\n",
      "    def restoreIpAddresses(self, s):\n",
      "        result = []\n",
      "        tmp_items = []\n",
      "        def rec_ip(depth, split_point, tmp_items, result):\n",
      "            print 'tmp_items', depth, split_point, tmp_items\n",
      "            if depth == 4 and split_point ==len(s)+1:\n",
      "                result.append('.'.join(tmp_items))\n",
      "            elif depth < 4 and len(s) - split_point <= (4-depth)*3:\n",
      "                for i in range(1,4):\n",
      "                    digits = s[split_point: split_point+i]\n",
      "#                    print digits\n",
      "                    if len(digits)>0:\n",
      "                        if int(digits) < 256:\n",
      "                            rec_ip(depth+1, split_point+i, tmp_items+[digits], result)\n",
      "        rec_ip(0, 0, tmp_items, result)\n",
      "        return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a= Solution()\n",
      "print a.restoreIpAddresses('111111111111111111111111111111111111111111111111111111111')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tmp_items 0 0 []\n",
        "[]\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = 3\n",
      "n = 4\n",
      "a = [[None]*n]*m\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/dist-packages/nose/plugins/manager.py:405: UserWarning: Module decorator was already imported from /usr/lib/python2.7/dist-packages/decorator.pyc, but /usr/local/lib/python2.7/dist-packages is being added to sys.path\n",
        "  import pkg_resources\n"
       ]
      },
      {
       "ename": "ImportError",
       "evalue": "No module named logistic_sgd",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-32-35223498d41e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlogistic_sgd\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtile_raster_images\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mImportError\u001b[0m: No module named logistic_sgd"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def divide(a, b):\n",
      "\treal = a / b\n",
      "\tremain = a % b\n",
      "\tdecimal = []\n",
      "\tremainders = {}\n",
      "\ti = 0\n",
      "\twhile remain != 0:\n",
      "\t\tif remain not in remainders:\n",
      "\t\t\tremainders[remain] = i\n",
      "\t\telse:\n",
      "\t\t\tdecimal.insert(remainders[remain],'(')\n",
      "\t\t\tbreak\n",
      "\t\tremain *= 10\n",
      "\t\tdigit, remain = divmod(remain, b)\n",
      "\t\tdecimal.append(str(digit))\n",
      "\t\ti += 1\n",
      "\tif remain != 0:\n",
      "\t\tdecimal.append(')')\n",
      "\treturn str(real) + '.' + ''.join(decimal)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "divide(1,7)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 101,
       "text": [
        "'0.(142857)'"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#filename = 'Untitled0.ipynb'\n",
      "def longest_word(filename, lst):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    with open(filename,'r') as file_handle:\n",
      "        long_word = None\n",
      "        lenght = 0\n",
      "        for line in file_handle:\n",
      "            word = line.strip()\n",
      "            if is_construct(word, lst) and len(word) > lenght:\n",
      "                long_word = word\n",
      "                lenght = len(word)\n",
      "        return long_word\n",
      "\n",
      "    \n",
      "def is_construct(word, lst):\n",
      "    \"\"\"\n",
      "    check whether the word can be constructed from the letter in the list\n",
      "    Parameters:\n",
      "        word: string \n",
      "    \"\"\"\n",
      "    result = True\n",
      "    dict_letters = {}\n",
      "    for letter in lst:\n",
      "        dict_letters[letter] = True\n",
      "\n",
      "    for char in word:\n",
      "        if char not in dict_letters:\n",
      "            result =  False\n",
      "            break\n",
      "    return result\n",
      "\n",
      "def test():\n",
      "    filename = 'test.txt'\n",
      "    lst = ['a', 'b', 'c', 'd']\n",
      "    print longest_word(filename, lst)\n",
      "\n",
      "if __name__ == '__main__' :\n",
      "    test()          \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ababab\n"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Node:\n",
      "    def __init__(self, data, next = None):\n",
      "        self.data  =  data\n",
      "        self.next =  next\n",
      "class Queue:\n",
      "    def __init__(self):\n",
      "        self.head = None\n",
      "        self.tail =None\n",
      "    def enqueue(self, item):\n",
      "        if self.head == None:\n",
      "            self.head = Node(item)\n",
      "            self.tail =self.head\n",
      "        else:\n",
      "            self.tail.next = Node(item)\n",
      "            self.tail = self.tail.next\n",
      "    def dequeue(self):\n",
      "        if self.head == None:\n",
      "            pass\n",
      "        else:\n",
      "            item = self.head\n",
      "            self.head = self.head.next\n",
      "            return item"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aq = Queue()\n",
      "aq.enqueue(3)\n",
      "aq.enqueue(5)\n",
      "aq.enqueue(7)\n",
      "print aq.dequeue().data\n",
      "print aq.dequeue().data\n",
      "print aq.dequeue().data\n",
      "print aq.dequeue()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3\n",
        "5\n",
        "7\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def move_tower(height, from_pole, to_pole, with_pole):\n",
      "    if height >=1 :\n",
      "        move_tower(height-1, from_pole, with_pole, to_pole)\n",
      "        move_disk(from_pole, to_pole)\n",
      "        move_tower(height-1, with_pole, to_pole, from_pole)\n",
      "def move_disk(from_pole, to_pole):\n",
      "    print 'move disk from %s to %s' % (from_pole, to_pole)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "move_tower(3, 1,3,2 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "move disk from 1 to 3\n",
        "move disk from 1 to 2\n",
        "move disk from 3 to 2\n",
        "move disk from 1 to 3\n",
        "move disk from 2 to 1\n",
        "move disk from 2 to 3\n",
        "move disk from 1 to 3\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def number_coins(coin_list, change):\n",
      "    min_coins = change\n",
      "    if change in coin_list:\n",
      "        return 1\n",
      "    else:\n",
      "        for coin in [ i for i in coin_list if i < change]:\n",
      "            n_coins = 1 +  number_coins(coin_list, change - coin)\n",
      "            if n_coins < min_coins:\n",
      "                min_coins = n_coins\n",
      "    return min_coins "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def binary_search(lst, item):\n",
      "    if len(lst) == 0:\n",
      "        return False\n",
      "    elif len(lst) == 1:\n",
      "        return True if lst[0] == item else False\n",
      "    else:\n",
      "        mid = len(lst) // 2 \n",
      "        if item < lst[mid]:\n",
      "            return binary_search(lst[ :mid], item)\n",
      "        else:\n",
      "            return binary_search(lst[mid:], item)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = [2,3,4,4,4,4]\n",
      "b = a\n",
      "c = a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "2**3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 116,
       "text": [
        "8"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a =3\n",
      "a = a << 1\n",
      "print int('111', 8)\n",
      "bin(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "73\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 114,
       "text": [
        "'0b110'"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def merge_sort(lst):\n",
      "    if len(lst)<= 1:\n",
      "        return lst\n",
      "    else:\n",
      "        mid = len(lst) // 2\n",
      "        left = mergesort(lst[ :mid])\n",
      "        right  = mergesort(lst[mid: ])\n",
      "        # merge\n",
      "        i_left = 0\n",
      "        i_right = 0\n",
      "        i_lst = 0\n",
      "        while i_left < len(left) and i_right < len(i_right):\n",
      "            if left[i_left] <= right[i_right]:\n",
      "                lst[i_lst] = left[i_left]\n",
      "                i_left +=1\n",
      "                \n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 89,
       "text": [
        "[]"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mstr = \"\"\"hello\n",
      "world\n",
      "\"\"\"\n",
      "um = unicode(mstr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in um:\n",
      "    print ord(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "104\n",
        "101\n",
        "108\n",
        "108\n",
        "111\n",
        "10\n",
        "119\n",
        "111\n",
        "114\n",
        "108\n",
        "100\n",
        "10\n"
       ]
      }
     ],
     "prompt_number": 104
    }
   ],
   "metadata": {}
  }
 ]
}