{
 "metadata": {
  "name": "",
  "signature": "sha256:52eb4a8fe20ccf746e0ccfa1707e477f8955b8ec66144d5afa83e0356d561543"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import packages if you miss any, just install them\n",
      "import csv\n",
      "from dateutil import parser\n",
      "from datetime import timedelta\n",
      "from sklearn import svm\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import pdb\n",
      "import pickle\n",
      "import numpy as np\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn import preprocessing\n",
      "import sklearn\n",
      "import scipy.stats as ss\n",
      "\n",
      "\n",
      "import cPickle\n",
      "import gzip\n",
      "import os\n",
      "import sys\n",
      "import time\n",
      "\n",
      "import numpy\n",
      "\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "from theano.tensor.shared_randomstreams import RandomStreams\n",
      "\n",
      "class dA(object):\n",
      "    \"\"\"Denoising Auto-Encoder class (dA)\n",
      "\n",
      "    A denoising autoencoders tries to reconstruct the input from a corrupted\n",
      "    version of it by projecting it first in a latent space and reprojecting\n",
      "    it afterwards back in the input space. Please refer to Vincent et al.,2008\n",
      "    for more details. If x is the input then equation (1) computes a partially\n",
      "    destroyed version of x by means of a stochastic mapping q_D. Equation (2)\n",
      "    computes the projection of the input into the latent space. Equation (3)\n",
      "    computes the reconstruction of the input, while equation (4) computes the\n",
      "    reconstruction error.\n",
      "\n",
      "    .. math::\n",
      "\n",
      "        \\tilde{x} ~ q_D(\\tilde{x}|x)                                     (1)\n",
      "\n",
      "        y = s(W \\tilde{x} + b)                                           (2)\n",
      "\n",
      "        x = s(W' y  + b')                                                (3)\n",
      "\n",
      "        L(x,z) = -sum_{k=1}^d [x_k \\log z_k + (1-x_k) \\log( 1-z_k)]      (4)\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, numpy_rng, theano_rng=None, input=None,\n",
      "                 n_visible=784, n_hidden=500,\n",
      "                 W=None, bhid=None, bvis=None):\n",
      "        \"\"\"\n",
      "        Initialize the dA class by specifying the number of visible units (the\n",
      "        dimension d of the input ), the number of hidden units ( the dimension\n",
      "        d' of the latent or hidden space ) and the corruption level. The\n",
      "        constructor also receives symbolic variables for the input, weights and\n",
      "        bias. Such a symbolic variables are useful when, for example the input\n",
      "        is the result of some computations, or when weights are shared between\n",
      "        the dA and an MLP layer. When dealing with SdAs this always happens,\n",
      "        the dA on layer 2 gets as input the output of the dA on layer 1,\n",
      "        and the weights of the dA are used in the second stage of training\n",
      "        to construct an MLP.\n",
      "\n",
      "        :type numpy_rng: numpy.random.RandomState\n",
      "        :param numpy_rng: number random generator used to generate weights\n",
      "\n",
      "        :type theano_rng: theano.tensor.shared_randomstreams.RandomStreams\n",
      "        :param theano_rng: Theano random generator; if None is given one is\n",
      "                     generated based on a seed drawn from `rng`\n",
      "\n",
      "        :type input: theano.tensor.TensorType\n",
      "        :param input: a symbolic description of the input or None for\n",
      "                      standalone dA\n",
      "\n",
      "        :type n_visible: int\n",
      "        :param n_visible: number of visible units\n",
      "\n",
      "        :type n_hidden: int\n",
      "        :param n_hidden:  number of hidden units\n",
      "\n",
      "        :type W: theano.tensor.TensorType\n",
      "        :param W: Theano variable pointing to a set of weights that should be\n",
      "                  shared belong the dA and another architecture; if dA should\n",
      "                  be standalone set this to None\n",
      "\n",
      "        :type bhid: theano.tensor.TensorType\n",
      "        :param bhid: Theano variable pointing to a set of biases values (for\n",
      "                     hidden units) that should be shared belong dA and another\n",
      "                     architecture; if dA should be standalone set this to None\n",
      "\n",
      "        :type bvis: theano.tensor.TensorType\n",
      "        :param bvis: Theano variable pointing to a set of biases values (for\n",
      "                     visible units) that should be shared belong dA and another\n",
      "                     architecture; if dA should be standalone set this to None\n",
      "\n",
      "\n",
      "        \"\"\"\n",
      "        self.n_visible = n_visible\n",
      "        self.n_hidden = n_hidden\n",
      "\n",
      "        # create a Theano random generator that gives symbolic random values\n",
      "        if not theano_rng:\n",
      "            theano_rng = RandomStreams(numpy_rng.randint(2 ** 30))\n",
      "\n",
      "        # note : W' was written as `W_prime` and b' as `b_prime`\n",
      "        if not W:\n",
      "            # W is initialized with `initial_W` which is uniformely sampled\n",
      "            # from -4*sqrt(6./(n_visible+n_hidden)) and\n",
      "            # 4*sqrt(6./(n_hidden+n_visible))the output of uniform if\n",
      "            # converted using asarray to dtype\n",
      "            # theano.config.floatX so that the code is runable on GPU\n",
      "            initial_W = numpy.asarray(numpy_rng.uniform(\n",
      "                      low=-4 * numpy.sqrt(6. / (n_hidden + n_visible)),\n",
      "                      high=4 * numpy.sqrt(6. / (n_hidden + n_visible)),\n",
      "                      size=(n_visible, n_hidden)), dtype=theano.config.floatX)\n",
      "            W = theano.shared(value=initial_W, name='W', borrow=True)\n",
      "\n",
      "        if not bvis:\n",
      "            bvis = theano.shared(value=numpy.zeros(n_visible,\n",
      "                                         dtype=theano.config.floatX),\n",
      "                                 borrow=True)\n",
      "\n",
      "        if not bhid:\n",
      "            bhid = theano.shared(value=numpy.zeros(n_hidden,\n",
      "                                                   dtype=theano.config.floatX),\n",
      "                                 name='b',\n",
      "                                 borrow=True)\n",
      "\n",
      "        self.W = W\n",
      "        # b corresponds to the bias of the hidden\n",
      "        self.b = bhid\n",
      "        # b_prime corresponds to the bias of the visible\n",
      "        self.b_prime = bvis\n",
      "        # tied weights, therefore W_prime is W transpose\n",
      "        self.W_prime = self.W.T\n",
      "        self.theano_rng = theano_rng\n",
      "        # if no input is given, generate a variable representing the input\n",
      "        if input == None:\n",
      "            # we use a matrix because we expect a minibatch of several\n",
      "            # examples, each example being a row\n",
      "            self.x = T.dmatrix(name='input')\n",
      "        else:\n",
      "            self.x = input\n",
      "\n",
      "        self.params = [self.W, self.b, self.b_prime]\n",
      "\n",
      "    def get_corrupted_input(self, input, corruption_level):\n",
      "        \"\"\"This function keeps ``1-corruption_level`` entries of the inputs the\n",
      "        same and zero-out randomly selected subset of size ``coruption_level``\n",
      "        Note : first argument of theano.rng.binomial is the shape(size) of\n",
      "               random numbers that it should produce\n",
      "               second argument is the number of trials\n",
      "               third argument is the probability of success of any trial\n",
      "\n",
      "                this will produce an array of 0s and 1s where 1 has a\n",
      "                probability of 1 - ``corruption_level`` and 0 with\n",
      "                ``corruption_level``\n",
      "\n",
      "                The binomial function return int64 data type by\n",
      "                default.  int64 multiplicated by the input\n",
      "                type(floatX) always return float64.  To keep all data\n",
      "                in floatX when floatX is float32, we set the dtype of\n",
      "                the binomial to floatX. As in our case the value of\n",
      "                the binomial is always 0 or 1, this don't change the\n",
      "                result. This is needed to allow the gpu to work\n",
      "                correctly as it only support float32 for now.\n",
      "\n",
      "        \"\"\"\n",
      "        return  self.theano_rng.binomial(size=input.shape, n=1,\n",
      "                                         p=1 - corruption_level,\n",
      "                                         dtype=theano.config.floatX) * input\n",
      "\n",
      "    def get_hidden_values(self, input):\n",
      "        \"\"\" Computes the values of the hidden layer \"\"\"\n",
      "        return T.nnet.sigmoid(T.dot(input, self.W) + self.b)\n",
      "\n",
      "    def get_reconstructed_input(self, hidden):\n",
      "        \"\"\"Computes the reconstructed input given the values of the\n",
      "        hidden layer\n",
      "\n",
      "        \"\"\"\n",
      "        return  T.nnet.sigmoid(T.dot(hidden, self.W_prime) + self.b_prime)\n",
      "\n",
      "    def get_cost_updates(self, corruption_level, learning_rate):\n",
      "        \"\"\" This function computes the cost and the updates for one trainng\n",
      "        step of the dA \"\"\"\n",
      "\n",
      "        tilde_x = self.get_corrupted_input(self.x, corruption_level)\n",
      "        y = self.get_hidden_values(tilde_x)\n",
      "        z = self.get_reconstructed_input(y)\n",
      "        # note : we sum over the size of a datapoint; if we are using\n",
      "        #        minibatches, L will be a vector, with one entry per\n",
      "        #        example in minibatch\n",
      "        L = - T.sum(self.x * T.log(z) + (1 - self.x) * T.log(1 - z), axis=1)\n",
      "        # note : L is now a vector, where each element is the\n",
      "        #        cross-entropy cost of the reconstruction of the\n",
      "        #        corresponding example of the minibatch. We need to\n",
      "        #        compute the average of all these to get the cost of\n",
      "        #        the minibatch\n",
      "        cost = T.mean(L)\n",
      "\n",
      "        # compute the gradients of the cost of the `dA` with respect\n",
      "        # to its parameters\n",
      "        gparams = T.grad(cost, self.params)\n",
      "        # generate the list of updates\n",
      "        updates = []\n",
      "        for param, gparam in zip(self.params, gparams):\n",
      "            updates.append((param, param - learning_rate * gparam))\n",
      "\n",
      "        return (cost, updates)\n",
      "\"\"\"\n",
      " This tutorial introduces stacked denoising auto-encoders (SdA) using Theano.\n",
      "\n",
      " Denoising autoencoders are the building blocks for SdA.\n",
      " They are based on auto-encoders as the ones used in Bengio et al. 2007.\n",
      " An autoencoder takes an input x and first maps it to a hidden representation\n",
      " y = f_{\\theta}(x) = s(Wx+b), parameterized by \\theta={W,b}. The resulting\n",
      " latent representation y is then mapped back to a \"reconstructed\" vector\n",
      " z \\in [0,1]^d in input space z = g_{\\theta'}(y) = s(W'y + b').  The weight\n",
      " matrix W' can optionally be constrained such that W' = W^T, in which case\n",
      " the autoencoder is said to have tied weights. The network is trained such\n",
      " that to minimize the reconstruction error (the error between x and z).\n",
      "\n",
      " For the denosing autoencoder, during training, first x is corrupted into\n",
      " \\tilde{x}, where \\tilde{x} is a partially destroyed version of x by means\n",
      " of a stochastic mapping. Afterwards y is computed as before (using\n",
      " \\tilde{x}), y = s(W\\tilde{x} + b) and z as s(W'y + b'). The reconstruction\n",
      " error is now measured between z and the uncorrupted input x, which is\n",
      " computed as the cross-entropy :\n",
      "      - \\sum_{k=1}^d[ x_k \\log z_k + (1-x_k) \\log( 1-z_k)]\n",
      "\n",
      "\n",
      " References :\n",
      "   - P. Vincent, H. Larochelle, Y. Bengio, P.A. Manzagol: Extracting and\n",
      "   Composing Robust Features with Denoising Autoencoders, ICML'08, 1096-1103,\n",
      "   2008\n",
      "   - Y. Bengio, P. Lamblin, D. Popovici, H. Larochelle: Greedy Layer-Wise\n",
      "   Training of Deep Networks, Advances in Neural Information Processing\n",
      "   Systems 19, 2007\n",
      "\n",
      "\"\"\"\n",
      "import cPickle\n",
      "import gzip\n",
      "import os\n",
      "import sys\n",
      "import time\n",
      "\n",
      "import numpy\n",
      "\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "from theano.tensor.shared_randomstreams import RandomStreams\n",
      "\n",
      "from logistic_sgd import LogisticRegression, load_data\n",
      "from mlp import HiddenLayer\n",
      "from dA import dA\n",
      "\n",
      "\n",
      "class SdA(object):\n",
      "    \"\"\"Stacked denoising auto-encoder class (SdA)\n",
      "\n",
      "    A stacked denoising autoencoder model is obtained by stacking several\n",
      "    dAs. The hidden layer of the dA at layer `i` becomes the input of\n",
      "    the dA at layer `i+1`. The first layer dA gets as input the input of\n",
      "    the SdA, and the hidden layer of the last dA represents the output.\n",
      "    Note that after pretraining, the SdA is dealt with as a normal MLP,\n",
      "    the dAs are only used to initialize the weights.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, numpy_rng, theano_rng=None, n_ins=784,\n",
      "                 hidden_layers_sizes=[500, 500], n_outs=10,\n",
      "                 corruption_levels=[0.1, 0.1]):\n",
      "        \"\"\" This class is made to support a variable number of layers.\n",
      "\n",
      "        :type numpy_rng: numpy.random.RandomState\n",
      "        :param numpy_rng: numpy random number generator used to draw initial\n",
      "                    weights\n",
      "\n",
      "        :type theano_rng: theano.tensor.shared_randomstreams.RandomStreams\n",
      "        :param theano_rng: Theano random generator; if None is given one is\n",
      "                           generated based on a seed drawn from `rng`\n",
      "\n",
      "        :type n_ins: int\n",
      "        :param n_ins: dimension of the input to the sdA\n",
      "\n",
      "        :type n_layers_sizes: list of ints\n",
      "        :param n_layers_sizes: intermediate layers size, must contain\n",
      "                               at least one value\n",
      "\n",
      "        :type n_outs: int\n",
      "        :param n_outs: dimension of the output of the network\n",
      "\n",
      "        :type corruption_levels: list of float\n",
      "        :param corruption_levels: amount of corruption to use for each\n",
      "                                  layer\n",
      "        \"\"\"\n",
      "\n",
      "        self.sigmoid_layers = []\n",
      "        self.dA_layers = []\n",
      "        self.params = []\n",
      "        self.n_layers = len(hidden_layers_sizes)\n",
      "\n",
      "        assert self.n_layers > 0\n",
      "\n",
      "        if not theano_rng:\n",
      "            theano_rng = RandomStreams(numpy_rng.randint(2 ** 30))\n",
      "        # allocate symbolic variables for the data\n",
      "        self.x = T.matrix('x')  # the data is presented as rasterized images\n",
      "        self.y = T.ivector('y')  # the labels are presented as 1D vector of\n",
      "                                 # [int] labels\n",
      "\n",
      "        # The SdA is an MLP, for which all weights of intermediate layers\n",
      "        # are shared with a different denoising autoencoders\n",
      "        # We will first construct the SdA as a deep multilayer perceptron,\n",
      "        # and when constructing each sigmoidal layer we also construct a\n",
      "        # denoising autoencoder that shares weights with that layer\n",
      "        # During pretraining we will train these autoencoders (which will\n",
      "        # lead to chainging the weights of the MLP as well)\n",
      "        # During finetunining we will finish training the SdA by doing\n",
      "        # stochastich gradient descent on the MLP\n",
      "\n",
      "        for i in xrange(self.n_layers):\n",
      "            # construct the sigmoidal layer\n",
      "\n",
      "            # the size of the input is either the number of hidden units of\n",
      "            # the layer below or the input size if we are on the first layer\n",
      "            if i == 0:\n",
      "                input_size = n_ins\n",
      "            else:\n",
      "                input_size = hidden_layers_sizes[i - 1]\n",
      "\n",
      "            # the input to this layer is either the activation of the hidden\n",
      "            # layer below or the input of the SdA if you are on the first\n",
      "            # layer\n",
      "            if i == 0:\n",
      "                layer_input = self.x\n",
      "            else:\n",
      "                layer_input = self.sigmoid_layers[-1].output\n",
      "\n",
      "            sigmoid_layer = HiddenLayer(rng=numpy_rng,\n",
      "                                        input=layer_input,\n",
      "                                        n_in=input_size,\n",
      "                                        n_out=hidden_layers_sizes[i],\n",
      "                                        activation=T.nnet.sigmoid)\n",
      "            # add the layer to our list of layers\n",
      "            self.sigmoid_layers.append(sigmoid_layer)\n",
      "            # its arguably a philosophical question...\n",
      "            # but we are going to only declare that the parameters of the\n",
      "            # sigmoid_layers are parameters of the StackedDAA\n",
      "            # the visible biases in the dA are parameters of those\n",
      "            # dA, but not the SdA\n",
      "            self.params.extend(sigmoid_layer.params)\n",
      "\n",
      "            # Construct a denoising autoencoder that shared weights with this\n",
      "            # layer\n",
      "            dA_layer = dA(numpy_rng=numpy_rng,\n",
      "                          theano_rng=theano_rng,\n",
      "                          input=layer_input,\n",
      "                          n_visible=input_size,\n",
      "                          n_hidden=hidden_layers_sizes[i],\n",
      "                          W=sigmoid_layer.W,\n",
      "                          bhid=sigmoid_layer.b)\n",
      "            self.dA_layers.append(dA_layer)\n",
      "\n",
      "        # We now need to add a logistic layer on top of the MLP\n",
      "        self.logLayer = LogisticRegression(\n",
      "                         input=self.sigmoid_layers[-1].output,\n",
      "                         n_in=hidden_layers_sizes[-1], n_out=n_outs)\n",
      "\n",
      "        self.params.extend(self.logLayer.params)\n",
      "        # construct a function that implements one step of finetunining\n",
      "\n",
      "        # compute the cost for second phase of training,\n",
      "        # defined as the negative log likelihood\n",
      "        self.finetune_cost = self.logLayer.negative_log_likelihood(self.y)\n",
      "        # compute the gradients with respect to the model parameters\n",
      "        # symbolic variable that points to the number of errors made on the\n",
      "        # minibatch given by self.x and self.y\n",
      "        self.errors = self.logLayer.errors(self.y)\n",
      "\n",
      "    def pretraining_functions(self, train_set_x, batch_size):\n",
      "        ''' Generates a list of functions, each of them implementing one\n",
      "        step in trainnig the dA corresponding to the layer with same index.\n",
      "        The function will require as input the minibatch index, and to train\n",
      "        a dA you just need to iterate, calling the corresponding function on\n",
      "        all minibatch indexes.\n",
      "\n",
      "        :type train_set_x: theano.tensor.TensorType\n",
      "        :param train_set_x: Shared variable that contains all datapoints used\n",
      "                            for training the dA\n",
      "\n",
      "        :type batch_size: int\n",
      "        :param batch_size: size of a [mini]batch\n",
      "\n",
      "        :type learning_rate: float\n",
      "        :param learning_rate: learning rate used during training for any of\n",
      "                              the dA layers\n",
      "        '''\n",
      "\n",
      "        # index to a [mini]batch\n",
      "        index = T.lscalar('index')  # index to a minibatch\n",
      "        corruption_level = T.scalar('corruption')  # % of corruption to use\n",
      "        learning_rate = T.scalar('lr')  # learning rate to use\n",
      "        # number of batches\n",
      "        n_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
      "        # begining of a batch, given `index`\n",
      "        batch_begin = index * batch_size\n",
      "        # ending of a batch given `index`\n",
      "        batch_end = batch_begin + batch_size\n",
      "\n",
      "        pretrain_fns = []\n",
      "        for dA in self.dA_layers:\n",
      "            # get the cost and the updates list\n",
      "            cost, updates = dA.get_cost_updates(corruption_level,\n",
      "                                                learning_rate)\n",
      "            # compile the theano function\n",
      "            fn = theano.function(inputs=[index,\n",
      "                              theano.Param(corruption_level, default=0.2),\n",
      "                              theano.Param(learning_rate, default=0.1)],\n",
      "                                 outputs=cost,\n",
      "                                 updates=updates,\n",
      "                                 givens={self.x: train_set_x[batch_begin:\n",
      "                                                             batch_end]})\n",
      "            # append `fn` to the list of functions\n",
      "            pretrain_fns.append(fn)\n",
      "\n",
      "        return pretrain_fns\n",
      "\n",
      "    def build_finetune_functions(self, datasets, batch_size, learning_rate):\n",
      "        '''Generates a function `train` that implements one step of\n",
      "        finetuning, a function `validate` that computes the error on\n",
      "        a batch from the validation set, and a function `test` that\n",
      "        computes the error on a batch from the testing set\n",
      "\n",
      "        :type datasets: list of pairs of theano.tensor.TensorType\n",
      "        :param datasets: It is a list that contain all the datasets;\n",
      "                         the has to contain three pairs, `train`,\n",
      "                         `valid`, `test` in this order, where each pair\n",
      "                         is formed of two Theano variables, one for the\n",
      "                         datapoints, the other for the labels\n",
      "\n",
      "        :type batch_size: int\n",
      "        :param batch_size: size of a minibatch\n",
      "\n",
      "        :type learning_rate: float\n",
      "        :param learning_rate: learning rate used during finetune stage\n",
      "        '''\n",
      "\n",
      "        (train_set_x, train_set_y) = datasets[0]\n",
      "        (valid_set_x, valid_set_y) = datasets[1]\n",
      "        (test_set_x, test_set_y) = datasets[2]\n",
      "\n",
      "        # compute number of minibatches for training, validation and testing\n",
      "        n_valid_batches = valid_set_x.get_value(borrow=True).shape[0]\n",
      "        n_valid_batches /= batch_size\n",
      "        n_test_batches = test_set_x.get_value(borrow=True).shape[0]\n",
      "        n_test_batches /= batch_size\n",
      "\n",
      "        index = T.lscalar('index')  # index to a [mini]batch\n",
      "\n",
      "        # compute the gradients with respect to the model parameters\n",
      "        gparams = T.grad(self.finetune_cost, self.params)\n",
      "\n",
      "        # compute list of fine-tuning updates\n",
      "        updates = []\n",
      "        for param, gparam in zip(self.params, gparams):\n",
      "            updates.append((param, param - gparam * learning_rate))\n",
      "\n",
      "        train_fn = theano.function(inputs=[index],\n",
      "              outputs=self.finetune_cost,\n",
      "              updates=updates,\n",
      "              givens={\n",
      "                self.x: train_set_x[index * batch_size:\n",
      "                                    (index + 1) * batch_size],\n",
      "                self.y: train_set_y[index * batch_size:\n",
      "                                    (index + 1) * batch_size]},\n",
      "              name='train')\n",
      "\n",
      "        test_score_i = theano.function([index], self.errors,\n",
      "                 givens={\n",
      "                   self.x: test_set_x[index * batch_size:\n",
      "                                      (index + 1) * batch_size],\n",
      "                   self.y: test_set_y[index * batch_size:\n",
      "                                      (index + 1) * batch_size]},\n",
      "                      name='test')\n",
      "\n",
      "        valid_score_i = theano.function([index], self.errors,\n",
      "              givens={\n",
      "                 self.x: valid_set_x[index * batch_size:\n",
      "                                     (index + 1) * batch_size],\n",
      "                 self.y: valid_set_y[index * batch_size:\n",
      "                                     (index + 1) * batch_size]},\n",
      "                      name='valid')\n",
      "\n",
      "        # Create a function that scans the entire validation set\n",
      "        def valid_score():\n",
      "            return [valid_score_i(i) for i in xrange(n_valid_batches)]\n",
      "\n",
      "        # Create a function that scans the entire test set\n",
      "        def test_score():\n",
      "            return [test_score_i(i) for i in xrange(n_test_batches)]\n",
      "\n",
      "        return train_fn, valid_score, test_score\n",
      "import scipy as sp\n",
      "def shared_dataset(data_xy, borrow=True):\n",
      "    \"\"\" Function that loads the dataset into shared variables\n",
      "\n",
      "    The reason we store our dataset in shared variables is to allow\n",
      "    Theano to copy it into the GPU memory (when code is run on GPU).\n",
      "    Since copying data into the GPU is slow, copying a minibatch everytime\n",
      "    is needed (the default behaviour if the data is not in a shared\n",
      "    variable) would lead to a large decrease in performance.\n",
      "    \"\"\"\n",
      "    data_x, data_y = data_xy\n",
      "    shared_x = theano.shared(numpy.asarray(data_x,\n",
      "                                           dtype=theano.config.floatX),\n",
      "                             borrow=borrow)\n",
      "    shared_y = theano.shared(numpy.asarray(data_y,\n",
      "                                           dtype=theano.config.floatX),\n",
      "                             borrow=borrow)\n",
      "    # When storing data on the GPU it has to be stored as floats\n",
      "    # therefore we will store the labels as ``floatX`` as well\n",
      "    # (``shared_y`` does exactly that). But during our computations\n",
      "    # we need them as ints (we use labels as index, and if they are\n",
      "    # floats it doesn't make sense) therefore instead of returning\n",
      "    # ``shared_y`` we will have to cast it to int. This little hack\n",
      "    # lets ous get around this issue\n",
      "    return shared_x, T.cast(shared_y, 'int32')\n",
      "\n",
      "######## testining SDA #############\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "\"\"\"\n",
      "Demonstrates how to train and test a stochastic denoising autoencoder.\n",
      "\n",
      "This is demonstrated on MNIST.\n",
      "\n",
      ":type learning_rate: float\n",
      ":param learning_rate: learning rate used in the finetune stage\n",
      "(factor for the stochastic gradient)\n",
      "\n",
      ":type pretraining_epochs: int\n",
      ":param pretraining_epochs: number of epoch to do pretraining\n",
      "\n",
      ":type pretrain_lr: float\n",
      ":param pretrain_lr: learning rate to be used during pre-training\n",
      "\n",
      ":type n_iter: int\n",
      ":param n_iter: maximal number of iterations ot run the optimizer\n",
      "\n",
      ":type dataset: string\n",
      ":param dataset: path the the pickled dataset\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "##### create a function to train an Sda and return it.\n",
      "def trainSda(hidden_layers_sizes = [100, 100, 100], corruption_levels = [0, 0, 0], batch_size = 30 , \\\n",
      "             training_epochs = 100, pretraining_epochs = 100, pretrain_lr = 0.001, finetune_lr=0.1, \\\n",
      "             X_train_minmax = X_train_minmax, y_train = y_train,\n",
      "             X_validation_minmax = X_validation_minmax, y_validation = y_validation, \n",
      "             X_test_minmax = X_test_minmax, y_test = y_test\n",
      "             ):\n",
      "    n_visible = X_train_minmax.shape[1]\n",
      "    # compute number of minibatches for training, validation and testing\n",
      "\n",
      "    train_set_x, train_set_y = shared_dataset( (X_train_minmax,  y_train), borrow=True)\n",
      "    valid_set_x, valid_set_y = shared_dataset( (X_validation_minmax,  y_validation), borrow=True)\n",
      "    test_set_x, test_set_y = shared_dataset( (X_test_minmax,  y_test), borrow=True)\n",
      "    n_train_batches = train_set_x.get_value(borrow=True).shape[0]\n",
      "    n_train_batches /= batch_size\n",
      "    # numpy random generator\n",
      "    numpy_rng = numpy.random.RandomState(89677)\n",
      "    print '... building the model'\n",
      "    # construct the stacked denoising autoencoder class\n",
      "    sda = SdA(numpy_rng=numpy_rng, n_ins=n_visible,\n",
      "              hidden_layers_sizes= hidden_layers_sizes,\n",
      "              n_outs=2)\n",
      "    #########################\n",
      "    # PRETRAINING THE MODEL #\n",
      "    #########################\n",
      "    print '... getting the pretraining functions'\n",
      "    pretraining_fns = sda.pretraining_functions(train_set_x=train_set_x,\n",
      "                                                batch_size=batch_size)\n",
      "\n",
      "    print '... pre-training the model'\n",
      "    start_time = time.clock()\n",
      "    ## Pre-train layer-wise\n",
      "\n",
      "    for i in xrange(sda.n_layers):\n",
      "        # go through pretraining epochs\n",
      "        for epoch in xrange(pretraining_epochs):\n",
      "            # go through the training set\n",
      "            c = []\n",
      "            for batch_index in xrange(n_train_batches):\n",
      "                c.append(pretraining_fns[i](index=batch_index,\n",
      "                         corruption=corruption_levels[i],\n",
      "                         lr=pretrain_lr))\n",
      "            print 'Pre-training layer %i, epoch %d, cost ' % (i, epoch),\n",
      "            print numpy.mean(c)\n",
      "\n",
      "    end_time = time.clock()\n",
      "\n",
      "    print >> sys.stderr, ('The pretraining code ran for %.2fm' % ((end_time - start_time) / 60.))\n",
      "\n",
      "    ########################\n",
      "    # FINETUNING THE MODEL #\n",
      "    ########################\n",
      "\n",
      "    # get the training, validation and testing function for the model\n",
      "    print '... getting the finetuning functions'\n",
      "    datasets = [(train_set_x, train_set_y) , (valid_set_x, valid_set_y), (test_set_x, test_set_y)]\n",
      "    train_fn, validate_model, test_model = sda.build_finetune_functions(\n",
      "                datasets=datasets, batch_size=batch_size,\n",
      "                learning_rate=finetune_lr)\n",
      "\n",
      "    print '... finetunning the model'\n",
      "    # early-stopping parameters\n",
      "    patience = 10 * n_train_batches  # look as this many examples regardless\n",
      "    patience_increase = 2.  # wait this much longer when a new best is\n",
      "                            # found\n",
      "    improvement_threshold = 0.995  # a relative improvement of this much is\n",
      "                                   # considered significant\n",
      "    validation_frequency = min(n_train_batches, patience / 2)\n",
      "                                  # go through this many\n",
      "                                  # minibatche before checking the network\n",
      "                                  # on the validation set; in this case we\n",
      "                                  # check every epoch\n",
      "\n",
      "    best_params = None\n",
      "    best_validation_loss = numpy.inf\n",
      "    test_score = 0.\n",
      "    start_time = time.clock()\n",
      "\n",
      "    done_looping = False\n",
      "    epoch = 0\n",
      "\n",
      "    while (epoch < training_epochs) and (not done_looping):\n",
      "        epoch = epoch + 1\n",
      "        for minibatch_index in xrange(n_train_batches):\n",
      "            minibatch_avg_cost = train_fn(minibatch_index)\n",
      "            iter = (epoch - 1) * n_train_batches + minibatch_index\n",
      "\n",
      "            if (iter + 1) % validation_frequency == 0:\n",
      "                validation_losses = validate_model()\n",
      "                this_validation_loss = numpy.mean(validation_losses)\n",
      "                print('epoch %i, minibatch %i/%i, validation error %f %%' %\n",
      "                      (epoch, minibatch_index + 1, n_train_batches,\n",
      "                       this_validation_loss * 100.))\n",
      "\n",
      "                # if we got the best validation score until now\n",
      "                if this_validation_loss < best_validation_loss:\n",
      "\n",
      "                    #improve patience if loss improvement is good enough\n",
      "                    if (this_validation_loss < best_validation_loss *\n",
      "                        improvement_threshold):\n",
      "                        patience = max(patience, iter * patience_increase)\n",
      "\n",
      "                    # save best validation score and iteration number\n",
      "                    best_validation_loss = this_validation_loss\n",
      "                    best_iter = iter\n",
      "\n",
      "                    # test it on the test set\n",
      "                    test_losses = test_model()\n",
      "                    test_score = numpy.mean(test_losses)\n",
      "                    print((' epoch %i, minibatch %i/%i, test error of '\n",
      "                           'best model %f %%') %\n",
      "                          (epoch, minibatch_index + 1, n_train_batches,\n",
      "                           test_score * 100.))\n",
      "\n",
      "            if patience <= iter:\n",
      "                done_looping = True\n",
      "                break\n",
      "    return sda\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'X_train_minmax' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-3-2717b550ca3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;31m##### create a function to train an Sda and return it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m def trainSda(hidden_layers_sizes = [100, 100, 100], corruption_levels = [0, 0, 0], batch_size = 30 ,              training_epochs = 100, pretraining_epochs = 100, pretrain_lr = 0.001, finetune_lr=0.1,              X_train_minmax = X_train_minmax, y_train = y_train,\n\u001b[0m\u001b[0;32m    563\u001b[0m              \u001b[0mX_validation_minmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_validation_minmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_validation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m              \u001b[0mX_test_minmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test_minmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'X_train_minmax' is not defined"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#prepare your data\n",
      "import numpy as np\n",
      "import pylab as pl\n",
      "\n",
      "\n",
      "#transform data to 0.1-0.9 or 0-1\n",
      "\n",
      "\n",
      "X_train_minmax = \n",
      "y_train = \n",
      "X_validation_minmax = \n",
      "y_validation = \n",
      "X_test_minmax = \n",
      "y_test = "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['active_days', 'average_deaths', 'average_kills', 'average_actual_rating', 'average_duration', 'number_of_games', 'number_of_wins', 'number_of_losses', 'win_rate', 'period_1_df_active_days', 'period_1_df_average_deaths', 'period_1_df_average_kills', 'period_1_df_average_actual_rating', 'period_1_df_average_duration', 'period_1_df_number_of_games', 'period_1_df_number_of_wins', 'period_1_df_number_of_losses', 'period_2_df_active_days', 'period_2_df_average_deaths', 'period_2_df_average_kills', 'period_2_df_average_actual_rating', 'period_2_df_average_duration', 'period_2_df_number_of_games', 'period_2_df_number_of_wins', 'period_2_df_number_of_losses', 'diff_df_active_days', 'diff_df_average_deaths', 'diff_df_average_kills', 'diff_df_average_actual_rating', 'diff_df_average_duration', 'diff_df_number_of_losses', 'diff_df_active_days_percentge', 'diff_df_average_deaths_percentge', 'diff_df_average_kills_percentge', 'diff_df_average_actual_rating_percentge', 'diff_df_average_duration_percentge', 'diff_df_number_of_games_percentge', 'diff_df_number_of_wins_percentge', 'diff_df_number_of_losses_percentge', 'streak_loss', 'last_game_level', 'spent', 'spent_usd', 'log_number_of_games', 'log_number_of_wins', 'log_number_of_losses', 'log_period_1_df_number_of_games', 'log_period_1_df_number_of_wins', 'log_period_1_df_number_of_losses', 'log_period_2_df_number_of_games', 'log_period_2_df_number_of_wins', 'log_period_2_df_number_of_losses', 'log_last_game_level', 'log_diff_df_active_days_percentge', 'log_diff_df_average_deaths_percentge', 'log_diff_df_average_kills_percentge', 'log_diff_df_average_duration_percentge', 'log_diff_df_number_of_games_percentge', 'log_diff_df_number_of_wins_percentge', 'log_diff_df_number_of_losses_percentge']\n",
        "number of features 60\n",
        "24573"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19658 4915 19658 4915\n",
        "[ 0.37525215  0.38518842  0.42674664  0.47889133  0.4715159   0.15258374\n",
        "  0.14640059  0.16274556  0.478348    0.37825076  0.33266711  0.26891371\n",
        "  0.48797425  0.35599561  0.14730122  0.14380945  0.14015431  0.44721753\n",
        "  0.34163419  0.36248406  0.47219492  0.43373915  0.1536422   0.14855672\n",
        "  0.15363489  0.53448339  0.54903072  0.60982959  0.64609468  0.61763463\n",
        "  0.55375362  0.29593048  0.16045319  0.13092468  0.73007912  0.14778462\n",
        "  0.112204    0.12003625  0.11449644  0.17485692  0.26900674  0.64828946\n",
        "  0.24050617  0.36694143  0.42953363  0.46364872  0.37132409  0.32467413\n",
        "  0.32952524  0.43380445  0.375232    0.39399858  0.45277559  0.56664081\n",
        "  0.48493057  0.43930199  0.37172646  0.37766699  0.37098112  0.36006259]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "number of features 60\n",
        "0.1 0.9\n",
        "5971 5971\n",
        "5971 5971\n",
        "(11942L, 60L) [1 1 1 ..., 0 0 0]\n",
        "(11942L, 60L) [0 1 0 ..., 1 0 1]\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set up paramaters\n",
      "\n",
      "#finetune_lr=0.1\n",
      "finetune_lr=0.0001\n",
      "pretraining_epochs = 100\n",
      "#pretrain_lr=0.001\n",
      "pretrain_lr = 0.0000001\n",
      "training_epochs = 100\n",
      "batch_size = 30\n",
      "\n",
      "\n",
      "hidden_layers_sizes= [100, 100, 100, 100, 100]\n",
      "corruption_levels = [0, 0, 0, 0, 0]\n",
      "#corruption_levels = [0, 0, 0]\n",
      "sda = trainSda(hidden_layers_sizes = hidden_layers_sizes, corruption_levels = corruption_levels, batch_size = batch_size , \\\n",
      "             training_epochs = training_epochs, pretraining_epochs = pretraining_epochs, \n",
      "             pretrain_lr = pretrain_lr, finetune_lr=finetune_lr, \\\n",
      "             X_train_minmax = X_train_minmax, y_train = y_train,\n",
      "             X_validation_minmax = X_validation_minmax, y_validation = y_validation, \n",
      "             X_test_minmax = X_test_minmax, y_test = y_test\n",
      "             )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... building the model\n",
        "... getting the pretraining functions\n",
        "... pre-training the model"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Pre-training layer 0, epoch 0, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 86.0520980387\n",
        "Pre-training layer 0, epoch 1, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 86.0523170758\n",
        "Pre-training layer 0, epoch 2, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 86.0162159952\n",
        "Pre-training layer 0, epoch 3, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 86.0662843983\n",
        "Pre-training layer 0, epoch 4, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 86.0137633454\n",
        "Pre-training layer 0, epoch 5, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.9297987808\n",
        "Pre-training layer 0, epoch 6, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.9454868606\n",
        "Pre-training layer 0, epoch 7, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.9264792157\n",
        "Pre-training layer 0, epoch 8, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.8946182982\n",
        "Pre-training layer 0, epoch 9, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.854568457\n",
        "Pre-training layer 0, epoch 10, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.8967150755\n",
        "Pre-training layer 0, epoch 11, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.8689507294\n",
        "Pre-training layer 0, epoch 12, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.8917453961\n",
        "Pre-training layer 0, epoch 13, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.8479150506\n",
        "Pre-training layer 0, epoch 14, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.8541065198\n",
        "Pre-training layer 0, epoch 15, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.8010437595\n",
        "Pre-training layer 0, epoch 16, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.8270629378\n",
        "Pre-training layer 0, epoch 17, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.7005681278\n",
        "Pre-training layer 0, epoch 18, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.7885660205\n",
        "Pre-training layer 0, epoch 19, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.7078024802\n",
        "Pre-training layer 0, epoch 20, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.7350028976\n",
        "Pre-training layer 0, epoch 21, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.7116208276\n",
        "Pre-training layer 0, epoch 22, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.6338836351\n",
        "Pre-training layer 0, epoch 23, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.6841247653\n",
        "Pre-training layer 0, epoch 24, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.6541130891\n",
        "Pre-training layer 0, epoch 25, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.6100037843\n",
        "Pre-training layer 0, epoch 26, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.6143064814\n",
        "Pre-training layer 0, epoch 27, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.6826372886\n",
        "Pre-training layer 0, epoch 28, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.5537682375\n",
        "Pre-training layer 0, epoch 29, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.6135469916\n",
        "Pre-training layer 0, epoch 30, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.5280633111\n",
        "Pre-training layer 0, epoch 31, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.5401931601\n",
        "Pre-training layer 0, epoch 32, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.4934264824\n",
        "Pre-training layer 0, epoch 33, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.5291817998\n",
        "Pre-training layer 0, epoch 34, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.4592333992\n",
        "Pre-training layer 0, epoch 35, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.4355441848\n",
        "Pre-training layer 0, epoch 36, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.4008581035\n",
        "Pre-training layer 0, epoch 37, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.3860213851\n",
        "Pre-training layer 0, epoch 38, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.3317791144\n",
        "Pre-training layer 0, epoch 39, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.3777292693\n",
        "Pre-training layer 0, epoch 40, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.3333234443\n",
        "Pre-training layer 0, epoch 41, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.300681557\n",
        "Pre-training layer 0, epoch 42, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.3707914556\n",
        "Pre-training layer 0, epoch 43, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.3417986908\n",
        "Pre-training layer 0, epoch 44, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.2761745183\n",
        "Pre-training layer 0, epoch 45, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.2824954677\n",
        "Pre-training layer 0, epoch 46, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.2195448158\n",
        "Pre-training layer 0, epoch 47, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.1942038458\n",
        "Pre-training layer 0, epoch 48, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.2953181591\n",
        "Pre-training layer 0, epoch 49, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.2319294799\n",
        "Pre-training layer 0, epoch 50, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.1708835144\n",
        "Pre-training layer 0, epoch 51, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.1794292112\n",
        "Pre-training layer 0, epoch 52, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.1126228404\n",
        "Pre-training layer 0, epoch 53, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.1099453706\n",
        "Pre-training layer 0, epoch 54, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.1055937709\n",
        "Pre-training layer 0, epoch 55, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.0915509492\n",
        "Pre-training layer 0, epoch 56, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.0574736108\n",
        "Pre-training layer 0, epoch 57, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.0673709244\n",
        "Pre-training layer 0, epoch 58, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.0650668542\n",
        "Pre-training layer 0, epoch 59, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.9809744385\n",
        "Pre-training layer 0, epoch 60, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.0183512707\n",
        "Pre-training layer 0, epoch 61, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85.1013381794\n",
        "Pre-training layer 0, epoch 62, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.9327026639\n",
        "Pre-training layer 0, epoch 63, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.9215115541\n",
        "Pre-training layer 0, epoch 64, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.924839114\n",
        "Pre-training layer 0, epoch 65, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.9154205107\n",
        "Pre-training layer 0, epoch 66, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.9295396994\n",
        "Pre-training layer 0, epoch 67, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.9061699823\n",
        "Pre-training layer 0, epoch 68, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.8826887442\n",
        "Pre-training layer 0, epoch 69, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.9261175394\n",
        "Pre-training layer 0, epoch 70, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.7915339804\n",
        "Pre-training layer 0, epoch 71, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.7871725524\n",
        "Pre-training layer 0, epoch 72, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.8115314523\n",
        "Pre-training layer 0, epoch 73, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.783434179\n",
        "Pre-training layer 0, epoch 74, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.8171982562\n",
        "Pre-training layer 0, epoch 75, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.7421891572\n",
        "Pre-training layer 0, epoch 76, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.7597433618\n",
        "Pre-training layer 0, epoch 77, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.7168563481\n",
        "Pre-training layer 0, epoch 78, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.7803854057\n",
        "Pre-training layer 0, epoch 79, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.6524016831\n",
        "Pre-training layer 0, epoch 80, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.6104171601\n",
        "Pre-training layer 0, epoch 81, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.6215239734\n",
        "Pre-training layer 0, epoch 82, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.6436763482\n",
        "Pre-training layer 0, epoch 83, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.6570200226\n",
        "Pre-training layer 0, epoch 84, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.6525154249\n",
        "Pre-training layer 0, epoch 85, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.561856436\n",
        "Pre-training layer 0, epoch 86, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.5595827971\n",
        "Pre-training layer 0, epoch 87, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.6039922567\n",
        "Pre-training layer 0, epoch 88, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.5583337421\n",
        "Pre-training layer 0, epoch 89, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.4810240365\n",
        "Pre-training layer 0, epoch 90, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.4854580998\n",
        "Pre-training layer 0, epoch 91, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.5071500267\n",
        "Pre-training layer 0, epoch 92, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.4339494876\n",
        "Pre-training layer 0, epoch 93, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.4726957958\n",
        "Pre-training layer 0, epoch 94, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.4772169649\n",
        "Pre-training layer 0, epoch 95, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.4160685565\n",
        "Pre-training layer 0, epoch 96, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.4373476289\n",
        "Pre-training layer 0, epoch 97, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.4774113049\n",
        "Pre-training layer 0, epoch 98, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.4243109608\n",
        "Pre-training layer 0, epoch 99, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84.37756064\n",
        "Pre-training layer 1, epoch 0, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 120.04167726\n",
        "Pre-training layer 1, epoch 1, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 120.148723078\n",
        "Pre-training layer 1, epoch 2, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 120.201068361\n",
        "Pre-training layer 1, epoch 3, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 120.074753194\n",
        "Pre-training layer 1, epoch 4, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 120.010091612\n",
        "Pre-training layer 1, epoch 5, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 120.020362318\n",
        "Pre-training layer 1, epoch 6, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.957695663\n",
        "Pre-training layer 1, epoch 7, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 120.007070046\n",
        "Pre-training layer 1, epoch 8, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.929746771\n",
        "Pre-training layer 1, epoch 9, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 120.029097827\n",
        "Pre-training layer 1, epoch 10, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.986435286\n",
        "Pre-training layer 1, epoch 11, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.879922907\n",
        "Pre-training layer 1, epoch 12, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.807813486\n",
        "Pre-training layer 1, epoch 13, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.864403065\n",
        "Pre-training layer 1, epoch 14, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.793988531\n",
        "Pre-training layer 1, epoch 15, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.773958747\n",
        "Pre-training layer 1, epoch 16, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.798331474\n",
        "Pre-training layer 1, epoch 17, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.724980478\n",
        "Pre-training layer 1, epoch 18, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.704672539\n",
        "Pre-training layer 1, epoch 19, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.628568672\n",
        "Pre-training layer 1, epoch 20, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.785392794\n",
        "Pre-training layer 1, epoch 21, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.660154655\n",
        "Pre-training layer 1, epoch 22, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.616467335\n",
        "Pre-training layer 1, epoch 23, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.661672191\n",
        "Pre-training layer 1, epoch 24, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.605910913\n",
        "Pre-training layer 1, epoch 25, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.635648135\n",
        "Pre-training layer 1, epoch 26, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.556256933\n",
        "Pre-training layer 1, epoch 27, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.614929091\n",
        "Pre-training layer 1, epoch 28, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.607946746\n",
        "Pre-training layer 1, epoch 29, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.553416233\n",
        "Pre-training layer 1, epoch 30, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.424054115\n",
        "Pre-training layer 1, epoch 31, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.482372744\n",
        "Pre-training layer 1, epoch 32, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.463006855\n",
        "Pre-training layer 1, epoch 33, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.33868847\n",
        "Pre-training layer 1, epoch 34, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.46085678\n",
        "Pre-training layer 1, epoch 35, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.462766684\n",
        "Pre-training layer 1, epoch 36, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.387866887\n",
        "Pre-training layer 1, epoch 37, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.373084323\n",
        "Pre-training layer 1, epoch 38, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.34124663\n",
        "Pre-training layer 1, epoch 39, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.321528072\n",
        "Pre-training layer 1, epoch 40, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.308129376\n",
        "Pre-training layer 1, epoch 41, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.229814357\n",
        "Pre-training layer 1, epoch 42, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.219543976\n",
        "Pre-training layer 1, epoch 43, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.168439476\n",
        "Pre-training layer 1, epoch 44, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.273905914\n",
        "Pre-training layer 1, epoch 45, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.165972912\n",
        "Pre-training layer 1, epoch 46, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.113873458\n",
        "Pre-training layer 1, epoch 47, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.087058892\n",
        "Pre-training layer 1, epoch 48, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.12399458\n",
        "Pre-training layer 1, epoch 49, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.08475091\n",
        "Pre-training layer 1, epoch 50, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.064857159\n",
        "Pre-training layer 1, epoch 51, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.057661931\n",
        "Pre-training layer 1, epoch 52, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.117785648\n",
        "Pre-training layer 1, epoch 53, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.994027234\n",
        "Pre-training layer 1, epoch 54, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.964976498\n",
        "Pre-training layer 1, epoch 55, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.886614843\n",
        "Pre-training layer 1, epoch 56, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119.027403449\n",
        "Pre-training layer 1, epoch 57, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.978050466\n",
        "Pre-training layer 1, epoch 58, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.907292937\n",
        "Pre-training layer 1, epoch 59, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.87535125\n",
        "Pre-training layer 1, epoch 60, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.889270152\n",
        "Pre-training layer 1, epoch 61, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.856566795\n",
        "Pre-training layer 1, epoch 62, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.815618666\n",
        "Pre-training layer 1, epoch 63, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.858050304\n",
        "Pre-training layer 1, epoch 64, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.723289586\n",
        "Pre-training layer 1, epoch 65, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.710097307\n",
        "Pre-training layer 1, epoch 66, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.689242235\n",
        "Pre-training layer 1, epoch 67, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.647859081\n",
        "Pre-training layer 1, epoch 68, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.78559318\n",
        "Pre-training layer 1, epoch 69, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.69127503\n",
        "Pre-training layer 1, epoch 70, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.677101418\n",
        "Pre-training layer 1, epoch 71, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.7314598\n",
        "Pre-training layer 1, epoch 72, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.627939149\n",
        "Pre-training layer 1, epoch 73, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.558374323\n",
        "Pre-training layer 1, epoch 74, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.595796915\n",
        "Pre-training layer 1, epoch 75, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.581273628\n",
        "Pre-training layer 1, epoch 76, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.514124838\n",
        "Pre-training layer 1, epoch 77, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.484696894\n",
        "Pre-training layer 1, epoch 78, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.544423055\n",
        "Pre-training layer 1, epoch 79, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.409903046\n",
        "Pre-training layer 1, epoch 80, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.453221296\n",
        "Pre-training layer 1, epoch 81, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.44961203\n",
        "Pre-training layer 1, epoch 82, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.355619345\n",
        "Pre-training layer 1, epoch 83, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.419266687\n",
        "Pre-training layer 1, epoch 84, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.430297674\n",
        "Pre-training layer 1, epoch 85, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.477134445\n",
        "Pre-training layer 1, epoch 86, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.342147413\n",
        "Pre-training layer 1, epoch 87, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.294058598\n",
        "Pre-training layer 1, epoch 88, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.179361545\n",
        "Pre-training layer 1, epoch 89, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.312090322\n",
        "Pre-training layer 1, epoch 90, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.178962624\n",
        "Pre-training layer 1, epoch 91, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.310129348\n",
        "Pre-training layer 1, epoch 92, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.173836028\n",
        "Pre-training layer 1, epoch 93, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.197473948\n",
        "Pre-training layer 1, epoch 94, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.149395684\n",
        "Pre-training layer 1, epoch 95, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.01145935\n",
        "Pre-training layer 1, epoch 96, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.036062277\n",
        "Pre-training layer 1, epoch 97, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.099029316\n",
        "Pre-training layer 1, epoch 98, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.013782374\n",
        "Pre-training layer 1, epoch 99, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118.050258786\n",
        "Pre-training layer 2, epoch 0, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.979979273\n",
        "Pre-training layer 2, epoch 1, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.892730568\n",
        "Pre-training layer 2, epoch 2, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.906896775\n",
        "Pre-training layer 2, epoch 3, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.865913454\n",
        "Pre-training layer 2, epoch 4, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.939482234\n",
        "Pre-training layer 2, epoch 5, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.847458466\n",
        "Pre-training layer 2, epoch 6, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.825651969\n",
        "Pre-training layer 2, epoch 7, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.877913707\n",
        "Pre-training layer 2, epoch 8, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.709122203\n",
        "Pre-training layer 2, epoch 9, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.791562728\n",
        "Pre-training layer 2, epoch 10, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.782213288\n",
        "Pre-training layer 2, epoch 11, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.70174152\n",
        "Pre-training layer 2, epoch 12, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.672946028\n",
        "Pre-training layer 2, epoch 13, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.687665487\n",
        "Pre-training layer 2, epoch 14, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.711737335\n",
        "Pre-training layer 2, epoch 15, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.676239452\n",
        "Pre-training layer 2, epoch 16, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.648815571\n",
        "Pre-training layer 2, epoch 17, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.61848983\n",
        "Pre-training layer 2, epoch 18, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.626025569\n",
        "Pre-training layer 2, epoch 19, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.625346877\n",
        "Pre-training layer 2, epoch 20, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.485976575\n",
        "Pre-training layer 2, epoch 21, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.557377807\n",
        "Pre-training layer 2, epoch 22, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.499268792\n",
        "Pre-training layer 2, epoch 23, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.479950913\n",
        "Pre-training layer 2, epoch 24, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.466992735\n",
        "Pre-training layer 2, epoch 25, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.565918624\n",
        "Pre-training layer 2, epoch 26, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.361639197\n",
        "Pre-training layer 2, epoch 27, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.370552028\n",
        "Pre-training layer 2, epoch 28, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.428720084\n",
        "Pre-training layer 2, epoch 29, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.238098155\n",
        "Pre-training layer 2, epoch 30, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.360795465\n",
        "Pre-training layer 2, epoch 31, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.340347275\n",
        "Pre-training layer 2, epoch 32, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.284721811\n",
        "Pre-training layer 2, epoch 33, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.254998098\n",
        "Pre-training layer 2, epoch 34, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.306892034\n",
        "Pre-training layer 2, epoch 35, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.33319181\n",
        "Pre-training layer 2, epoch 36, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.2830892\n",
        "Pre-training layer 2, epoch 37, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.295431314\n",
        "Pre-training layer 2, epoch 38, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.191311241\n",
        "Pre-training layer 2, epoch 39, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.181744975\n",
        "Pre-training layer 2, epoch 40, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.166452736\n",
        "Pre-training layer 2, epoch 41, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.195142692\n",
        "Pre-training layer 2, epoch 42, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.245311625\n",
        "Pre-training layer 2, epoch 43, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.126320234\n",
        "Pre-training layer 2, epoch 44, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.198833069\n",
        "Pre-training layer 2, epoch 45, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.201394413\n",
        "Pre-training layer 2, epoch 46, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.982644842\n",
        "Pre-training layer 2, epoch 47, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.101559166\n",
        "Pre-training layer 2, epoch 48, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.048907284\n",
        "Pre-training layer 2, epoch 49, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.031120414\n",
        "Pre-training layer 2, epoch 50, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.892038285\n",
        "Pre-training layer 2, epoch 51, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.919592537\n",
        "Pre-training layer 2, epoch 52, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102.00326011\n",
        "Pre-training layer 2, epoch 53, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.914971577\n",
        "Pre-training layer 2, epoch 54, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.966360073\n",
        "Pre-training layer 2, epoch 55, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.887149883\n",
        "Pre-training layer 2, epoch 56, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.784564734\n",
        "Pre-training layer 2, epoch 57, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.853794427\n",
        "Pre-training layer 2, epoch 58, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.83142531\n",
        "Pre-training layer 2, epoch 59, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.727871073\n",
        "Pre-training layer 2, epoch 60, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.795362497\n",
        "Pre-training layer 2, epoch 61, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.927931175\n",
        "Pre-training layer 2, epoch 62, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.874952621\n",
        "Pre-training layer 2, epoch 63, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.756708163\n",
        "Pre-training layer 2, epoch 64, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.686725244\n",
        "Pre-training layer 2, epoch 65, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.801214619\n",
        "Pre-training layer 2, epoch 66, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.744759692\n",
        "Pre-training layer 2, epoch 67, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.684334884\n",
        "Pre-training layer 2, epoch 68, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.537072477\n",
        "Pre-training layer 2, epoch 69, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.662950279\n",
        "Pre-training layer 2, epoch 70, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.609808846\n",
        "Pre-training layer 2, epoch 71, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.569662138\n",
        "Pre-training layer 2, epoch 72, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.68527935\n",
        "Pre-training layer 2, epoch 73, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.589143595\n",
        "Pre-training layer 2, epoch 74, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.583977233\n",
        "Pre-training layer 2, epoch 75, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.60282173\n",
        "Pre-training layer 2, epoch 76, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.539694669\n",
        "Pre-training layer 2, epoch 77, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.476755032\n",
        "Pre-training layer 2, epoch 78, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.45348654\n",
        "Pre-training layer 2, epoch 79, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.463147326\n",
        "Pre-training layer 2, epoch 80, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.488831085\n",
        "Pre-training layer 2, epoch 81, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.412811409\n",
        "Pre-training layer 2, epoch 82, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.442730499\n",
        "Pre-training layer 2, epoch 83, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.478483516\n",
        "Pre-training layer 2, epoch 84, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.282793848\n",
        "Pre-training layer 2, epoch 85, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.437331139\n",
        "Pre-training layer 2, epoch 86, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.40659022\n",
        "Pre-training layer 2, epoch 87, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.27879983\n",
        "Pre-training layer 2, epoch 88, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.313355863\n",
        "Pre-training layer 2, epoch 89, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.317645969\n",
        "Pre-training layer 2, epoch 90, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.280986435\n",
        "Pre-training layer 2, epoch 91, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.264908092\n",
        "Pre-training layer 2, epoch 92, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.137971854\n",
        "Pre-training layer 2, epoch 93, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.218142022\n",
        "Pre-training layer 2, epoch 94, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.149898054\n",
        "Pre-training layer 2, epoch 95, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.107399823\n",
        "Pre-training layer 2, epoch 96, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.174127588\n",
        "Pre-training layer 2, epoch 97, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.01567959\n",
        "Pre-training layer 2, epoch 98, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.066595353\n",
        "Pre-training layer 2, epoch 99, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101.075358856\n",
        "Pre-training layer 3, epoch 0, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.348460663\n",
        "Pre-training layer 3, epoch 1, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.294194496\n",
        "Pre-training layer 3, epoch 2, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.326489924\n",
        "Pre-training layer 3, epoch 3, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.310193089\n",
        "Pre-training layer 3, epoch 4, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.301588029\n",
        "Pre-training layer 3, epoch 5, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.334155325\n",
        "Pre-training layer 3, epoch 6, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.178313016\n",
        "Pre-training layer 3, epoch 7, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.144553675\n",
        "Pre-training layer 3, epoch 8, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.207346421\n",
        "Pre-training layer 3, epoch 9, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.215699381\n",
        "Pre-training layer 3, epoch 10, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.134934838\n",
        "Pre-training layer 3, epoch 11, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.066433092\n",
        "Pre-training layer 3, epoch 12, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.154097934\n",
        "Pre-training layer 3, epoch 13, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.027759614\n",
        "Pre-training layer 3, epoch 14, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.053959416\n",
        "Pre-training layer 3, epoch 15, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.946707297\n",
        "Pre-training layer 3, epoch 16, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.035649561\n",
        "Pre-training layer 3, epoch 17, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.022459898\n",
        "Pre-training layer 3, epoch 18, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.916518166\n",
        "Pre-training layer 3, epoch 19, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.973208919\n",
        "Pre-training layer 3, epoch 20, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.824002656\n",
        "Pre-training layer 3, epoch 21, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.906485526\n",
        "Pre-training layer 3, epoch 22, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.831259092\n",
        "Pre-training layer 3, epoch 23, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.681390328\n",
        "Pre-training layer 3, epoch 24, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.895433208\n",
        "Pre-training layer 3, epoch 25, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.625666825\n",
        "Pre-training layer 3, epoch 26, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.817549253\n",
        "Pre-training layer 3, epoch 27, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.631081468\n",
        "Pre-training layer 3, epoch 28, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.695176209\n",
        "Pre-training layer 3, epoch 29, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.66549844\n",
        "Pre-training layer 3, epoch 30, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.635546594\n",
        "Pre-training layer 3, epoch 31, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.678730934\n",
        "Pre-training layer 3, epoch 32, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.537792194\n",
        "Pre-training layer 3, epoch 33, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.532256284\n",
        "Pre-training layer 3, epoch 34, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.522995101\n",
        "Pre-training layer 3, epoch 35, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.509123495\n",
        "Pre-training layer 3, epoch 36, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.538502273\n",
        "Pre-training layer 3, epoch 37, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.49120824\n",
        "Pre-training layer 3, epoch 38, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.461571629\n",
        "Pre-training layer 3, epoch 39, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.429419538\n",
        "Pre-training layer 3, epoch 40, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.367305338\n",
        "Pre-training layer 3, epoch 41, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.457630785\n",
        "Pre-training layer 3, epoch 42, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.356018439\n",
        "Pre-training layer 3, epoch 43, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.391652002\n",
        "Pre-training layer 3, epoch 44, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.20634512\n",
        "Pre-training layer 3, epoch 45, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.226661543\n",
        "Pre-training layer 3, epoch 46, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.33515243\n",
        "Pre-training layer 3, epoch 47, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.20625608\n",
        "Pre-training layer 3, epoch 48, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.244118012\n",
        "Pre-training layer 3, epoch 49, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.16080083\n",
        "Pre-training layer 3, epoch 50, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.137173847\n",
        "Pre-training layer 3, epoch 51, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.138755158\n",
        "Pre-training layer 3, epoch 52, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.156806288\n",
        "Pre-training layer 3, epoch 53, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.061392866\n",
        "Pre-training layer 3, epoch 54, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.056655401\n",
        "Pre-training layer 3, epoch 55, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.10132618\n",
        "Pre-training layer 3, epoch 56, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.02561974\n",
        "Pre-training layer 3, epoch 57, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.105363076\n",
        "Pre-training layer 3, epoch 58, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.979783275\n",
        "Pre-training layer 3, epoch 59, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.030972048\n",
        "Pre-training layer 3, epoch 60, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.927918428\n",
        "Pre-training layer 3, epoch 61, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.949427083\n",
        "Pre-training layer 3, epoch 62, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.929426993\n",
        "Pre-training layer 3, epoch 63, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.939812575\n",
        "Pre-training layer 3, epoch 64, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.802513247\n",
        "Pre-training layer 3, epoch 65, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.852627513\n",
        "Pre-training layer 3, epoch 66, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.773732345\n",
        "Pre-training layer 3, epoch 67, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.875693422\n",
        "Pre-training layer 3, epoch 68, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.744702491\n",
        "Pre-training layer 3, epoch 69, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.689969512\n",
        "Pre-training layer 3, epoch 70, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.78405862\n",
        "Pre-training layer 3, epoch 71, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.682696046\n",
        "Pre-training layer 3, epoch 72, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.66014117\n",
        "Pre-training layer 3, epoch 73, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.589529015\n",
        "Pre-training layer 3, epoch 74, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.771185156\n",
        "Pre-training layer 3, epoch 75, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.592983857\n",
        "Pre-training layer 3, epoch 76, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.67859886\n",
        "Pre-training layer 3, epoch 77, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.50891392\n",
        "Pre-training layer 3, epoch 78, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.46324131\n",
        "Pre-training layer 3, epoch 79, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.500191687\n",
        "Pre-training layer 3, epoch 80, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.471373386\n",
        "Pre-training layer 3, epoch 81, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.485863119\n",
        "Pre-training layer 3, epoch 82, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.410880535\n",
        "Pre-training layer 3, epoch 83, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.36804948\n",
        "Pre-training layer 3, epoch 84, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.411404926\n",
        "Pre-training layer 3, epoch 85, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.283414503\n",
        "Pre-training layer 3, epoch 86, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.314309942\n",
        "Pre-training layer 3, epoch 87, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.268094023\n",
        "Pre-training layer 3, epoch 88, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.368275519\n",
        "Pre-training layer 3, epoch 89, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.30904627\n",
        "Pre-training layer 3, epoch 90, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.254233832\n",
        "Pre-training layer 3, epoch 91, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.157572649\n",
        "Pre-training layer 3, epoch 92, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.162751739\n",
        "Pre-training layer 3, epoch 93, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.103830401\n",
        "Pre-training layer 3, epoch 94, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.180339451\n",
        "Pre-training layer 3, epoch 95, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.112519442\n",
        "Pre-training layer 3, epoch 96, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.22976855\n",
        "Pre-training layer 3, epoch 97, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.033264521\n",
        "Pre-training layer 3, epoch 98, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.146053671\n",
        "Pre-training layer 3, epoch 99, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.175624168\n",
        "Pre-training layer 4, epoch 0, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.760780629\n",
        "Pre-training layer 4, epoch 1, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.791027262\n",
        "Pre-training layer 4, epoch 2, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.677193921\n",
        "Pre-training layer 4, epoch 3, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.704580394\n",
        "Pre-training layer 4, epoch 4, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.663741379\n",
        "Pre-training layer 4, epoch 5, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.613051455\n",
        "Pre-training layer 4, epoch 6, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.625968721\n",
        "Pre-training layer 4, epoch 7, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.571784608\n",
        "Pre-training layer 4, epoch 8, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.545691508\n",
        "Pre-training layer 4, epoch 9, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.580372801\n",
        "Pre-training layer 4, epoch 10, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.526637117\n",
        "Pre-training layer 4, epoch 11, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.538231386\n",
        "Pre-training layer 4, epoch 12, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.421155315\n",
        "Pre-training layer 4, epoch 13, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.495692336\n",
        "Pre-training layer 4, epoch 14, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.400172079\n",
        "Pre-training layer 4, epoch 15, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.412470755\n",
        "Pre-training layer 4, epoch 16, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.371260189\n",
        "Pre-training layer 4, epoch 17, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.347343732\n",
        "Pre-training layer 4, epoch 18, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.298175733\n",
        "Pre-training layer 4, epoch 19, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.276424429\n",
        "Pre-training layer 4, epoch 20, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.226823922\n",
        "Pre-training layer 4, epoch 21, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.186827868\n",
        "Pre-training layer 4, epoch 22, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.216785402\n",
        "Pre-training layer 4, epoch 23, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.183965817\n",
        "Pre-training layer 4, epoch 24, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.17756837\n",
        "Pre-training layer 4, epoch 25, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.096073267\n",
        "Pre-training layer 4, epoch 26, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.145484324\n",
        "Pre-training layer 4, epoch 27, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.084040561\n",
        "Pre-training layer 4, epoch 28, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.02922001\n",
        "Pre-training layer 4, epoch 29, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109.080981958\n",
        "Pre-training layer 4, epoch 30, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.996289147\n",
        "Pre-training layer 4, epoch 31, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.925253089\n",
        "Pre-training layer 4, epoch 32, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.863912645\n",
        "Pre-training layer 4, epoch 33, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.958547688\n",
        "Pre-training layer 4, epoch 34, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.865032913\n",
        "Pre-training layer 4, epoch 35, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.843842637\n",
        "Pre-training layer 4, epoch 36, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.885427896\n",
        "Pre-training layer 4, epoch 37, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.735075102\n",
        "Pre-training layer 4, epoch 38, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.816705907\n",
        "Pre-training layer 4, epoch 39, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.806894995\n",
        "Pre-training layer 4, epoch 40, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.697422482\n",
        "Pre-training layer 4, epoch 41, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.769003965\n",
        "Pre-training layer 4, epoch 42, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.736860115\n",
        "Pre-training layer 4, epoch 43, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.57022538\n",
        "Pre-training layer 4, epoch 44, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.659185951\n",
        "Pre-training layer 4, epoch 45, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.552317356\n",
        "Pre-training layer 4, epoch 46, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.606588947\n",
        "Pre-training layer 4, epoch 47, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.508753607\n",
        "Pre-training layer 4, epoch 48, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.485403062\n",
        "Pre-training layer 4, epoch 49, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.559900149\n",
        "Pre-training layer 4, epoch 50, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.50862432\n",
        "Pre-training layer 4, epoch 51, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.550065976\n",
        "Pre-training layer 4, epoch 52, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.427117725\n",
        "Pre-training layer 4, epoch 53, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.279620628\n",
        "Pre-training layer 4, epoch 54, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.31948951\n",
        "Pre-training layer 4, epoch 55, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.280761847\n",
        "Pre-training layer 4, epoch 56, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.301432451\n",
        "Pre-training layer 4, epoch 57, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.218429469\n",
        "Pre-training layer 4, epoch 58, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.259552598\n",
        "Pre-training layer 4, epoch 59, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.250671579\n",
        "Pre-training layer 4, epoch 60, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.168835767\n",
        "Pre-training layer 4, epoch 61, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.140077522\n",
        "Pre-training layer 4, epoch 62, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.157146486\n",
        "Pre-training layer 4, epoch 63, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.107220836\n",
        "Pre-training layer 4, epoch 64, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.119040316\n",
        "Pre-training layer 4, epoch 65, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.084520941\n",
        "Pre-training layer 4, epoch 66, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.182092202\n",
        "Pre-training layer 4, epoch 67, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.951214969\n",
        "Pre-training layer 4, epoch 68, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108.051689108\n",
        "Pre-training layer 4, epoch 69, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.9852174\n",
        "Pre-training layer 4, epoch 70, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.925179954\n",
        "Pre-training layer 4, epoch 71, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.862862042\n",
        "Pre-training layer 4, epoch 72, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.87824142\n",
        "Pre-training layer 4, epoch 73, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.824514162\n",
        "Pre-training layer 4, epoch 74, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.911320678\n",
        "Pre-training layer 4, epoch 75, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.851154202\n",
        "Pre-training layer 4, epoch 76, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.712329676\n",
        "Pre-training layer 4, epoch 77, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.83576585\n",
        "Pre-training layer 4, epoch 78, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.706395344\n",
        "Pre-training layer 4, epoch 79, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.744800783\n",
        "Pre-training layer 4, epoch 80, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.622367578\n",
        "Pre-training layer 4, epoch 81, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.638130366\n",
        "Pre-training layer 4, epoch 82, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.679877254\n",
        "Pre-training layer 4, epoch 83, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.572324653\n",
        "Pre-training layer 4, epoch 84, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.544645642\n",
        "Pre-training layer 4, epoch 85, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.568201794\n",
        "Pre-training layer 4, epoch 86, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.491871692\n",
        "Pre-training layer 4, epoch 87, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.468087302\n",
        "Pre-training layer 4, epoch 88, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.439382372\n",
        "Pre-training layer 4, epoch 89, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.448598929\n",
        "Pre-training layer 4, epoch 90, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.420723818\n",
        "Pre-training layer 4, epoch 91, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.401588828\n",
        "Pre-training layer 4, epoch 92, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.291857629\n",
        "Pre-training layer 4, epoch 93, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.321131567\n",
        "Pre-training layer 4, epoch 94, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.364135082\n",
        "Pre-training layer 4, epoch 95, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.287676024\n",
        "Pre-training layer 4, epoch 96, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.319986969\n",
        "Pre-training layer 4, epoch 97, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.198214596\n",
        "Pre-training layer 4, epoch 98, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.271867616\n",
        "Pre-training layer 4, epoch 99, cost "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107.256513676\n",
        "... getting the finetuning functions\n",
        "... finetunning the model"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 1, minibatch 398/398, validation error 63.358779 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " epoch 1, minibatch 398/398, test error of best model 62.351738 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 2, minibatch 398/398, validation error 63.358779 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 3, minibatch 398/398, validation error 63.358779 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 4, minibatch 398/398, validation error 63.358779 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 5, minibatch 398/398, validation error 63.358779 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 6, minibatch 398/398, validation error 63.358779 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 7, minibatch 398/398, validation error 63.358779 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 8, minibatch 398/398, validation error 63.358779 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 9, minibatch 398/398, validation error 63.358779 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 10, minibatch 398/398, validation error 63.358779 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "The pretraining code ran for 4.48m\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this part is for testing the Sda model and report performance.\n",
      "\n",
      "train_set_x, train_set_y = shared_dataset( (X_train_minmax,  y_train), borrow=True)\n",
      "valid_set_x, valid_set_y = shared_dataset( (X_validation_minmax,  y_validation), borrow=True)\n",
      "test_set_x, test_set_y = shared_dataset( (X_test_minmax,  y_test), borrow=True)\n",
      "\n",
      "print 'hidden_layers_sizes:', hidden_layers_sizes\n",
      "print 'corruption_levels:', corruption_levels\n",
      "\n",
      "\n",
      "predict_train = theano.function([], sda.logLayer.y_pred,\n",
      "                   givens={sda.x: train_set_x})\n",
      "training_predicted = predict_train()\n",
      "\n",
      "print 'train accuracy: ', '{percent:.1%}'.format(percent=sklearn.metrics.accuracy_score(y_train, training_predicted)) \n",
      "print 'precision: ', '{percent:.1%}'.format(percent=sklearn.metrics.precision_score(y_train, training_predicted, pos_label=1)) \n",
      "print 'recall: ', '{percent:.1%}'.format( percent= sklearn.metrics.recall_score(y_train, training_predicted, pos_label=1))\n",
      "\n",
      "predict = theano.function([], sda.logLayer.y_pred,\n",
      "                   givens={sda.x: test_set_x})\n",
      "test_predicted = predict()\n",
      "print 'testing accuracy: ', '{percent:.1%}'.format(percent=sklearn.metrics.accuracy_score(y_test, test_predicted)) \n",
      "print 'precision: ', '{percent:.1%}'.format(percent=sklearn.metrics.precision_score(y_test, test_predicted, pos_label=1)) \n",
      "print 'recall: ', '{percent:.1%}'.format( percent= sklearn.metrics.recall_score(y_test, test_predicted, pos_label=1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}