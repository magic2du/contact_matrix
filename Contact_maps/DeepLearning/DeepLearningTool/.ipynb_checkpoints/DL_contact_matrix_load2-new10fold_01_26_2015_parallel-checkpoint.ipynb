{
 "metadata": {
  "name": "",
  "signature": "sha256:7b0d97c47efa1d33f175a18380eedde2acddf3e575ffb3590b92002d773f7816"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys, os\n",
      "sys.path.append('../../../libs/')\n",
      "import os.path\n",
      "import IO_class\n",
      "from IO_class import FileOperator, saveAsCsv\n",
      "from sklearn import cross_validation\n",
      "import sklearn\n",
      "import csv\n",
      "from dateutil import parser\n",
      "from datetime import timedelta\n",
      "from sklearn import svm\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import pdb\n",
      "import pickle\n",
      "import numpy as np\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.cross_validation import KFold\n",
      "from sklearn import preprocessing\n",
      "import sklearn\n",
      "import scipy.stats as ss\n",
      "from sklearn.svm import LinearSVC\n",
      "import random\n",
      "from DL_libs import *\n",
      "from itertools import izip #new\n",
      "import math\n",
      "from sklearn.svm import SVC"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#filename = 'SUCCESS_log_CrossValidation_load_DL_remoteFisherM1_DL_RE_US_DL_RE_US_1_1_19MAY2014.txt'\n",
      "#filename = 'listOfDDIsHaveOver2InterfacesHave40-75_Examples_2010_real_selected.txt' #for testing\n",
      "\n",
      "# set settings for this script\n",
      "settings = {}\n",
      "settings['filename'] = 'ddi_examples_40_60_over2top_diff_name_2014.txt'\n",
      "settings['fisher_mode'] = 'FisherM1ONLY'# settings['fisher_mode'] = 'FisherM1ONLY'\n",
      "settings['with_auc_score'] = False\n",
      "settings['reduce_ratio'] = 1\n",
      "settings['SVM'] = 0\n",
      "settings['DL'] = 1\n",
      "settings['SAE_SVM'] = 1\n",
      "settings['SAE_SVM_COMBO'] = 1\n",
      "settings['SVM_RBF'] = 1\n",
      "settings['SAE_SVM_RBF'] = 1\n",
      "settings['SAE_SVM_RBF_COMBO'] = 1\n",
      "settings['SVM_POLY'] = 0\n",
      "settings['DL_S'] = 1\n",
      "settings['DL_U'] = 0\n",
      "\n",
      "settings['finetune_lr'] = 1\n",
      "settings['batch_size'] = 100\n",
      "settings['pretraining_interations'] = 5001\n",
      "settings['pretrain_lr'] = 0.001\n",
      "settings['training_epochs'] = 20001\n",
      "settings['hidden_layers_sizes'] = [100, 100]\n",
      "settings['corruption_levels'] = [0, 0]\n",
      "\n",
      "\n",
      "filename = settings['filename']\n",
      "file_obj = FileOperator(filename)\n",
      "ddis = file_obj.readStripLines()\n",
      "import logging\n",
      "import time\n",
      "current_date = time.strftime(\"%m_%d_%Y\")\n",
      "\n",
      "logger = logging.getLogger(__name__)\n",
      "logger.setLevel(logging.DEBUG)\n",
      "\n",
      "logname = 'log_DL_contact_matrix_load' + current_date + '.log'\n",
      "handler = logging.FileHandler(logname)\n",
      "handler.setLevel(logging.DEBUG)\n",
      "\n",
      "# create a logging format\n",
      "\n",
      "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
      "handler.setFormatter(formatter)\n",
      "\n",
      "# add the handlers to the logger\n",
      "\n",
      "logger.addHandler(handler)\n",
      "\n",
      "logger.info('Input DDI file: ' + filename)\n",
      "#logger.debug('This message should go to the log file')\n",
      "for key, value in settings.items():\n",
      "    logger.info(key +': '+ str(value))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:Input DDI file: ddi_examples_40_60_over2top_diff_name_2014.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:DL: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:SVM: 0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:fisher_mode: FisherM1ONLY\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:SAE_SVM_RBF_COMBO: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:SAE_SVM_COMBO: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:DL_U: 0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:DL_S: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:corruption_levels: [0, 0]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:SVM_RBF: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:SVM_POLY: 0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:reduce_ratio: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:filename: ddi_examples_40_60_over2top_diff_name_2014.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:pretraining_interations: 5001\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:batch_size: 100\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:SAE_SVM_RBF: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:with_auc_score: False\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:pretrain_lr: 0.001\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:training_epochs: 20001\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:finetune_lr: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:hidden_layers_sizes: [100, 100]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:SAE_SVM: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of lines in ddi_examples_40_60_over2top_diff_name_2014.txt:136\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class DDI_family_base(object):\n",
      "    #def __init__(self, ddi, Vectors_Fishers_aaIndex_raw_folder = '/home/du/Documents/Vectors_Fishers_aaIndex_raw_2014/'):\n",
      "    #def __init__(self, ddi, Vectors_Fishers_aaIndex_raw_folder = '/home/sun/Downloads/contactmatrix/contactmatrixanddeeplearningcode/data_test/'):\n",
      "    def __init__(self, ddi, Vectors_Fishers_aaIndex_raw_folder = '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/'):\n",
      "        \"\"\" get total number of sequences in a ddi familgy\n",
      "        Attributes:\n",
      "            ddi: string ddi name\n",
      "            Vectors_Fishers_aaIndex_raw_folder: string, folder\n",
      "            total_number_of_sequences: int\n",
      "            raw_data: dict raw_data[2]\n",
      "        LOO_data['FisherM1'][1]\n",
      "\n",
      "        \"\"\"\n",
      "        self.ddi = ddi\n",
      "        self.Vectors_Fishers_aaIndex_raw_folder = Vectors_Fishers_aaIndex_raw_folder\n",
      "        self.ddi_folder = self.Vectors_Fishers_aaIndex_raw_folder + ddi + '/'\n",
      "        self.total_number_of_sequences = self.get_total_number_of_sequences()\n",
      "        self.raw_data = {}\n",
      "        self.positve_negative_number = {}\n",
      "        self.equal_size_data = {}\n",
      "        for seq_no in range(1, self.total_number_of_sequences+1):\n",
      "            self.raw_data[seq_no] = self.get_raw_data_for_selected_seq(seq_no)\n",
      "            try:\n",
      "                #positive_file = self.ddi_folder + 'numPos_'+ str(seq_no) + '.txt'\n",
      "                #file_obj = FileOperator(positive_file)\n",
      "                #lines = file_obj.readStripLines()\n",
      "                #import pdb; pdb.set_trace()\n",
      "                count_pos = int(np.sum(self.raw_data[seq_no][:, -1]))\n",
      "                count_neg = self.raw_data[seq_no].shape[0] - count_pos\n",
      "                #self.positve_negative_number[seq_no] = {'numPos': int(float(lines[0]))}\n",
      "                #assert int(float(lines[0])) == count_pos\n",
      "                self.positve_negative_number[seq_no] = {'numPos': count_pos}\n",
      "                #negative_file = self.ddi_folder + 'numNeg_'+ str(seq_no) + '.txt'\n",
      "                #file_obj = FileOperator(negative_file)\n",
      "                #lines = file_obj.readStripLines()\n",
      "                #self.positve_negative_number[seq_no]['numNeg'] =  int(float(lines[0]))\n",
      "                self.positve_negative_number[seq_no]['numNeg'] =  count_neg\n",
      "            except Exception,e:\n",
      "                print ddi, seq_no\n",
      "                print str(e)\n",
      "                logger.info(ddi + str(seq_no))\n",
      "                logger.info(str(e))                \n",
      "            # get data for equal positive and negative\n",
      "            n_pos = self.positve_negative_number[seq_no]['numPos']\n",
      "            n_neg = self.positve_negative_number[seq_no]['numNeg']\n",
      "            index_neg = range(n_pos, n_pos + n_neg)\n",
      "            random.shuffle(index_neg)\n",
      "            index_neg = index_neg[: n_pos]\n",
      "            positive_examples = self.raw_data[seq_no][ : n_pos, :]\n",
      "            negative_examples = self.raw_data[seq_no][index_neg, :]\n",
      "            self.equal_size_data[seq_no] = np.vstack((positive_examples, negative_examples))\n",
      "    def get_LOO_training_and_reduced_traing(self, seq_no, fisher_mode = 'FisherM1ONLY' , reduce_ratio = 4):\n",
      "        \"\"\" get the leave one out traing data, reduced traing\n",
      "        Parameters:\n",
      "            seq_no: \n",
      "            fisher_mode: default 'FisherM1ONLY'\n",
      "        Returns:\n",
      "            (train_X_LOO, train_y_LOO),(train_X_reduced, train_y_reduced),  (test_X, test_y)\n",
      "        \"\"\"\n",
      "        train_X_LOO = np.array([])\n",
      "        train_y_LOO = np.array([])\n",
      "        train_X_reduced = np.array([])\n",
      "        train_y_reduced = np.array([])\n",
      "\n",
      "        total_number_of_sequences = self.total_number_of_sequences\n",
      "        equal_size_data_selected_sequence = self.equal_size_data[seq_no]\n",
      "        \n",
      "        #get test data for selected sequence\n",
      "        test_X, test_y = self.select_X_y(equal_size_data_selected_sequence, fisher_mode = fisher_mode)\n",
      "        total_sequences = range(1, total_number_of_sequences+1)\n",
      "        loo_sequences = [i for i in total_sequences if i != seq_no]\n",
      "        number_of_reduced = len(loo_sequences)/reduce_ratio if len(loo_sequences)/reduce_ratio !=0 else 1\n",
      "        random.shuffle(loo_sequences)\n",
      "        reduced_sequences = loo_sequences[:number_of_reduced]\n",
      "\n",
      "        #for loo data\n",
      "        for current_no in loo_sequences:\n",
      "            raw_current_data = self.equal_size_data[current_no]\n",
      "            current_X, current_y = self.select_X_y(raw_current_data, fisher_mode = fisher_mode)\n",
      "            if train_X_LOO.ndim ==1:\n",
      "                train_X_LOO = current_X\n",
      "            else:\n",
      "                train_X_LOO = np.vstack((train_X_LOO, current_X))\n",
      "            train_y_LOO = np.concatenate((train_y_LOO, current_y))\n",
      "\n",
      "        #for reduced data\n",
      "        for current_no in reduced_sequences:\n",
      "            raw_current_data = self.equal_size_data[current_no]\n",
      "            current_X, current_y = self.select_X_y(raw_current_data, fisher_mode = fisher_mode)\n",
      "            if train_X_reduced.ndim ==1:\n",
      "                train_X_reduced = current_X\n",
      "            else:\n",
      "                train_X_reduced = np.vstack((train_X_reduced, current_X))\n",
      "            train_y_reduced = np.concatenate((train_y_reduced, current_y))                \n",
      "\n",
      "        return (train_X_LOO, train_y_LOO),(train_X_reduced, train_y_reduced), (test_X, test_y)\n",
      "        \n",
      "    #def get_ten_fold_crossvalid_one_subset(self, start_subset, end_subset, fisher_mode = 'FisherM1ONLY' , reduce_ratio = 4):\n",
      "    def get_ten_fold_crossvalid_one_subset(self, train_index, test_index, fisher_mode = 'FisherM1ONLY' , reduce_ratio = 4):\n",
      "        \"\"\" get traing data, reduced traing data for 10-fold crossvalidation\n",
      "        Parameters:\n",
      "            start_subset: index of start of the testing data\n",
      "            end_subset: index of end of the testing data\n",
      "            fisher_mode: default 'FisherM1ONLY'\n",
      "        Returns:\n",
      "            (train_X_10fold, train_y_10fold),(train_X_reduced, train_y_reduced),  (test_X, test_y)\n",
      "        \"\"\"\n",
      "        train_X_10fold = np.array([])\n",
      "        train_y_10fold = np.array([])\n",
      "        train_X_reduced = np.array([])\n",
      "        train_y_reduced = np.array([])\n",
      "        test_X = np.array([])\n",
      "        test_y = np.array([])\n",
      "\n",
      "        total_number_of_sequences = self.total_number_of_sequences\n",
      "        \n",
      "        #get test data for selected sequence\n",
      "        #for current_no in range(start_subset, end_subset):\n",
      "        for num in test_index:\n",
      "            current_no = num + 1\n",
      "            raw_current_data = self.equal_size_data[current_no]\n",
      "            current_X, current_y = self.select_X_y(raw_current_data, fisher_mode = fisher_mode)\n",
      "            if test_X.ndim ==1:\n",
      "                test_X = current_X\n",
      "            else:\n",
      "                test_X = np.vstack((test_X, current_X))\n",
      "            test_y = np.concatenate((test_y, current_y))\n",
      "        \n",
      "        #total_sequences = range(1, total_number_of_sequences+1)\n",
      "        #ten_fold_sequences = [i for i in total_sequences if not(i in range(start_subset, end_subset))]\n",
      "        #number_of_reduced = len(ten_fold_sequences)/reduce_ratio if len(ten_fold_sequences)/reduce_ratio !=0 else 1\n",
      "        #random.shuffle(ten_fold_sequences)\n",
      "        #reduced_sequences = ten_fold_sequences[:number_of_reduced]\n",
      "        \n",
      "        number_of_reduced = len(train_index)/reduce_ratio if len(train_index)/reduce_ratio !=0 else 1\n",
      "        random.shuffle(train_index)\n",
      "        reduced_sequences = train_index[:number_of_reduced]\n",
      "\n",
      "        #for 10-fold cross-validation data\n",
      "        #for current_no in ten_fold_sequences:\n",
      "        for num in train_index:\n",
      "            current_no = num + 1\n",
      "            raw_current_data = self.equal_size_data[current_no]\n",
      "            current_X, current_y = self.select_X_y(raw_current_data, fisher_mode = fisher_mode)\n",
      "            if train_X_10fold.ndim ==1:\n",
      "                train_X_10fold = current_X\n",
      "            else:\n",
      "                train_X_10fold = np.vstack((train_X_10fold, current_X))\n",
      "            train_y_10fold = np.concatenate((train_y_10fold, current_y))\n",
      "\n",
      "        #for reduced data\n",
      "        for num in reduced_sequences:\n",
      "            current_no = num + 1\n",
      "            raw_current_data = self.equal_size_data[current_no]\n",
      "            current_X, current_y = self.select_X_y(raw_current_data, fisher_mode = fisher_mode)\n",
      "            if train_X_reduced.ndim ==1:\n",
      "                train_X_reduced = current_X\n",
      "            else:\n",
      "                train_X_reduced = np.vstack((train_X_reduced, current_X))\n",
      "            train_y_reduced = np.concatenate((train_y_reduced, current_y))                \n",
      "\n",
      "        return (train_X_10fold, train_y_10fold),(train_X_reduced, train_y_reduced), (test_X, test_y)\n",
      "        \n",
      "    def get_total_number_of_sequences(self):\n",
      "        \"\"\" get total number of sequences in a ddi familgy\n",
      "        Parameters:\n",
      "            ddi: string\n",
      "            Vectors_Fishers_aaIndex_raw_folder: string\n",
      "        Returns:\n",
      "            n: int\n",
      "        \"\"\"\n",
      "        folder_path = self.Vectors_Fishers_aaIndex_raw_folder + self.ddi + '/' \n",
      "        filename = folder_path +'allPairs.txt'\n",
      "        all_pairs = np.loadtxt(filename)\n",
      "        return len(all_pairs)\n",
      "\n",
      "    def get_raw_data_for_selected_seq(self, seq_no):\n",
      "        \"\"\" get raw data for selected seq no in a family\n",
      "        Parameters:\n",
      "            ddi: \n",
      "            seq_no: \n",
      "        Returns:\n",
      "            data: raw data in the sequence file\n",
      "        \"\"\"\n",
      "        folder_path = self.Vectors_Fishers_aaIndex_raw_folder + self.ddi + '/' \n",
      "        filename = folder_path + 'F0_20_F1_20_Sliding_17_11_F0_20_F1_20_Sliding_17_11_ouput_'+ str(seq_no) + '.txt'\n",
      "        data = np.loadtxt(filename)\n",
      "        return data\n",
      "    def select_X_y(self, data, fisher_mode = ''):\n",
      "        \"\"\" select subset from the raw input data set\n",
      "        Parameters:\n",
      "            data: data from matlab txt file\n",
      "            fisher_mode: subset base on this Fisher of AAONLY...\n",
      "        Returns:\n",
      "            selected X,  y\n",
      "        \"\"\"\n",
      "        y = data[:,-1] # get lable\n",
      "        if fisher_mode == 'FisherM1': # fisher m1 plus AA index\n",
      "            a = data[:, 20:227]\n",
      "            b = data[:, 247:454]\n",
      "            X = np.hstack((a,b))\n",
      "        elif fisher_mode == 'FisherM1ONLY': \n",
      "            a = data[:, 20:40]\n",
      "            b = data[:, 247:267]\n",
      "            X = np.hstack((a,b))\n",
      "        elif fisher_mode == 'AAONLY':\n",
      "            a = data[:, 40:227]\n",
      "            b = data[:, 267:454]\n",
      "            X = np.hstack((a,b))\n",
      "        else:\n",
      "            raise('there is an error in mode')\n",
      "        return X, y\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import sklearn.preprocessing\n",
      "\n",
      "\n",
      "\n",
      "def LOO_out_performance_for_all(ddis):\n",
      "    for ddi in ddis:\n",
      "        try:\n",
      "            one_ddi_family = LOO_out_performance_for_one_ddi(ddi)\n",
      "            one_ddi_family.get_LOO_perfermance(settings = settings)\n",
      "        except Exception,e:\n",
      "            print str(e)\n",
      "            logger.info(\"There is a error in this ddi: %s\" % ddi)\n",
      "            logger.info(str(e))\n",
      "\n",
      "        \n",
      "class LOO_out_performance_for_one_ddi(object):\n",
      "        \"\"\" get the performance of ddi families\n",
      "        Attributes:\n",
      "            ddi: string ddi name\n",
      "            Vectors_Fishers_aaIndex_raw_folder: string, folder\n",
      "            total_number_of_sequences: int\n",
      "            raw_data: dict raw_data[2]\n",
      "\n",
      "        \"\"\"\n",
      "        def __init__(self, ddi):\n",
      "            self.ddi_obj = DDI_family_base(ddi)\n",
      "            self.ddi = ddi\n",
      "\n",
      "        def get_LOO_perfermance(self, settings = None):\n",
      "            fisher_mode = settings['fisher_mode']\n",
      "            analysis_scr = []\n",
      "            with_auc_score = settings['with_auc_score'] \n",
      "            reduce_ratio = settings['reduce_ratio'] \n",
      "            for seq_no in range(1, self.ddi_obj.total_number_of_sequences+1):\n",
      "                print seq_no\n",
      "                logger.info('sequence number: ' + str(seq_no))\n",
      "                if settings['SVM']:\n",
      "                    print \"SVM\"\n",
      "                    (train_X_LOO, train_y_LOO),(train_X_reduced, train_y_reduced), (test_X, test_y) = self.ddi_obj.get_LOO_training_and_reduced_traing(seq_no,fisher_mode = fisher_mode, reduce_ratio = reduce_ratio)\n",
      "                    standard_scaler = preprocessing.StandardScaler().fit(train_X_reduced)\n",
      "                    scaled_train_X = standard_scaler.transform(train_X_reduced)\n",
      "                    scaled_test_X = standard_scaler.transform(test_X)\n",
      "                    Linear_SVC = LinearSVC(C=1, penalty=\"l2\")\n",
      "                    Linear_SVC.fit(scaled_train_X, train_y_reduced)\n",
      "                    predicted_test_y = Linear_SVC.predict(scaled_test_X)\n",
      "                    isTest = True; #new\n",
      "                    analysis_scr.append((self.ddi, seq_no, fisher_mode, 'SVM', isTest) + tuple(performance_score(test_y, predicted_test_y).values())) #new\n",
      "\n",
      "                    predicted_train_y = Linear_SVC.predict(scaled_train_X)\n",
      "                    isTest = False; #new\n",
      "                    analysis_scr.append((self.ddi, seq_no, fisher_mode, 'SVM', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y).values()))\n",
      "                # Deep learning part\n",
      "                min_max_scaler = Preprocessing_Scaler_with_mean_point5()\n",
      "                X_train_pre_validation_minmax = min_max_scaler.fit(train_X_reduced)\n",
      "                X_train_pre_validation_minmax = min_max_scaler.transform(train_X_reduced)\n",
      "                x_test_minmax = min_max_scaler.transform(test_X)\n",
      "                pretraining_X_minmax = min_max_scaler.transform(train_X_LOO)\n",
      "                x_train_minmax, x_validation_minmax, y_train_minmax, y_validation_minmax = train_test_split(X_train_pre_validation_minmax, \n",
      "                                                                                                  train_y_reduced\n",
      "                                                                    , test_size=0.4, random_state=42)\n",
      "                finetune_lr = settings['finetune_lr']\n",
      "                batch_size = settings['batch_size']\n",
      "                pretraining_epochs = cal_epochs(settings['pretraining_interations'], x_train_minmax, batch_size = batch_size)\n",
      "                #pretrain_lr=0.001\n",
      "                pretrain_lr = settings['pretrain_lr']\n",
      "                training_epochs = cal_epochs(settings['training_epochs'], x_train_minmax, batch_size = batch_size)\n",
      "                hidden_layers_sizes= settings['hidden_layers_sizes']\n",
      "                corruption_levels = settings['corruption_levels']\n",
      "                if settings['DL']:\n",
      "                    print \"direct deep learning\"\n",
      "                    # direct deep learning \n",
      "                    sda = trainSda(x_train_minmax, y_train_minmax,\n",
      "                                 x_validation_minmax, y_validation_minmax , \n",
      "                                 x_test_minmax, test_y,\n",
      "                                 hidden_layers_sizes = hidden_layers_sizes, corruption_levels = corruption_levels, batch_size = batch_size , \\\n",
      "                                 training_epochs = training_epochs, pretraining_epochs = pretraining_epochs, \n",
      "                                 pretrain_lr = pretrain_lr, finetune_lr=finetune_lr\n",
      "                     )\n",
      "                    print 'hidden_layers_sizes:', hidden_layers_sizes\n",
      "                    print 'corruption_levels:', corruption_levels\n",
      "                    training_predicted = sda.predict(x_train_minmax)\n",
      "                    y_train = y_train_minmax\n",
      "                    isTest = False; #new\n",
      "                    analysis_scr.append((self.ddi, seq_no, fisher_mode, 'DL', isTest) + tuple(performance_score(y_train, training_predicted).values()))\n",
      "\n",
      "                    test_predicted = sda.predict(x_test_minmax)\n",
      "                    y_test = test_y\n",
      "                    isTest = True; #new\n",
      "                    analysis_scr.append((self.ddi, seq_no, fisher_mode, 'DL', isTest) + tuple(performance_score(y_test, test_predicted).values()))\n",
      "\n",
      "                if 0:\n",
      "                    # deep learning using unlabeled data for pretraining\n",
      "                    print 'deep learning with unlabel data'\n",
      "                    pretraining_epochs_for_reduced = cal_epochs(1500, pretraining_X_minmax, batch_size = batch_size)\n",
      "                    sda_unlabel = trainSda(x_train_minmax, y_train_minmax,\n",
      "                                 x_validation_minmax, y_validation_minmax , \n",
      "                                 x_test_minmax, test_y, \n",
      "                                 pretraining_X_minmax = pretraining_X_minmax,\n",
      "                                 hidden_layers_sizes = hidden_layers_sizes, corruption_levels = corruption_levels, batch_size = batch_size , \\\n",
      "                                 training_epochs = training_epochs, pretraining_epochs = pretraining_epochs_for_reduced, \n",
      "                                 pretrain_lr = pretrain_lr, finetune_lr=finetune_lr\n",
      "                     )\n",
      "                    print 'hidden_layers_sizes:', hidden_layers_sizes\n",
      "                    print 'corruption_levels:', corruption_levels\n",
      "                    training_predicted = sda_unlabel.predict(x_train_minmax)\n",
      "                    y_train = y_train_minmax\n",
      "                    isTest = False; #new\n",
      "                    analysis_scr.append((self.ddi, seq_no, fisher_mode, 'DL_U', isTest) + tuple(performance_score(y_train, training_predicted, with_auc_score).values()))\n",
      "\n",
      "                    test_predicted = sda_unlabel.predict(x_test_minmax)\n",
      "                    y_test = test_y\n",
      "\n",
      "                    isTest = True; #new\n",
      "                    analysis_scr.append((self.ddi, seq_no, fisher_mode, 'DL_U', isTest) + tuple(performance_score(y_test, test_predicted, with_auc_score).values()))\n",
      "                if settings['DL_S']:\n",
      "                    # deep learning using split network\n",
      "                    print 'deep learning using split network'\n",
      "                    # get the new representation for A set. first 784-D\n",
      "                    pretraining_epochs = cal_epochs(settings['pretraining_interations'], x_train_minmax, batch_size = batch_size)\n",
      "                    hidden_layers_sizes= settings['hidden_layers_sizes']\n",
      "                    corruption_levels = settings['corruption_levels']\n",
      "                    \n",
      "                    x = x_train_minmax[:, :x_train_minmax.shape[1]/2]\n",
      "                    print \"original shape for A\", x.shape\n",
      "                    a_MAE_A = train_a_MultipleAEs(x, pretraining_epochs=pretraining_epochs, pretrain_lr=pretrain_lr, batch_size=batch_size, \n",
      "                                            hidden_layers_sizes =hidden_layers_sizes, corruption_levels=corruption_levels)\n",
      "                    new_x_train_minmax_A =  a_MAE_A.transform(x_train_minmax[:, :x_train_minmax.shape[1]/2])\n",
      "                    x = x_train_minmax[:, x_train_minmax.shape[1]/2:]\n",
      "                    \n",
      "                    print \"original shape for B\", x.shape\n",
      "                    a_MAE_B = train_a_MultipleAEs(x, pretraining_epochs=pretraining_epochs, pretrain_lr=pretrain_lr, batch_size=batch_size, \n",
      "                                            hidden_layers_sizes =hidden_layers_sizes, corruption_levels=corruption_levels)\n",
      "                    new_x_train_minmax_B =  a_MAE_B.transform(x_train_minmax[:, x_train_minmax.shape[1]/2:])\n",
      "                    \n",
      "                    new_x_test_minmax_A = a_MAE_A.transform(x_test_minmax[:, :x_test_minmax.shape[1]/2])\n",
      "                    new_x_test_minmax_B = a_MAE_B.transform(x_test_minmax[:, x_test_minmax.shape[1]/2:])\n",
      "                    new_x_validation_minmax_A = a_MAE_A.transform(x_validation_minmax[:, :x_validation_minmax.shape[1]/2])\n",
      "                    new_x_validation_minmax_B = a_MAE_B.transform(x_validation_minmax[:, x_validation_minmax.shape[1]/2:])\n",
      "                    new_x_train_minmax_whole = np.hstack((new_x_train_minmax_A, new_x_train_minmax_B))\n",
      "                    new_x_test_minmax_whole = np.hstack((new_x_test_minmax_A, new_x_test_minmax_B))\n",
      "                    new_x_validationt_minmax_whole = np.hstack((new_x_validation_minmax_A, new_x_validation_minmax_B))\n",
      "\n",
      "                    finetune_lr = settings['finetune_lr']\n",
      "                    batch_size = settings['batch_size']\n",
      "                    pretraining_epochs = cal_epochs(settings['pretraining_interations'], x_train_minmax, batch_size = batch_size)\n",
      "                    #pretrain_lr=0.001\n",
      "                    pretrain_lr = settings['pretrain_lr']\n",
      "                    training_epochs = cal_epochs(settings['training_epochs'], x_train_minmax, batch_size = batch_size)\n",
      "                    hidden_layers_sizes= settings['hidden_layers_sizes']\n",
      "                    corruption_levels = settings['corruption_levels']\n",
      "                    \n",
      "                    sda_transformed = trainSda(new_x_train_minmax_whole, y_train_minmax,\n",
      "                         new_x_validationt_minmax_whole, y_validation_minmax , \n",
      "                         new_x_test_minmax_whole, y_test,\n",
      "                         hidden_layers_sizes = hidden_layers_sizes, corruption_levels = corruption_levels, batch_size = batch_size , \\\n",
      "                         training_epochs = training_epochs, pretraining_epochs = pretraining_epochs, \n",
      "                         pretrain_lr = pretrain_lr, finetune_lr=finetune_lr\n",
      "                         )\n",
      "                    \n",
      "                    print 'hidden_layers_sizes:', hidden_layers_sizes\n",
      "                    print 'corruption_levels:', corruption_levels\n",
      "                    training_predicted = sda_transformed.predict(new_x_train_minmax_whole)\n",
      "                    y_train = y_train_minmax\n",
      "                    \n",
      "                    isTest = False; #new\n",
      "                    analysis_scr.append((self.ddi, seq_no, fisher_mode, 'DL_S', isTest) + tuple(performance_score(y_train, training_predicted, with_auc_score).values()))\n",
      "\n",
      "                    test_predicted = sda_transformed.predict(new_x_test_minmax_whole)\n",
      "                    y_test = test_y\n",
      "\n",
      "                    isTest = True; #new\n",
      "                    analysis_scr.append((self.ddi, seq_no, fisher_mode, 'DL_S', isTest) + tuple(performance_score(y_test, test_predicted, with_auc_score).values()))\n",
      "            \n",
      "            \n",
      "            \n",
      "            report_name = filename + '_' + '_'.join(map(str, hidden_layers_sizes)) + \\\n",
      "                            '_' + str(pretrain_lr) + '_' + str(finetune_lr) + '_' + str(reduce_ratio)+ \\\n",
      "                            '_' +str(training_epochs) + '_' + current_date\n",
      "            saveAsCsv(with_auc_score, report_name, performance_score(y_test, test_predicted, with_auc_score), analysis_scr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#for 10-fold cross validation\n",
      "\n",
      "def ten_fold_crossvalid_performance_for_all(ddis):\n",
      "    for ddi in ddis:\n",
      "        try:\n",
      "            process_one_ddi_tenfold(ddi)\n",
      "        except Exception,e:\n",
      "            print str(e)\n",
      "            logger.debug(\"There is a error in this ddi: %s\" % ddi)\n",
      "            logger.info(str(e))\n",
      "def process_one_ddi_tenfold(ddi):\n",
      "    \"\"\"A function to waste CPU cycles\"\"\"\n",
      "    logger.info('DDI: %s' % ddi)\n",
      "    try:\n",
      "        one_ddi_family = {}\n",
      "        one_ddi_family[ddi] = Ten_fold_crossvalid_performance_for_one_ddi(ddi)\n",
      "        one_ddi_family[ddi].get_ten_fold_crossvalid_perfermance(settings=settings)\n",
      "    except Exception,e:\n",
      "        print str(e)\n",
      "        logger.debug(\"There is a error in this ddi: %s\" % ddi)\n",
      "        logger.info(str(e))\n",
      "    return None\n",
      "class Ten_fold_crossvalid_performance_for_one_ddi(object):\n",
      "        \"\"\" get the performance of ddi families\n",
      "        Attributes:\n",
      "            ddi: string ddi name\n",
      "            Vectors_Fishers_aaIndex_raw_folder: string, folder\n",
      "            total_number_of_sequences: int\n",
      "            raw_data: dict raw_data[2]\n",
      "\n",
      "        \"\"\"\n",
      "        def __init__(self, ddi):\n",
      "            self.ddi_obj = DDI_family_base(ddi)\n",
      "            self.ddi = ddi\n",
      "        def get_ten_fold_crossvalid_perfermance(self, settings = None):\n",
      "            fisher_mode = settings['fisher_mode']\n",
      "            analysis_scr = []\n",
      "            with_auc_score = settings['with_auc_score']\n",
      "            reduce_ratio = settings['reduce_ratio']\n",
      "            #for seq_no in range(1, self.ddi_obj.total_number_of_sequences+1):\n",
      "            #subset_size = math.floor(self.ddi_obj.total_number_of_sequences / 10.0)\n",
      "            kf = KFold(self.ddi_obj.total_number_of_sequences, n_folds = 10, shuffle = True)\n",
      "            #for subset_no in range(1, 11):\n",
      "            for ((train_index, test_index),subset_no) in izip(kf,range(1,11)):\n",
      "            #for train_index, test_index in kf;\n",
      "                print(\"Subset:\", subset_no)\n",
      "                print(\"Train index: \", train_index)\n",
      "                print(\"Test index: \", test_index)\n",
      "                #logger.info('subset number: ' + str(subset_no))\n",
      "                (train_X_10fold, train_y_10fold),(train_X_reduced, train_y_reduced), (test_X, test_y) = self.ddi_obj.get_ten_fold_crossvalid_one_subset(train_index, test_index, fisher_mode = fisher_mode, reduce_ratio = reduce_ratio)\n",
      "                standard_scaler = preprocessing.StandardScaler().fit(train_X_reduced)\n",
      "                scaled_train_X = standard_scaler.transform(train_X_reduced)\n",
      "                scaled_test_X = standard_scaler.transform(test_X)\n",
      "                \n",
      "                if settings['SVM']:\n",
      "                    print \"SVM\"                   \n",
      "                    Linear_SVC = LinearSVC(C=1, penalty=\"l2\")\n",
      "                    Linear_SVC.fit(scaled_train_X, train_y_reduced)\n",
      "                    predicted_test_y = Linear_SVC.predict(scaled_test_X)\n",
      "                    isTest = True; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'SVM', isTest) + tuple(performance_score(test_y, predicted_test_y).values())) #new\n",
      "\n",
      "                    predicted_train_y = Linear_SVC.predict(scaled_train_X)\n",
      "                    isTest = False; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'SVM', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y).values()))                    \n",
      "                if settings['SVM_RBF']:\n",
      "                    print \"SVM_RBF\"\n",
      "                    L1_SVC_RBF_Selector = SVC(C=1, gamma=0.01, kernel='rbf').fit(scaled_train_X, train_y_reduced)\n",
      "\n",
      "                    predicted_test_y = L1_SVC_RBF_Selector.predict(scaled_test_X)\n",
      "                    isTest = True; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'SVM_RBF', isTest) + tuple(performance_score(test_y, predicted_test_y).values())) #new\n",
      "\n",
      "                    predicted_train_y = L1_SVC_RBF_Selector.predict(scaled_train_X)\n",
      "                    isTest = False; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'SVM_RBF', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y).values()))\n",
      "                if settings['SVM_POLY']:\n",
      "                    print \"SVM_POLY\"\n",
      "                    L1_SVC_POLY_Selector = SVC(C=1, kernel='poly').fit(scaled_train_X, train_y_reduced)\n",
      "\n",
      "                    predicted_test_y = L1_SVC_POLY_Selector.predict(scaled_test_X)\n",
      "                    isTest = True; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'SVM_POLY', isTest) + tuple(performance_score(test_y, predicted_test_y).values())) #new\n",
      "\n",
      "                    predicted_train_y = L1_SVC_POLY_Selector.predict(scaled_train_X)\n",
      "                    isTest = False; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'SVM_POLY', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y).values()))\n",
      "                # direct deep learning \n",
      "                min_max_scaler = Preprocessing_Scaler_with_mean_point5()\n",
      "                X_train_pre_validation_minmax = min_max_scaler.fit(train_X_reduced)\n",
      "                X_train_pre_validation_minmax = min_max_scaler.transform(train_X_reduced)\n",
      "                x_test_minmax = min_max_scaler.transform(test_X)\n",
      "                \n",
      "                x_train_minmax, x_validation_minmax, y_train_minmax, y_validation_minmax = train_test_split(X_train_pre_validation_minmax, \n",
      "                                                                                                  train_y_reduced\n",
      "                                                                    , test_size=0.4, random_state=42)\n",
      "                finetune_lr = settings['finetune_lr']\n",
      "                batch_size = settings['batch_size']\n",
      "                pretraining_epochs = cal_epochs(settings['pretraining_interations'], x_train_minmax, batch_size = batch_size)\n",
      "                #pretrain_lr=0.001\n",
      "                pretrain_lr = settings['pretrain_lr']\n",
      "                training_epochs = settings['training_epochs']\n",
      "                hidden_layers_sizes= settings['hidden_layers_sizes']\n",
      "                corruption_levels = settings['corruption_levels']\n",
      "                \n",
      "                #### new prepresentation\n",
      "                x = X_train_pre_validation_minmax\n",
      "                a_MAE_A = train_a_MultipleAEs(x, pretraining_epochs=pretraining_epochs, pretrain_lr=pretrain_lr, batch_size=batch_size, \n",
      "                                        hidden_layers_sizes =hidden_layers_sizes, corruption_levels=corruption_levels)\n",
      "                new_x_train_minmax_A =  a_MAE_A.transform(X_train_pre_validation_minmax)\n",
      "                new_x_test_minmax_A =  a_MAE_A.transform(x_test_minmax)\n",
      "                standard_scaler = preprocessing.StandardScaler().fit(new_x_train_minmax_A)\n",
      "                new_x_train_scaled = standard_scaler.transform(new_x_train_minmax_A)\n",
      "                new_x_test_scaled = standard_scaler.transform(new_x_test_minmax_A)\n",
      "                new_x_train_combo = np.hstack((scaled_train_X, new_x_train_scaled))\n",
      "                new_x_test_combo = np.hstack((scaled_test_X, new_x_test_scaled))\n",
      "                \n",
      "                \n",
      "                if settings['SAE_SVM']: \n",
      "                    print 'SAE followed by SVM'\n",
      "\n",
      "                    Linear_SVC = LinearSVC(C=1, penalty=\"l2\")\n",
      "                    Linear_SVC.fit(new_x_train_scaled, train_y_reduced)\n",
      "                    predicted_test_y = Linear_SVC.predict(new_x_test_scaled)\n",
      "                    isTest = True; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'SAE_SVM', isTest) + tuple(performance_score(test_y, predicted_test_y).values())) #new\n",
      "                    predicted_train_y = Linear_SVC.predict(new_x_train_scaled)\n",
      "                    isTest = False; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'SAE_SVM', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y).values()))\n",
      "                if settings['SAE_SVM_RBF']: \n",
      "                    print 'SAE followed by SVM RBF'\n",
      "                    x = X_train_pre_validation_minmax\n",
      "                    L1_SVC_RBF_Selector = SVC(C=1, gamma=0.01, kernel='rbf').fit(new_x_train_scaled, train_y_reduced)\n",
      "                    predicted_test_y = L1_SVC_RBF_Selector.predict(new_x_test_scaled)\n",
      "                    isTest = True; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'SAE_SVM_RBF', isTest) + tuple(performance_score(test_y, predicted_test_y).values())) #new\n",
      "                    predicted_train_y = L1_SVC_RBF_Selector.predict(new_x_train_scaled)\n",
      "                    isTest = False; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'SAE_SVM_RBF', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y).values()))\n",
      "                if settings['SAE_SVM_COMBO']: \n",
      "                    print 'SAE followed by SVM with combo feature'\n",
      "                    Linear_SVC = LinearSVC(C=1, penalty=\"l2\")\n",
      "                    Linear_SVC.fit(new_x_train_combo, train_y_reduced)\n",
      "                    predicted_test_y = Linear_SVC.predict(new_x_test_combo)\n",
      "                    isTest = True; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'SAE_SVM_COMBO', isTest) + tuple(performance_score(test_y, predicted_test_y).values())) #new\n",
      "                    predicted_train_y = Linear_SVC.predict(new_x_train_combo)\n",
      "                    isTest = False; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'SAE_SVM_COMBO', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y).values()))                                \n",
      "                if settings['SAE_SVM_RBF_COMBO']: \n",
      "                    print 'SAE followed by SVM RBF with combo feature'\n",
      "                    L1_SVC_RBF_Selector = SVC(C=1, gamma=0.01, kernel='rbf').fit(new_x_train_combo, train_y_reduced)\n",
      "                    predicted_test_y = L1_SVC_RBF_Selector.predict(new_x_test_combo)        \n",
      "                    isTest = True; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'SAE_SVM_RBF_COMBO', isTest) + tuple(performance_score(test_y, predicted_test_y).values())) #new\n",
      "                    predicted_train_y = L1_SVC_RBF_Selector.predict(new_x_train_combo)\n",
      "                    isTest = False; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'SAE_SVM_RBF_COMBO', isTest) + tuple(performance_score(train_y_reduced, predicted_train_y).values()))                                                                  \n",
      "                    \n",
      "                if settings['DL']:\n",
      "                    print \"direct deep learning\"\n",
      "                    sda = trainSda(x_train_minmax, y_train_minmax,\n",
      "                                 x_validation_minmax, y_validation_minmax , \n",
      "                                 x_test_minmax, test_y,\n",
      "                                 hidden_layers_sizes = hidden_layers_sizes, corruption_levels = corruption_levels, batch_size = batch_size , \\\n",
      "                                 training_epochs = training_epochs, pretraining_epochs = pretraining_epochs, \n",
      "                                 pretrain_lr = pretrain_lr, finetune_lr=finetune_lr\n",
      "                     )\n",
      "                    print 'hidden_layers_sizes:', hidden_layers_sizes\n",
      "                    print 'corruption_levels:', corruption_levels\n",
      "                    training_predicted = sda.predict(x_train_minmax)\n",
      "                    y_train = y_train_minmax\n",
      "                    isTest = False; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'DL', isTest) + tuple(performance_score(y_train, training_predicted).values()))\n",
      "\n",
      "                    test_predicted = sda.predict(x_test_minmax)\n",
      "                    y_test = test_y\n",
      "                    isTest = True; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'DL', isTest) + tuple(performance_score(y_test, test_predicted).values()))\n",
      "                \n",
      "                if settings['DL_U']:\n",
      "                # deep learning using unlabeled data for pretraining\n",
      "                    print 'deep learning with unlabel data'\n",
      "                    pretraining_X_minmax = min_max_scaler.transform(train_X_10fold)\n",
      "                    pretraining_epochs = cal_epochs(settings['pretraining_interations'], x_train_minmax, batch_size = batch_size)\n",
      "                    sda_unlabel = trainSda(x_train_minmax, y_train_minmax,\n",
      "                                 x_validation_minmax, y_validation_minmax , \n",
      "                                 x_test_minmax, test_y, \n",
      "                                 pretraining_X_minmax = pretraining_X_minmax,\n",
      "                                 hidden_layers_sizes = hidden_layers_sizes, corruption_levels = corruption_levels, batch_size = batch_size , \\\n",
      "                                 training_epochs = training_epochs, pretraining_epochs = pretraining_epochs, \n",
      "                                 pretrain_lr = pretrain_lr, finetune_lr=finetune_lr\n",
      "                     )\n",
      "                    print 'hidden_layers_sizes:', hidden_layers_sizes\n",
      "                    print 'corruption_levels:', corruption_levels\n",
      "                    training_predicted = sda_unlabel.predict(x_train_minmax)\n",
      "                    y_train = y_train_minmax\n",
      "                    isTest = False; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'DL_U', isTest) + tuple(performance_score(y_train, training_predicted, with_auc_score).values()))\n",
      "\n",
      "                    test_predicted = sda_unlabel.predict(x_test_minmax)\n",
      "                    y_test = test_y\n",
      "\n",
      "                    isTest = True; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'DL_U', isTest) + tuple(performance_score(y_test, test_predicted, with_auc_score).values()))\n",
      "                if settings['DL_S']:\n",
      "                    # deep learning using split network\n",
      "                    y_test = test_y\n",
      "                    print 'deep learning using split network'\n",
      "                    # get the new representation for A set. first 784-D\n",
      "                    pretraining_epochs = cal_epochs(settings['pretraining_interations'], x_train_minmax, batch_size = batch_size)\n",
      "                    \n",
      "                    x = x_train_minmax[:, :x_train_minmax.shape[1]/2]\n",
      "                    print \"original shape for A\", x.shape\n",
      "                    a_MAE_A = train_a_MultipleAEs(x, pretraining_epochs=pretraining_epochs, pretrain_lr=pretrain_lr, batch_size=batch_size, \n",
      "                                            hidden_layers_sizes =hidden_layers_sizes, corruption_levels=corruption_levels)\n",
      "                    new_x_train_minmax_A =  a_MAE_A.transform(x_train_minmax[:, :x_train_minmax.shape[1]/2])\n",
      "                    x = x_train_minmax[:, x_train_minmax.shape[1]/2:]\n",
      "                    \n",
      "                    print \"original shape for B\", x.shape\n",
      "                    a_MAE_B = train_a_MultipleAEs(x, pretraining_epochs=pretraining_epochs, pretrain_lr=pretrain_lr, batch_size=batch_size, \n",
      "                                            hidden_layers_sizes =hidden_layers_sizes, corruption_levels=corruption_levels)\n",
      "                    new_x_train_minmax_B =  a_MAE_B.transform(x_train_minmax[:, x_train_minmax.shape[1]/2:])\n",
      "                    \n",
      "                    new_x_test_minmax_A = a_MAE_A.transform(x_test_minmax[:, :x_test_minmax.shape[1]/2])\n",
      "                    new_x_test_minmax_B = a_MAE_B.transform(x_test_minmax[:, x_test_minmax.shape[1]/2:])\n",
      "                    new_x_validation_minmax_A = a_MAE_A.transform(x_validation_minmax[:, :x_validation_minmax.shape[1]/2])\n",
      "                    new_x_validation_minmax_B = a_MAE_B.transform(x_validation_minmax[:, x_validation_minmax.shape[1]/2:])\n",
      "                    new_x_train_minmax_whole = np.hstack((new_x_train_minmax_A, new_x_train_minmax_B))\n",
      "                    new_x_test_minmax_whole = np.hstack((new_x_test_minmax_A, new_x_test_minmax_B))\n",
      "                    new_x_validationt_minmax_whole = np.hstack((new_x_validation_minmax_A, new_x_validation_minmax_B))\n",
      "\n",
      "                    \n",
      "                    sda_transformed = trainSda(new_x_train_minmax_whole, y_train_minmax,\n",
      "                         new_x_validationt_minmax_whole, y_validation_minmax , \n",
      "                         new_x_test_minmax_whole, y_test,\n",
      "                         hidden_layers_sizes = hidden_layers_sizes, corruption_levels = corruption_levels, batch_size = batch_size , \\\n",
      "                         training_epochs = training_epochs, pretraining_epochs = pretraining_epochs, \n",
      "                         pretrain_lr = pretrain_lr, finetune_lr=finetune_lr\n",
      "                         )\n",
      "                    \n",
      "                    print 'hidden_layers_sizes:', hidden_layers_sizes\n",
      "                    print 'corruption_levels:', corruption_levels\n",
      "                    training_predicted = sda_transformed.predict(new_x_train_minmax_whole)\n",
      "                    y_train = y_train_minmax\n",
      "                    \n",
      "                    isTest = False; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'DL_S', isTest) + tuple(performance_score(y_train, training_predicted, with_auc_score).values()))\n",
      "\n",
      "                    test_predicted = sda_transformed.predict(new_x_test_minmax_whole)\n",
      "                    y_test = test_y\n",
      "\n",
      "                    isTest = True; #new\n",
      "                    analysis_scr.append((self.ddi, subset_no, fisher_mode, 'DL_S', isTest) + tuple(performance_score(y_test, test_predicted, with_auc_score).values()))\n",
      "            \n",
      "            \n",
      "            report_name = filename + '_' + '_test10fold_'.join(map(str, hidden_layers_sizes)) + \\\n",
      "                            '_' + str(pretrain_lr) + '_' + str(finetune_lr) + '_' + str(reduce_ratio)+ \\\n",
      "                    '_' + str(training_epochs) + '_' + current_date\n",
      "            saveAsCsv(with_auc_score, report_name, performance_score(test_y, predicted_test_y, with_auc_score), analysis_scr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#LOO_out_performance_for_all(ddis)\n",
      "#LOO_out_performance_for_all(ddis)\n",
      "from multiprocessing import Pool\n",
      "pool = Pool(2)\n",
      "pool.map(process_one_ddi_tenfold, ddis[:])\n",
      "pool.close()\n",
      "pool.join()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/RNA_pol_Rpb1_5_int_RNA_pol_Rpb5_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/ERAP1_C_int_Peptidase_M1/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/NTP_transf_2_int_tRNA_NucTransf2/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/DNA_PPF_int_gp45-slide_C/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Pkinase_int_TGF_beta_GS/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Asn_synthase_int_GATase_7/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Eno-Rase_FAD_bd_int_Enoyl_reductase/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Hemocyanin_M_int_Hemocyanin_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/C2-set_2_int_V-set/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Colicin-DNase_int_Colicin_Pyocin/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/LRR_1_int_LRR_7/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/FERM_C_int_FERM_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/PSII_int_PsbU/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/FERM_C_int_FERM_M/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Skp1_int_Skp1_POZ/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/TetR_C_2_int_TetR_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Lyase_8_int_Lyase_8_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/FG-GAP_int_Integrin_beta/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Lyase_8_int_Lyase_8_C/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Trypsin_int_V-set/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/OKR_DC_1_int_OKR_DC_1_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Arg_repressor_int_Arg_repressor_C/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/SUFU_int_SUFU_C/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Peptidase_S9_int_Peptidase_S9_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Alpha-amylase_int_DUF3459/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/GAF_int_PHY/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Sigma70_r2_int_Sigma70_r3/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/RNA_pol_Rpb2_6_int_Sigma70_r4/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/FXa_inhibition_int_Ldl_recept_b/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/PQQ_int_PQQ_2/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Fn3-like_int_Glyco_hydro_3/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/MutS_II_int_MutS_III/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/GT36_AF_int_Glyco_transf_36/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/EFG_IV_int_Exotox-A_cataly/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Alpha-amylase_C_int_TIG/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/IlvC_int_IlvN/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/RNA_pol_Rpb2_7_int_RNA_pol_Rpb6/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Cytochrom_B_N_2_int_Rieske/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/GCV_T_int_GCV_T_C/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/RNA_pol_Rpb2_7_int_Sigma70_r3/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/EF-hand_7_int_Pkinase/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/ABC_tran_int_CFTR_R/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/RNA_pol_Rpb1_5_int_RNA_pol_Rpb2_5/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/CBM_X_int_GT36_AF/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Pkinase_int_Ribonuc_2-5A/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/EFG_II_int_GTP_EFTU_D2/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/HATPase_c_int_HisKA/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Amidase_int_Glu-tRNAGln/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/PolyA_pol_int_PolyA_pol_RNAbd/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Glyco_hydro_4_int_Glyco_hydro_4C/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Bromodomain_int_PHD/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/ATLF_int_Anthrax-tox_M/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/GTP_EFTU_int_eIF2_C/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Transglut_N_int_Transglut_core/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/DHO_dh_int_Fer4_20/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/PDZ_2_int_Trypsin_2/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/NAD_Gly3P_dh_C_int_NAD_Gly3P_dh_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Stap_Strp_tox_C_int_V-set/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/LRR_4_int_LRR_6/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/PNPase_int_RNase_PH/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/LRR_4_int_LRR_7/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/AAA_int_CDC48_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/RNA_pol_L_2_int_RNA_pol_Rpb8/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/CK_II_beta_int_Pkinase/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/RNA_pol_Rpb1_5_int_RNA_pol_Rpb2_45/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Fucose_iso_N1_int_Fucose_iso_N2/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/G6PD_C_int_G6PD_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/POR_N_int_TPP_enzyme_C/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Fn3-like_int_Glyco_hydro_3_C/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Pkinase_int_Pkinase_Tyr/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Hemocyanin_C_int_Hemocyanin_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/MutS_I_int_MutS_II/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/ATP-sulfurylase_int_PUA_2/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/PGM_PMM_III_int_PGM_PMM_IV/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/SNARE_int_Synaptobrevin/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Cbl_N2_int_Cbl_N3/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/V-set_int_VWA/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/MaoC_dehydrat_N_int_MaoC_dehydratas/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Cytochrom_B559a_int_Photo_RC/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/UreE_C_int_UreE_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/GST_C_2_int_GST_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/DUF1205_int_Glyco_transf_28/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/RNA_pol_Rpb2_1_int_Sigma70_r3/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Synapsin_int_Synapsin_C/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Topoisom_bac_int_Toprim/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Pyr_redox_int_Pyr_redox_dim/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/RNA_pol_Rpb1_3_int_RNA_pol_Rpb6/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/EF-hand_7_int_GFP/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Molybdop_Fe4S4_int_Molydop_binding/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/BCDHK_Adom3_int_HATPase_c/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Peptidase_S41_int_Tricorn_C1/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/UCR_hinge_int_UcrQ/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/UvrD-helicase_int_UvrD_C/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Dynamin_M_int_Dynamin_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Neur_chan_LBD_int_V-set/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Cytochrom_D1_int_Cytochrome_CBB3/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Lipase3_N_int_Lipase_3/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/THDPS_M_int_THDPS_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/RNA_pol_Rpb1_1_int_Sigma70_r1_2/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/End_beta_propel_int_End_tail_spike/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Fimbrial_int_PapD_C/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Ephrin_int_Ephrin_lbd/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Fimbrial_int_PapD_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/MSP_int_Photo_RC/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/GHMP_kinases_C_int_GHMP_kinases_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Arrestin_C_int_Arrestin_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Med11_int_Med22/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/UCR_TM_int_UCR_UQCRX_QCR9/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Cohesin_int_Dockerin_1/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Mur_ligase_int_Mur_ligase_M/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/AlkA_N_int_HhH-GPD/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/AMNp_N_int_PNP_UDP_1/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/PDGF_int_V-set/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Ribosomal_S11_int_Ribosomal_S7/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/EFG_II_int_GTP_EFTU/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Photo_RC_int_PsbT/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Adaptin_N_int_Clat_adaptor_s/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Cbl_N_int_Cbl_N3/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/GP120_int_ig/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Cbl_N_int_Cbl_N2/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/FAD_binding_1_int_NAD_binding_1/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Amidase_int_GatB_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Ecotin_int_Trypsin/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/MutS_I_int_MutS_III/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/OTCace_int_PyrI_C/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Photo_RC_int_PsbL/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Lipoprot_C_int_Sushi/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Photo_RC_int_PsbJ/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Pre-SET_int_SET/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/6PGD_int_NAD_binding_2/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/LRRNT_int_LRR_8/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Phosphodiest_int_Somatomedin_B/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/UBACT_int_UBA_e1_thiolCys/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/NUDIX_2_int_RRM_6/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/QueF_int_QueF_N/allPairs.txt'\n",
        "[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/GFRP_int_GTP_cyclohydroI/allPairs.txt'\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:__main__:DDI: ERAP1_C_int_Peptidase_M1\n",
        "INFO:__main__:DDI: RNA_pol_Rpb1_5_int_RNA_pol_Rpb5_N\n",
        "DEBUG:__main__:There is a error in this ddi: ERAP1_C_int_Peptidase_M1\n",
        "DEBUG:__main__:There is a error in this ddi: RNA_pol_Rpb1_5_int_RNA_pol_Rpb5_N\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/ERAP1_C_int_Peptidase_M1/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/RNA_pol_Rpb1_5_int_RNA_pol_Rpb5_N/allPairs.txt'\n",
        "INFO:__main__:DDI: DNA_PPF_int_gp45-slide_C\n",
        "INFO:__main__:DDI: NTP_transf_2_int_tRNA_NucTransf2\n",
        "DEBUG:__main__:There is a error in this ddi: DNA_PPF_int_gp45-slide_C\n",
        "DEBUG:__main__:There is a error in this ddi: NTP_transf_2_int_tRNA_NucTransf2\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/DNA_PPF_int_gp45-slide_C/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/NTP_transf_2_int_tRNA_NucTransf2/allPairs.txt'\n",
        "INFO:__main__:DDI: Asn_synthase_int_GATase_7\n",
        "INFO:__main__:DDI: Pkinase_int_TGF_beta_GS\n",
        "DEBUG:__main__:There is a error in this ddi: Asn_synthase_int_GATase_7\n",
        "DEBUG:__main__:There is a error in this ddi: Pkinase_int_TGF_beta_GS\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Asn_synthase_int_GATase_7/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Pkinase_int_TGF_beta_GS/allPairs.txt'\n",
        "INFO:__main__:DDI: Hemocyanin_M_int_Hemocyanin_N\n",
        "INFO:__main__:DDI: Eno-Rase_FAD_bd_int_Enoyl_reductase\n",
        "DEBUG:__main__:There is a error in this ddi: Hemocyanin_M_int_Hemocyanin_N\n",
        "DEBUG:__main__:There is a error in this ddi: Eno-Rase_FAD_bd_int_Enoyl_reductase\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Hemocyanin_M_int_Hemocyanin_N/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Eno-Rase_FAD_bd_int_Enoyl_reductase/allPairs.txt'\n",
        "INFO:__main__:DDI: Colicin-DNase_int_Colicin_Pyocin\n",
        "INFO:__main__:DDI: C2-set_2_int_V-set\n",
        "DEBUG:__main__:There is a error in this ddi: Colicin-DNase_int_Colicin_Pyocin\n",
        "DEBUG:__main__:There is a error in this ddi: C2-set_2_int_V-set\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Colicin-DNase_int_Colicin_Pyocin/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/C2-set_2_int_V-set/allPairs.txt'\n",
        "INFO:__main__:DDI: FERM_C_int_FERM_N\n",
        "INFO:__main__:DDI: LRR_1_int_LRR_7\n",
        "DEBUG:__main__:There is a error in this ddi: FERM_C_int_FERM_N\n",
        "DEBUG:__main__:There is a error in this ddi: LRR_1_int_LRR_7\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/FERM_C_int_FERM_N/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/LRR_1_int_LRR_7/allPairs.txt'\n",
        "INFO:__main__:DDI: FERM_C_int_FERM_M\n",
        "INFO:__main__:DDI: PSII_int_PsbU\n",
        "DEBUG:__main__:There is a error in this ddi: FERM_C_int_FERM_M\n",
        "DEBUG:__main__:There is a error in this ddi: PSII_int_PsbU\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/FERM_C_int_FERM_M/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/PSII_int_PsbU/allPairs.txt'\n",
        "INFO:__main__:DDI: TetR_C_2_int_TetR_N\n",
        "INFO:__main__:DDI: Skp1_int_Skp1_POZ\n",
        "DEBUG:__main__:There is a error in this ddi: TetR_C_2_int_TetR_N\n",
        "DEBUG:__main__:There is a error in this ddi: Skp1_int_Skp1_POZ\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/TetR_C_2_int_TetR_N/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Skp1_int_Skp1_POZ/allPairs.txt'\n",
        "INFO:__main__:DDI: FG-GAP_int_Integrin_beta\n",
        "INFO:__main__:DDI: Lyase_8_int_Lyase_8_N\n",
        "DEBUG:__main__:There is a error in this ddi: FG-GAP_int_Integrin_beta\n",
        "DEBUG:__main__:There is a error in this ddi: Lyase_8_int_Lyase_8_N\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/FG-GAP_int_Integrin_beta/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Lyase_8_int_Lyase_8_N/allPairs.txt'\n",
        "INFO:__main__:DDI: Trypsin_int_V-set\n",
        "INFO:__main__:DDI: Lyase_8_int_Lyase_8_C\n",
        "DEBUG:__main__:There is a error in this ddi: Trypsin_int_V-set\n",
        "DEBUG:__main__:There is a error in this ddi: Lyase_8_int_Lyase_8_C\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Trypsin_int_V-set/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Lyase_8_int_Lyase_8_C/allPairs.txt'\n",
        "INFO:__main__:DDI: Arg_repressor_int_Arg_repressor_C\n",
        "INFO:__main__:DDI: OKR_DC_1_int_OKR_DC_1_N\n",
        "DEBUG:__main__:There is a error in this ddi: Arg_repressor_int_Arg_repressor_C\n",
        "DEBUG:__main__:There is a error in this ddi: OKR_DC_1_int_OKR_DC_1_N\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Arg_repressor_int_Arg_repressor_C/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/OKR_DC_1_int_OKR_DC_1_N/allPairs.txt'\n",
        "INFO:__main__:DDI: Peptidase_S9_int_Peptidase_S9_N\n",
        "INFO:__main__:DDI: SUFU_int_SUFU_C\n",
        "DEBUG:__main__:There is a error in this ddi: Peptidase_S9_int_Peptidase_S9_N\n",
        "DEBUG:__main__:There is a error in this ddi: SUFU_int_SUFU_C\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Peptidase_S9_int_Peptidase_S9_N/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/SUFU_int_SUFU_C/allPairs.txt'\n",
        "INFO:__main__:DDI: GAF_int_PHY\n",
        "INFO:__main__:DDI: Alpha-amylase_int_DUF3459\n",
        "DEBUG:__main__:There is a error in this ddi: GAF_int_PHY\n",
        "DEBUG:__main__:There is a error in this ddi: Alpha-amylase_int_DUF3459\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/GAF_int_PHY/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Alpha-amylase_int_DUF3459/allPairs.txt'\n",
        "INFO:__main__:DDI: RNA_pol_Rpb2_6_int_Sigma70_r4\n",
        "INFO:__main__:DDI: Sigma70_r2_int_Sigma70_r3\n",
        "DEBUG:__main__:There is a error in this ddi: RNA_pol_Rpb2_6_int_Sigma70_r4\n",
        "DEBUG:__main__:There is a error in this ddi: Sigma70_r2_int_Sigma70_r3\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/RNA_pol_Rpb2_6_int_Sigma70_r4/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Sigma70_r2_int_Sigma70_r3/allPairs.txt'\n",
        "INFO:__main__:DDI: PQQ_int_PQQ_2\n",
        "INFO:__main__:DDI: FXa_inhibition_int_Ldl_recept_b\n",
        "DEBUG:__main__:There is a error in this ddi: PQQ_int_PQQ_2\n",
        "DEBUG:__main__:There is a error in this ddi: FXa_inhibition_int_Ldl_recept_b\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/PQQ_int_PQQ_2/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/FXa_inhibition_int_Ldl_recept_b/allPairs.txt'\n",
        "INFO:__main__:DDI: MutS_II_int_MutS_III\n",
        "INFO:__main__:DDI: Fn3-like_int_Glyco_hydro_3\n",
        "DEBUG:__main__:There is a error in this ddi: MutS_II_int_MutS_III\n",
        "DEBUG:__main__:There is a error in this ddi: Fn3-like_int_Glyco_hydro_3\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/MutS_II_int_MutS_III/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Fn3-like_int_Glyco_hydro_3/allPairs.txt'\n",
        "INFO:__main__:DDI: EFG_IV_int_Exotox-A_cataly\n",
        "INFO:__main__:DDI: GT36_AF_int_Glyco_transf_36\n",
        "DEBUG:__main__:There is a error in this ddi: EFG_IV_int_Exotox-A_cataly\n",
        "DEBUG:__main__:There is a error in this ddi: GT36_AF_int_Glyco_transf_36\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/EFG_IV_int_Exotox-A_cataly/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/GT36_AF_int_Glyco_transf_36/allPairs.txt'\n",
        "INFO:__main__:DDI: IlvC_int_IlvN\n",
        "INFO:__main__:DDI: Alpha-amylase_C_int_TIG\n",
        "DEBUG:__main__:There is a error in this ddi: IlvC_int_IlvN\n",
        "DEBUG:__main__:There is a error in this ddi: Alpha-amylase_C_int_TIG\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/IlvC_int_IlvN/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Alpha-amylase_C_int_TIG/allPairs.txt'\n",
        "INFO:__main__:DDI: Cytochrom_B_N_2_int_Rieske\n",
        "INFO:__main__:DDI: RNA_pol_Rpb2_7_int_RNA_pol_Rpb6\n",
        "DEBUG:__main__:There is a error in this ddi: Cytochrom_B_N_2_int_Rieske\n",
        "DEBUG:__main__:There is a error in this ddi: RNA_pol_Rpb2_7_int_RNA_pol_Rpb6\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/Cytochrom_B_N_2_int_Rieske/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/RNA_pol_Rpb2_7_int_RNA_pol_Rpb6/allPairs.txt'\n",
        "INFO:__main__:DDI: RNA_pol_Rpb2_7_int_Sigma70_r3\n",
        "INFO:__main__:DDI: GCV_T_int_GCV_T_C\n",
        "DEBUG:__main__:There is a error in this ddi: RNA_pol_Rpb2_7_int_Sigma70_r3\n",
        "DEBUG:__main__:There is a error in this ddi: GCV_T_int_GCV_T_C\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/RNA_pol_Rpb2_7_int_Sigma70_r3/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/GCV_T_int_GCV_T_C/allPairs.txt'\n",
        "INFO:__main__:DDI: ABC_tran_int_CFTR_R\n",
        "INFO:__main__:DDI: EF-hand_7_int_Pkinase\n",
        "DEBUG:__main__:There is a error in this ddi: ABC_tran_int_CFTR_R\n",
        "DEBUG:__main__:There is a error in this ddi: EF-hand_7_int_Pkinase\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/ABC_tran_int_CFTR_R/allPairs.txt'\n",
        "INFO:__main__:[Errno 2] No such file or directory: '/big/du/Protein_Protein_Interaction_Project/Contact_Matrix_Project/Vectors_Fishers_aaIndex_raw_2014_paper/EF-hand_7_int_Pkinase/allPairs.txt'\n",
        "INFO:__main__:DDI: CBM_X_int_GT36_AF\n",
        "INFO:__main__:DDI: RNA_pol_Rpb1_5_int_RNA_pol_Rpb2_5\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = logging._handlers.copy()\n",
      "for i in x:\n",
      "    log.removeHandler(i)\n",
      "    i.flush()\n",
      "    i.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    }
   ],
   "metadata": {}
  }
 ]
}