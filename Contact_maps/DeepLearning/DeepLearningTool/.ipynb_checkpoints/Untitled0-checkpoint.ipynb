{
 "metadata": {
  "name": "",
  "signature": "sha256:d8eaac23382db1abdda336753128e59eb22a12ee0bb87c74c06f1a65c52e2d72"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pprocess\n",
      " \n",
      "# Define a function to parallelize:\n",
      "def process_one_ddi(ddi):\n",
      "    \"\"\"A function to waste CPU cycles\"\"\"\n",
      "    one_ddi_family = LOO_out_performance_for_one_ddi(ddi)\n",
      "    one_ddi_family.get_LOO_perfermance('FisherM1', '')\n",
      "\n",
      "# Parallel computation:\n",
      "def parallel_process(function, ddis, nproc = 2):\n",
      "    # maximum number of simultaneous processes desired\n",
      "    results = pprocess.Map(limit=nproc, reuse=1)\n",
      "    parallel_function = results.manage(pprocess.MakeReusable(function))\n",
      "    [parallel_function(ddi) for ddi in ddis];  # Start computing things\n",
      "    return results[:]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = parallel_process(test, [1,2,3,4,5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 115,
       "text": [
        "[None, None, None, None, None]"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test(x)\n",
      "    print x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Solution:\n",
      "    # @param tokens, a list of string\n",
      "    # @return an integer\n",
      "    def evalRPN(self, tokens):\n",
      "        stack = []\n",
      "        for token in tokens:\n",
      "            if token in ['+', '-', '*', '/']:\n",
      "                op1 = stack.pop()\n",
      "                op2 = stack.pop()\n",
      "                if token == '+': stack.append(op1 + op2)\n",
      "                elif token == '-': stack.append(op1 - op2)\n",
      "                elif token == '*': stack.append(op1 * op2)\n",
      "                elif token == '/': stack.append(op1 / op2)\n",
      "            else:\n",
      "                stack.append(int(token))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arrayofTuples = [('a',1,5),('b',2,4),('c',7,8)]\n",
      "\n",
      "def breakTuples(t):\n",
      "    newList = list()\n",
      "    for item in t:\n",
      "        x = item[0]\n",
      "        y = item[1]\n",
      "        z = item[2]\n",
      "        a = tuple([x,y])\n",
      "        b = tuple([x,z])\n",
      "        newList.append(a)\n",
      "        newList.append(b)\n",
      "        \n",
      "    newList.sort(key=lambda x:x[1])\n",
      "    return newList\n",
      "\n",
      "\n",
      "print(breakTuples(arrayofTuples))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('a', 1), ('b', 2), ('b', 4), ('a', 5), ('c', 7), ('c', 8)]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a  =  np.random.random([10,1000])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(a, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "array([ 0.49603454,  0.48139543,  0.51701695,  0.50197379,  0.49245943,\n",
        "        0.49904039,  0.49760535,  0.50717965,  0.50647108,  0.51121551])"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.preprocessing\n",
      "class Precessing_Scaler_0_9(sklearn.preprocessing.StandardScaler):\n",
      "    def __init__(self):\n",
      "        super(Precessing_Scaler_0_9, self).__init__(self, with_std=0.333)\n",
      "    def transform(self, X): # transform data to 0.1 to 0.9\n",
      "        new_X = super(Precessing_Scaler_0_9, self).transform(X)\n",
      "        print \n",
      "        new_X[new_X > 1] = 1\n",
      "        new_X[new_X < -1] = -1\n",
      "        new_X = (new_X + 1) * 0.4 + 0.1\n",
      "        return new_X\n",
      "    def fit_transform(self):\n",
      "        print 'Did not implement'\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def performance_score(target_label, predicted_label, predicted_score = False, print_report = True): \n",
      "    \"\"\" get performance matrix for prediction\n",
      "        Attributes:\n",
      "            target_label: int 0, 1\n",
      "            predicted_label: 0, 1 or ranking\n",
      "            predicted_score: bool if False, predicted_label is from 0, 1. If Ture, predicted_label is ranked, need to get AUC score.\n",
      "            print_report: if True, print the perfromannce on screen\n",
      "    \"\"\"\n",
      "    import sklearn\n",
      "    from sklearn.metrics import roc_auc_score\n",
      "    score = {}\n",
      "    if predicted_score == False:\n",
      "        score['accuracy'] = sklearn.metrics.accuracy_score(target_label, predicted_label)\n",
      "        score['precision'] = sklearn.metrics.precision_score(target_label, predicted_label, pos_label=1)\n",
      "        score['recall'] = sklearn.metrics.recall_score(target_label, predicted_label, pos_label=1)\n",
      "    if predicted_score == True:\n",
      "        auc_score  = roc_auc_score(target_label, predicted_label)\n",
      "        score['auc_score'] = auc_score\n",
      "        target_label = [x >= 0.5 for x in target_label]\n",
      "        score['accuracy'] = sklearn.metrics.accuracy_score(target_label, predicted_label)\n",
      "        score['precision'] = sklearn.metrics.precision_score(target_label, predicted_label, pos_label=1)\n",
      "        score['recall'] = sklearn.metrics.recall_score(target_label, predicted_label, pos_label=1)\n",
      "    if print_report == True:\n",
      "        for key, value in score.iteritems():\n",
      "            print key, '{percent:.1%}'.format(percent=value)\n",
      "    return score\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scaler = PrecessingScaler(with_std=0.333)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "performance_score([1,1,0,0], [1,0,0,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "recall 50.0%\n",
        "precision 100.0%\n",
        "accuracy 75.0%\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 77,
       "text": [
        "{'accuracy': 0.75, 'precision': 1.0, 'recall': 0.5}"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = [2,3,2,3,4]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 83,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = transform_to_1_9.transform(c)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "0.90000000000000002"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    standard_scaler = preprocessing.StandardScaler().fit(train_X_reduced)\n",
      "                scaled_train_X = standard_scaler.transform(train_X_reduced)\n",
      "                scaled_test_X = standard_scaler.transform(test_X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "'''\n",
      "1.1 Implement an algorithm to determine if a string has all unique characters.What\n",
      "if you can not use additional data structures?\n",
      "'''\n",
      " \n",
      "def demo(text):\n",
      "    result = 0\n",
      "    for i in text:\n",
      "        flag = (1 << ord(i))\n",
      "    #print \"i, flag, result = \", i, flag, result\n",
      "        if result & flag > 0:\n",
      "            return False\n",
      "        else:\n",
      "            result |= flag\n",
      "        return True\n",
      " \n",
      "def demo2(text):\n",
      "    text = ''.join(sorted(text))\n",
      "    for i in range(1, len(text)):\n",
      "        if text[i] == text[i-1]:\n",
      "            return False\n",
      "    return True\n",
      " \n",
      " \n",
      "import random\n",
      "import unittest\n",
      "\n",
      "class TestSequenceFunctions(unittest.TestCase):\n",
      "\n",
      "    def setUp(self):\n",
      "        self.seq = range(10)\n",
      "\n",
      "    def test_shuffle(self):\n",
      "        # make sure the shuffled sequence does not lose any elements\n",
      "        random.shuffle(self.seq)\n",
      "        self.seq.sort()\n",
      "        self.assertEqual(self.seq, range(10))\n",
      "\n",
      "        # should raise an exception for an immutable sequence\n",
      "        self.assertRaises(TypeError, random.shuffle, (1,2,3))\n",
      "\n",
      "    def test_choice(self):\n",
      "        element = random.choice(self.seq)\n",
      "        self.assertTrue(element in self.seq)\n",
      "\n",
      "    def test_sample(self):\n",
      "        with self.assertRaises(ValueError):\n",
      "            random.sample(self.seq, 20)\n",
      "        for element in random.sample(self.seq, 5):\n",
      "            self.assertTrue(element in self.seq)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    unittest.main()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'module' object has no attribute '/home/du/'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-6-626fd3f840ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0munittest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/usr/lib/python2.7/unittest/main.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, module, defaultTest, argv, testRunner, testLoader, exit, verbosity, failfast, catchbreak, buffer)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtestLoader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseArgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunTests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/unittest/main.pyc\u001b[0m in \u001b[0;36mparseArgs\u001b[1;34m(self, argv)\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtestNames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaultTest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateTests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mgetopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musageExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/unittest/main.pyc\u001b[0m in \u001b[0;36mcreateTests\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             self.test = self.testLoader.loadTestsFromNames(self.testNames,\n\u001b[1;32m--> 158\u001b[1;33m                                                            self.module)\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_discovery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLoader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTestLoader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/unittest/loader.pyc\u001b[0m in \u001b[0;36mloadTestsFromNames\u001b[1;34m(self, names, module)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mof\u001b[0m \u001b[0mstring\u001b[0m \u001b[0mspecifiers\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mSee\u001b[0m \u001b[1;34m'loadTestsFromName()'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \"\"\"\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0msuites\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadTestsFromName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuiteClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuites\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/unittest/loader.pyc\u001b[0m in \u001b[0;36mloadTestsFromName\u001b[1;34m(self, name, module)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0mparent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModuleType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute '/home/du/'"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "1.2 Write code to reverse a C-Style String (C-String means that \"abcd\" is represented as\n",
      "five characters, including the null character )\n",
      "'''\n",
      " \n",
      "def demo(text):\n",
      "    return text[::-1]\n",
      " \n",
      "import unittest\n",
      "class MyTestCases(unittest.TestCase):\n",
      "    def test_mycase(self):\n",
      "        self.demo = demo\n",
      "        self.assertEqual(self.demo(\"\"), \"\")\n",
      "        self.assertEqual(self.demo(\"abcd\"), \"dcba\")\n",
      "        self.assertEqual(self.demo(\"abcdabcd\"), \"dcbadcba\")\n",
      "        self.assertEqual(self.demo(\"1314\"), \"4131\")\n",
      "#unittest.main()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1<<2\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "4"
       ]
      }
     ],
     "prompt_number": 14
    }
   ],
   "metadata": {}
  }
 ]
}